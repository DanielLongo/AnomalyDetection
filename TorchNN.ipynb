{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTMs with the latest version of Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynaconf import settings\n",
    "import numpy as np\n",
    "import random\n",
    "from data import EEGDataset, stackplot, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2765 recordings\n",
      "By set limit only using 2764 recordings\n",
      "Removing recordings of insufficient length...\n",
      "Removed 0 of 2764 recordings. There are now 2764 recordings.\n"
     ]
    }
   ],
   "source": [
    "train_dataset_csv = settings.TRAIN_DATASET_CSV\n",
    "dev_dataset_csv = settings.DEV_DATASET_CSV\n",
    "# real_train_dataset = EEGDataset(train_dataset_csv, 260, [1], max_num_examples=300, transform=normalize)\n",
    "real_train_dataset = EEGDataset(train_dataset_csv, 260, [1], max_num_examples=-1, transform=normalize)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(300):\n",
    "    example = real_train_dataset[i].numpy()\n",
    "#     example = example.T\n",
    "    start = 0\n",
    "    end = start + 250\n",
    "    pred_end = end + 10\n",
    "    X_train.append(example[:, start:end])\n",
    "    y_train.append(example[:, end:pred_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_real_train)\n",
    "y_train = np.asarray(y_real_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=80, num_layers=2, output_size=1, n_predictions=10, dropout=.3):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.n_predictions = n_predictions\n",
    "#         self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_layer_size, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(p=.3)\n",
    "        self.lstm2 = nn.LSTM(hidden_layer_size, hidden_layer_size, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(p=.3)\n",
    "#         self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(hidden_layer_size, n_predictions * output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        out, (_, _) = self.lstm1(input_seq)\n",
    "        out = self.dropout1(out)\n",
    "        out, (_, _) = self.lstm2(out)\n",
    "        out = self.dropout2(out)\n",
    "        preds = self.fc1(out[:,-1].squeeze()).squeeze()\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs):\n",
    "    torch_model.train()\n",
    "    running_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            a = torch_model(x.transpose(1,2))\n",
    "            loss = criteron(a.squeeze(), y.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_losses.append(loss.item())\n",
    "            if i % 10 == 0:\n",
    "                cur_iter = len(train_loader) * epoch + i\n",
    "                print(f\"epoch {epoch} | iter {cur_iter} | Running Loss {sum(running_losses)/len(running_losses)}\")\n",
    "                running_losses.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch_model = TorchLSTM(n_predictions=10, hidden_layer_size=80, num_layers=2)\n",
    "torch_model = TorchNN()\n",
    "torch_model.cuda()\n",
    "criteron = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(torch_model.parameters(), lr=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | iter 0 | Running Loss 0.30823349952697754\n",
      "epoch 1 | iter 5 | Running Loss 0.21635002493858338\n",
      "epoch 2 | iter 10 | Running Loss 0.11599928885698318\n",
      "epoch 3 | iter 15 | Running Loss 0.07994017004966736\n",
      "epoch 4 | iter 20 | Running Loss 0.07273350134491921\n",
      "epoch 5 | iter 25 | Running Loss 0.06145182400941849\n",
      "epoch 6 | iter 30 | Running Loss 0.05253302901983261\n",
      "epoch 7 | iter 35 | Running Loss 0.04463906362652779\n",
      "epoch 8 | iter 40 | Running Loss 0.04144860953092575\n",
      "epoch 9 | iter 45 | Running Loss 0.04104018285870552\n",
      "epoch 10 | iter 50 | Running Loss 0.03125474825501442\n",
      "epoch 11 | iter 55 | Running Loss 0.03426313064992428\n",
      "epoch 12 | iter 60 | Running Loss 0.02889178916811943\n",
      "epoch 13 | iter 65 | Running Loss 0.02866005040705204\n",
      "epoch 14 | iter 70 | Running Loss 0.027767509594559668\n",
      "epoch 15 | iter 75 | Running Loss 0.02889553867280483\n",
      "epoch 16 | iter 80 | Running Loss 0.027431533485651017\n",
      "epoch 17 | iter 85 | Running Loss 0.02926704064011574\n",
      "epoch 18 | iter 90 | Running Loss 0.022436612844467164\n",
      "epoch 19 | iter 95 | Running Loss 0.024116380512714385\n",
      "epoch 20 | iter 100 | Running Loss 0.021891191601753235\n",
      "epoch 21 | iter 105 | Running Loss 0.023836065270006656\n",
      "epoch 22 | iter 110 | Running Loss 0.020306535065174103\n",
      "epoch 23 | iter 115 | Running Loss 0.02298104129731655\n",
      "epoch 24 | iter 120 | Running Loss 0.02117786221206188\n",
      "epoch 25 | iter 125 | Running Loss 0.022148200869560243\n",
      "epoch 26 | iter 130 | Running Loss 0.02111770324409008\n",
      "epoch 27 | iter 135 | Running Loss 0.02087751403450966\n",
      "epoch 28 | iter 140 | Running Loss 0.020091086253523828\n",
      "epoch 29 | iter 145 | Running Loss 0.02110544517636299\n",
      "epoch 30 | iter 150 | Running Loss 0.017470902390778066\n",
      "epoch 31 | iter 155 | Running Loss 0.02340341918170452\n",
      "epoch 32 | iter 160 | Running Loss 0.01818872392177582\n",
      "epoch 33 | iter 165 | Running Loss 0.01826267708092928\n",
      "epoch 34 | iter 170 | Running Loss 0.018043604493141175\n",
      "epoch 35 | iter 175 | Running Loss 0.0170799707993865\n",
      "epoch 36 | iter 180 | Running Loss 0.0166603896766901\n",
      "epoch 37 | iter 185 | Running Loss 0.01597863417118788\n",
      "epoch 38 | iter 190 | Running Loss 0.017530001513659955\n",
      "epoch 39 | iter 195 | Running Loss 0.015018468350172042\n",
      "epoch 40 | iter 200 | Running Loss 0.016733326576650144\n",
      "epoch 41 | iter 205 | Running Loss 0.015848146751523018\n",
      "epoch 42 | iter 210 | Running Loss 0.015243483521044255\n",
      "epoch 43 | iter 215 | Running Loss 0.015502111986279488\n",
      "epoch 44 | iter 220 | Running Loss 0.015325443632900716\n",
      "epoch 45 | iter 225 | Running Loss 0.015684868209064007\n",
      "epoch 46 | iter 230 | Running Loss 0.013896987959742545\n",
      "epoch 47 | iter 235 | Running Loss 0.013407716155052185\n",
      "epoch 48 | iter 240 | Running Loss 0.012625689059495926\n",
      "epoch 49 | iter 245 | Running Loss 0.013089848496019841\n",
      "epoch 50 | iter 250 | Running Loss 0.014479357749223709\n",
      "epoch 51 | iter 255 | Running Loss 0.01279787328094244\n",
      "epoch 52 | iter 260 | Running Loss 0.012994098663330077\n",
      "epoch 53 | iter 265 | Running Loss 0.01192813627421856\n",
      "epoch 54 | iter 270 | Running Loss 0.011992410756647587\n",
      "epoch 55 | iter 275 | Running Loss 0.01191516537219286\n",
      "epoch 56 | iter 280 | Running Loss 0.011890059150755406\n",
      "epoch 57 | iter 285 | Running Loss 0.013497947715222836\n",
      "epoch 58 | iter 290 | Running Loss 0.012762094847857952\n",
      "epoch 59 | iter 295 | Running Loss 0.01418588701635599\n",
      "epoch 60 | iter 300 | Running Loss 0.013377687335014344\n",
      "epoch 61 | iter 305 | Running Loss 0.012731272075325251\n",
      "epoch 62 | iter 310 | Running Loss 0.011935245990753175\n",
      "epoch 63 | iter 315 | Running Loss 0.01047960314899683\n",
      "epoch 64 | iter 320 | Running Loss 0.010282633453607559\n",
      "epoch 65 | iter 325 | Running Loss 0.01016656830906868\n",
      "epoch 66 | iter 330 | Running Loss 0.010709259007126094\n",
      "epoch 67 | iter 335 | Running Loss 0.01097263041883707\n",
      "epoch 68 | iter 340 | Running Loss 0.009774340502917766\n",
      "epoch 69 | iter 345 | Running Loss 0.009670352283865213\n",
      "epoch 70 | iter 350 | Running Loss 0.010446961224079131\n",
      "epoch 71 | iter 355 | Running Loss 0.009616026747971773\n",
      "epoch 72 | iter 360 | Running Loss 0.009976424090564252\n",
      "epoch 73 | iter 365 | Running Loss 0.009682255424559116\n",
      "epoch 74 | iter 370 | Running Loss 0.009252397902309894\n",
      "epoch 75 | iter 375 | Running Loss 0.00961402729153633\n",
      "epoch 76 | iter 380 | Running Loss 0.00855366988107562\n",
      "epoch 77 | iter 385 | Running Loss 0.010212537553161382\n",
      "epoch 78 | iter 390 | Running Loss 0.008929056487977505\n",
      "epoch 79 | iter 395 | Running Loss 0.011910485103726387\n",
      "epoch 80 | iter 400 | Running Loss 0.00933709992095828\n",
      "epoch 81 | iter 405 | Running Loss 0.00965362498536706\n",
      "epoch 82 | iter 410 | Running Loss 0.009058182500302792\n",
      "epoch 83 | iter 415 | Running Loss 0.00872703017666936\n",
      "epoch 84 | iter 420 | Running Loss 0.00995037006214261\n",
      "epoch 85 | iter 425 | Running Loss 0.009767671301960944\n",
      "epoch 86 | iter 430 | Running Loss 0.008449760545045138\n",
      "epoch 87 | iter 435 | Running Loss 0.006499378941953182\n",
      "epoch 88 | iter 440 | Running Loss 0.008295078109949828\n",
      "epoch 89 | iter 445 | Running Loss 0.007666828017681837\n",
      "epoch 90 | iter 450 | Running Loss 0.008202299196273088\n",
      "epoch 91 | iter 455 | Running Loss 0.007218349445611239\n",
      "epoch 92 | iter 460 | Running Loss 0.007249053567647934\n",
      "epoch 93 | iter 465 | Running Loss 0.006827972363680601\n",
      "epoch 94 | iter 470 | Running Loss 0.006934637576341629\n",
      "epoch 95 | iter 475 | Running Loss 0.006723999604582786\n",
      "epoch 96 | iter 480 | Running Loss 0.0065066426992416385\n",
      "epoch 97 | iter 485 | Running Loss 0.006768542248755694\n",
      "epoch 98 | iter 490 | Running Loss 0.007349415495991707\n",
      "epoch 99 | iter 495 | Running Loss 0.006906840112060308\n",
      "epoch 100 | iter 500 | Running Loss 0.006726974155753851\n",
      "epoch 101 | iter 505 | Running Loss 0.006187805160880089\n",
      "epoch 102 | iter 510 | Running Loss 0.0062200921587646\n",
      "epoch 103 | iter 515 | Running Loss 0.006586519163101911\n",
      "epoch 104 | iter 520 | Running Loss 0.006985808815807104\n",
      "epoch 105 | iter 525 | Running Loss 0.006062153354287147\n",
      "epoch 106 | iter 530 | Running Loss 0.006646009627729654\n",
      "epoch 107 | iter 535 | Running Loss 0.007020418997853994\n",
      "epoch 108 | iter 540 | Running Loss 0.006249227467924357\n",
      "epoch 109 | iter 545 | Running Loss 0.007037345319986343\n",
      "epoch 110 | iter 550 | Running Loss 0.007445892225950957\n",
      "epoch 111 | iter 555 | Running Loss 0.008010062295943499\n",
      "epoch 112 | iter 560 | Running Loss 0.007064309809356928\n",
      "epoch 113 | iter 565 | Running Loss 0.0064334703609347345\n",
      "epoch 114 | iter 570 | Running Loss 0.005958935990929603\n",
      "epoch 115 | iter 575 | Running Loss 0.006439869664609433\n",
      "epoch 116 | iter 580 | Running Loss 0.005669100303202867\n",
      "epoch 117 | iter 585 | Running Loss 0.0056772932410240175\n",
      "epoch 118 | iter 590 | Running Loss 0.005682499147951603\n",
      "epoch 119 | iter 595 | Running Loss 0.006467315834015608\n",
      "epoch 120 | iter 600 | Running Loss 0.006018581986427307\n",
      "epoch 121 | iter 605 | Running Loss 0.005735772848129273\n",
      "epoch 122 | iter 610 | Running Loss 0.006082810461521149\n",
      "epoch 123 | iter 615 | Running Loss 0.005191043205559254\n",
      "epoch 124 | iter 620 | Running Loss 0.005008625984191895\n",
      "epoch 125 | iter 625 | Running Loss 0.00529428762383759\n",
      "epoch 126 | iter 630 | Running Loss 0.005072386050596833\n",
      "epoch 127 | iter 635 | Running Loss 0.005074731633067131\n",
      "epoch 128 | iter 640 | Running Loss 0.0053528842981904745\n",
      "epoch 129 | iter 645 | Running Loss 0.005418431339785456\n",
      "epoch 130 | iter 650 | Running Loss 0.0047368227504193785\n",
      "epoch 131 | iter 655 | Running Loss 0.004708467982709408\n",
      "epoch 132 | iter 660 | Running Loss 0.004684578161686659\n",
      "epoch 133 | iter 665 | Running Loss 0.005099868820980191\n",
      "epoch 134 | iter 670 | Running Loss 0.0048473876435309645\n",
      "epoch 135 | iter 675 | Running Loss 0.005324102751910686\n",
      "epoch 136 | iter 680 | Running Loss 0.004690424632281065\n",
      "epoch 137 | iter 685 | Running Loss 0.005108815245330333\n",
      "epoch 138 | iter 690 | Running Loss 0.004919665772467852\n",
      "epoch 139 | iter 695 | Running Loss 0.004384742910042405\n",
      "epoch 140 | iter 700 | Running Loss 0.004857865441590547\n",
      "epoch 141 | iter 705 | Running Loss 0.004524884652346373\n",
      "epoch 142 | iter 710 | Running Loss 0.004451764374971389\n",
      "epoch 143 | iter 715 | Running Loss 0.0049776161089539524\n",
      "epoch 144 | iter 720 | Running Loss 0.004461514763534069\n",
      "epoch 145 | iter 725 | Running Loss 0.0045888697728514675\n",
      "epoch 146 | iter 730 | Running Loss 0.004461827175691724\n",
      "epoch 147 | iter 735 | Running Loss 0.004528198717162013\n",
      "epoch 148 | iter 740 | Running Loss 0.004243660252541304\n",
      "epoch 149 | iter 745 | Running Loss 0.004573942208662629\n",
      "epoch 150 | iter 750 | Running Loss 0.004180627316236496\n",
      "epoch 151 | iter 755 | Running Loss 0.003791432082653046\n",
      "epoch 152 | iter 760 | Running Loss 0.004694367805495858\n",
      "epoch 153 | iter 765 | Running Loss 0.003957429621368647\n",
      "epoch 154 | iter 770 | Running Loss 0.00424066879786551\n",
      "epoch 155 | iter 775 | Running Loss 0.004532216303050518\n",
      "epoch 156 | iter 780 | Running Loss 0.0055613428819924595\n",
      "epoch 157 | iter 785 | Running Loss 0.005277069890871644\n",
      "epoch 158 | iter 790 | Running Loss 0.005989247094839811\n",
      "epoch 159 | iter 795 | Running Loss 0.005504628829658032\n",
      "epoch 160 | iter 800 | Running Loss 0.004536336055025458\n",
      "epoch 161 | iter 805 | Running Loss 0.004797064792364835\n",
      "epoch 162 | iter 810 | Running Loss 0.004451285768300295\n",
      "epoch 163 | iter 815 | Running Loss 0.004066620720550418\n",
      "epoch 164 | iter 820 | Running Loss 0.004012760240584612\n",
      "epoch 165 | iter 825 | Running Loss 0.003848785161972046\n",
      "epoch 166 | iter 830 | Running Loss 0.0036312232725322245\n",
      "epoch 167 | iter 835 | Running Loss 0.0037355122156441213\n",
      "epoch 168 | iter 840 | Running Loss 0.0036374983843415975\n",
      "epoch 169 | iter 845 | Running Loss 0.0034127362072467805\n",
      "epoch 170 | iter 850 | Running Loss 0.0034043106716126204\n",
      "epoch 171 | iter 855 | Running Loss 0.0034540722146630285\n",
      "epoch 172 | iter 860 | Running Loss 0.0036699215415865183\n",
      "epoch 173 | iter 865 | Running Loss 0.0031388122122734787\n",
      "epoch 174 | iter 870 | Running Loss 0.0032922171521931887\n",
      "epoch 175 | iter 875 | Running Loss 0.0035479442216455937\n",
      "epoch 176 | iter 880 | Running Loss 0.0031238209921866655\n",
      "epoch 177 | iter 885 | Running Loss 0.003275601612403989\n",
      "epoch 178 | iter 890 | Running Loss 0.003320683864876628\n",
      "epoch 179 | iter 895 | Running Loss 0.0030719881411641835\n",
      "epoch 180 | iter 900 | Running Loss 0.0032365137711167337\n",
      "epoch 181 | iter 905 | Running Loss 0.0034404904115945103\n",
      "epoch 182 | iter 910 | Running Loss 0.002647548308596015\n",
      "epoch 183 | iter 915 | Running Loss 0.003199625527486205\n",
      "epoch 184 | iter 920 | Running Loss 0.0035562386270612477\n",
      "epoch 185 | iter 925 | Running Loss 0.0027360535925254224\n",
      "epoch 186 | iter 930 | Running Loss 0.0026734874583780764\n",
      "epoch 187 | iter 935 | Running Loss 0.002977915434166789\n",
      "epoch 188 | iter 940 | Running Loss 0.003204018250107765\n",
      "epoch 189 | iter 945 | Running Loss 0.0031959501560777427\n",
      "epoch 190 | iter 950 | Running Loss 0.0032826111651957034\n",
      "epoch 191 | iter 955 | Running Loss 0.0028447956312447785\n",
      "epoch 192 | iter 960 | Running Loss 0.003211067523807287\n",
      "epoch 193 | iter 965 | Running Loss 0.0033060743007808924\n",
      "epoch 194 | iter 970 | Running Loss 0.0029260525014251472\n",
      "epoch 195 | iter 975 | Running Loss 0.002879267977550626\n",
      "epoch 196 | iter 980 | Running Loss 0.003027853509411216\n",
      "epoch 197 | iter 985 | Running Loss 0.0032478882465511562\n",
      "epoch 198 | iter 990 | Running Loss 0.0031574008520692588\n",
      "epoch 199 | iter 995 | Running Loss 0.003305963706225157\n",
      "epoch 200 | iter 1000 | Running Loss 0.0031607358250766993\n",
      "epoch 201 | iter 1005 | Running Loss 0.002643858594819903\n",
      "epoch 202 | iter 1010 | Running Loss 0.003001799713820219\n",
      "epoch 203 | iter 1015 | Running Loss 0.0027058664709329605\n",
      "epoch 204 | iter 1020 | Running Loss 0.0029163639061152934\n",
      "epoch 205 | iter 1025 | Running Loss 0.0028276019264012577\n",
      "epoch 206 | iter 1030 | Running Loss 0.0031216997187584637\n",
      "epoch 207 | iter 1035 | Running Loss 0.003043329529464245\n",
      "epoch 208 | iter 1040 | Running Loss 0.0029680618084967137\n",
      "epoch 209 | iter 1045 | Running Loss 0.0030056779738515615\n",
      "epoch 210 | iter 1050 | Running Loss 0.0027662683743983505\n",
      "epoch 211 | iter 1055 | Running Loss 0.0024342486867681146\n",
      "epoch 212 | iter 1060 | Running Loss 0.0024900558404624463\n",
      "epoch 213 | iter 1065 | Running Loss 0.002260397421196103\n",
      "epoch 214 | iter 1070 | Running Loss 0.0025813285494223235\n",
      "epoch 215 | iter 1075 | Running Loss 0.002460316685028374\n",
      "epoch 216 | iter 1080 | Running Loss 0.002354645822197199\n",
      "epoch 217 | iter 1085 | Running Loss 0.0025225778110325335\n",
      "epoch 218 | iter 1090 | Running Loss 0.0022333064815029504\n",
      "epoch 219 | iter 1095 | Running Loss 0.0023012505611404777\n",
      "epoch 220 | iter 1100 | Running Loss 0.0027317097410559654\n",
      "epoch 221 | iter 1105 | Running Loss 0.0026798489736393092\n",
      "epoch 222 | iter 1110 | Running Loss 0.002476092614233494\n",
      "epoch 223 | iter 1115 | Running Loss 0.0026871086098253726\n",
      "epoch 224 | iter 1120 | Running Loss 0.0021573993843048813\n",
      "epoch 225 | iter 1125 | Running Loss 0.0028316174168139694\n",
      "epoch 226 | iter 1130 | Running Loss 0.0026209954638034107\n",
      "epoch 227 | iter 1135 | Running Loss 0.002653820253908634\n",
      "epoch 228 | iter 1140 | Running Loss 0.002689834451302886\n",
      "epoch 229 | iter 1145 | Running Loss 0.00244260982144624\n",
      "epoch 230 | iter 1150 | Running Loss 0.0023589647142216565\n",
      "epoch 231 | iter 1155 | Running Loss 0.0025965845212340354\n",
      "epoch 232 | iter 1160 | Running Loss 0.0025625122711062432\n",
      "epoch 233 | iter 1165 | Running Loss 0.00265165688470006\n",
      "epoch 234 | iter 1170 | Running Loss 0.002736268495209515\n",
      "epoch 235 | iter 1175 | Running Loss 0.002660041768103838\n",
      "epoch 236 | iter 1180 | Running Loss 0.0027759159449487923\n",
      "epoch 237 | iter 1185 | Running Loss 0.0025977151468396186\n",
      "epoch 238 | iter 1190 | Running Loss 0.0024082812014967203\n",
      "epoch 239 | iter 1195 | Running Loss 0.0023733826354146005\n",
      "epoch 240 | iter 1200 | Running Loss 0.0024127014679834248\n",
      "epoch 241 | iter 1205 | Running Loss 0.002212826395407319\n",
      "epoch 242 | iter 1210 | Running Loss 0.002392389997839928\n",
      "epoch 243 | iter 1215 | Running Loss 0.0022330825915560125\n",
      "epoch 244 | iter 1220 | Running Loss 0.00211093183606863\n",
      "epoch 245 | iter 1225 | Running Loss 0.0020714627811685205\n",
      "epoch 246 | iter 1230 | Running Loss 0.0020082790171727536\n",
      "epoch 247 | iter 1235 | Running Loss 0.0021392337745055555\n",
      "epoch 248 | iter 1240 | Running Loss 0.001965897483751178\n",
      "epoch 249 | iter 1245 | Running Loss 0.002006556955166161\n",
      "epoch 250 | iter 1250 | Running Loss 0.00200977879576385\n",
      "epoch 251 | iter 1255 | Running Loss 0.0019108634442090988\n",
      "epoch 252 | iter 1260 | Running Loss 0.0019056205404922367\n",
      "epoch 253 | iter 1265 | Running Loss 0.002002465748228133\n",
      "epoch 254 | iter 1270 | Running Loss 0.001612394186668098\n",
      "epoch 255 | iter 1275 | Running Loss 0.0018425447400659324\n",
      "epoch 256 | iter 1280 | Running Loss 0.0017453636741265655\n",
      "epoch 257 | iter 1285 | Running Loss 0.0018281901720911264\n",
      "epoch 258 | iter 1290 | Running Loss 0.0016658144537359475\n",
      "epoch 259 | iter 1295 | Running Loss 0.001678487891331315\n",
      "epoch 260 | iter 1300 | Running Loss 0.001706492598168552\n",
      "epoch 261 | iter 1305 | Running Loss 0.0018535526469349861\n",
      "epoch 262 | iter 1310 | Running Loss 0.001721544866450131\n",
      "epoch 263 | iter 1315 | Running Loss 0.0016033393563702702\n",
      "epoch 264 | iter 1320 | Running Loss 0.0017123484751209617\n",
      "epoch 265 | iter 1325 | Running Loss 0.0015561521984636783\n",
      "epoch 266 | iter 1330 | Running Loss 0.0016800526529550553\n",
      "epoch 267 | iter 1335 | Running Loss 0.0017938459990546108\n",
      "epoch 268 | iter 1340 | Running Loss 0.002082204259932041\n",
      "epoch 269 | iter 1345 | Running Loss 0.0017033245181664824\n",
      "epoch 270 | iter 1350 | Running Loss 0.001599165517836809\n",
      "epoch 271 | iter 1355 | Running Loss 0.0017569908406585455\n",
      "epoch 272 | iter 1360 | Running Loss 0.0014468222158029675\n",
      "epoch 273 | iter 1365 | Running Loss 0.0015492808539420365\n",
      "epoch 274 | iter 1370 | Running Loss 0.001691136253066361\n",
      "epoch 275 | iter 1375 | Running Loss 0.0016085504554212092\n",
      "epoch 276 | iter 1380 | Running Loss 0.0017097520641982556\n",
      "epoch 277 | iter 1385 | Running Loss 0.0017614828189834951\n",
      "epoch 278 | iter 1390 | Running Loss 0.0015895794844254852\n",
      "epoch 279 | iter 1395 | Running Loss 0.001504124701023102\n",
      "epoch 280 | iter 1400 | Running Loss 0.0016064944909885525\n",
      "epoch 281 | iter 1405 | Running Loss 0.0016482237726449967\n",
      "epoch 282 | iter 1410 | Running Loss 0.0017025030218064785\n",
      "epoch 283 | iter 1415 | Running Loss 0.0018365756142884493\n",
      "epoch 284 | iter 1420 | Running Loss 0.0016955582424998284\n",
      "epoch 285 | iter 1425 | Running Loss 0.0016940399538725615\n",
      "epoch 286 | iter 1430 | Running Loss 0.0017028622329235076\n",
      "epoch 287 | iter 1435 | Running Loss 0.001511017046868801\n",
      "epoch 288 | iter 1440 | Running Loss 0.0014553811633959413\n",
      "epoch 289 | iter 1445 | Running Loss 0.001439678599126637\n",
      "epoch 290 | iter 1450 | Running Loss 0.001954884734004736\n",
      "epoch 291 | iter 1455 | Running Loss 0.0021746500162407754\n",
      "epoch 292 | iter 1460 | Running Loss 0.0025318751577287912\n",
      "epoch 293 | iter 1465 | Running Loss 0.0023594536585733296\n",
      "epoch 294 | iter 1470 | Running Loss 0.0017489986028522253\n",
      "epoch 295 | iter 1475 | Running Loss 0.0021030814619734882\n",
      "epoch 296 | iter 1480 | Running Loss 0.001866594422608614\n",
      "epoch 297 | iter 1485 | Running Loss 0.0016719110310077668\n",
      "epoch 298 | iter 1490 | Running Loss 0.0016905310796573759\n",
      "epoch 299 | iter 1495 | Running Loss 0.0013608199544250966\n",
      "epoch 300 | iter 1500 | Running Loss 0.0016986043425276875\n",
      "epoch 301 | iter 1505 | Running Loss 0.0014889974612742663\n",
      "epoch 302 | iter 1510 | Running Loss 0.0013819667277857662\n",
      "epoch 303 | iter 1515 | Running Loss 0.0013832142343744636\n",
      "epoch 304 | iter 1520 | Running Loss 0.0013112170156091452\n",
      "epoch 305 | iter 1525 | Running Loss 0.0012808514293283224\n",
      "epoch 306 | iter 1530 | Running Loss 0.0012142633204348385\n",
      "epoch 307 | iter 1535 | Running Loss 0.0012495226226747036\n",
      "epoch 308 | iter 1540 | Running Loss 0.0013200955465435982\n",
      "epoch 309 | iter 1545 | Running Loss 0.0012121489504352211\n",
      "epoch 310 | iter 1550 | Running Loss 0.001346833724528551\n",
      "epoch 311 | iter 1555 | Running Loss 0.001106259028892964\n",
      "epoch 312 | iter 1560 | Running Loss 0.0012650210410356522\n",
      "epoch 313 | iter 1565 | Running Loss 0.0013605760410428046\n",
      "epoch 314 | iter 1570 | Running Loss 0.0011813910445198418\n",
      "epoch 315 | iter 1575 | Running Loss 0.0011160844354890288\n",
      "epoch 316 | iter 1580 | Running Loss 0.0011902773869223893\n",
      "epoch 317 | iter 1585 | Running Loss 0.0012151285889558494\n",
      "epoch 318 | iter 1590 | Running Loss 0.0010639570071361959\n",
      "epoch 319 | iter 1595 | Running Loss 0.0012903843307867646\n",
      "epoch 320 | iter 1600 | Running Loss 0.0011786822462454439\n",
      "epoch 321 | iter 1605 | Running Loss 0.0011837022844702005\n",
      "epoch 322 | iter 1610 | Running Loss 0.0011525975074619054\n",
      "epoch 323 | iter 1615 | Running Loss 0.001190198853146285\n",
      "epoch 324 | iter 1620 | Running Loss 0.0010971575742587448\n",
      "epoch 325 | iter 1625 | Running Loss 0.0010866099735721945\n",
      "epoch 326 | iter 1630 | Running Loss 0.0011665214085951447\n",
      "epoch 327 | iter 1635 | Running Loss 0.001109948568046093\n",
      "epoch 328 | iter 1640 | Running Loss 0.0012401866493746637\n",
      "epoch 329 | iter 1645 | Running Loss 0.001504810038022697\n",
      "epoch 330 | iter 1650 | Running Loss 0.0016187963308766484\n",
      "epoch 331 | iter 1655 | Running Loss 0.0018856218084692955\n",
      "epoch 332 | iter 1660 | Running Loss 0.0019171805353835226\n",
      "epoch 333 | iter 1665 | Running Loss 0.0015121867880225181\n",
      "epoch 334 | iter 1670 | Running Loss 0.0013690811349079013\n",
      "epoch 335 | iter 1675 | Running Loss 0.0014662524685263635\n",
      "epoch 336 | iter 1680 | Running Loss 0.0016799811739474535\n",
      "epoch 337 | iter 1685 | Running Loss 0.0018239261815324425\n",
      "epoch 338 | iter 1690 | Running Loss 0.002150157652795315\n",
      "epoch 339 | iter 1695 | Running Loss 0.0017059148522093892\n",
      "epoch 340 | iter 1700 | Running Loss 0.001372440136037767\n",
      "epoch 341 | iter 1705 | Running Loss 0.00131664436776191\n",
      "epoch 342 | iter 1710 | Running Loss 0.0013061844278126956\n",
      "epoch 343 | iter 1715 | Running Loss 0.0010075508966110648\n",
      "epoch 344 | iter 1720 | Running Loss 0.0010806674603372813\n",
      "epoch 345 | iter 1725 | Running Loss 0.0010191883891820907\n",
      "epoch 346 | iter 1730 | Running Loss 0.0010149444569833577\n",
      "epoch 347 | iter 1735 | Running Loss 0.0009397486806847155\n",
      "epoch 348 | iter 1740 | Running Loss 0.0009478857740759849\n",
      "epoch 349 | iter 1745 | Running Loss 0.0009592579095624387\n",
      "epoch 350 | iter 1750 | Running Loss 0.0009850627859123052\n",
      "epoch 351 | iter 1755 | Running Loss 0.001032884221058339\n",
      "epoch 352 | iter 1760 | Running Loss 0.0010096972342580556\n",
      "epoch 353 | iter 1765 | Running Loss 0.0010743657243438066\n",
      "epoch 354 | iter 1770 | Running Loss 0.0010509876650758089\n",
      "epoch 355 | iter 1775 | Running Loss 0.0008681606967002153\n",
      "epoch 356 | iter 1780 | Running Loss 0.000888516241684556\n",
      "epoch 357 | iter 1785 | Running Loss 0.0009158814558759331\n",
      "epoch 358 | iter 1790 | Running Loss 0.0010701989522203803\n",
      "epoch 359 | iter 1795 | Running Loss 0.0009458153741434217\n",
      "epoch 360 | iter 1800 | Running Loss 0.0010619489941745997\n",
      "epoch 361 | iter 1805 | Running Loss 0.000919873476959765\n",
      "epoch 362 | iter 1810 | Running Loss 0.000994278327561915\n",
      "epoch 363 | iter 1815 | Running Loss 0.0009257750003598631\n",
      "epoch 364 | iter 1820 | Running Loss 0.0008045546128414571\n",
      "epoch 365 | iter 1825 | Running Loss 0.0009875158779323102\n",
      "epoch 366 | iter 1830 | Running Loss 0.001113937993068248\n",
      "epoch 367 | iter 1835 | Running Loss 0.0010825188015587627\n",
      "epoch 368 | iter 1840 | Running Loss 0.0008834508946165443\n",
      "epoch 369 | iter 1845 | Running Loss 0.0008493505534715951\n",
      "epoch 370 | iter 1850 | Running Loss 0.0009741383488290012\n",
      "epoch 371 | iter 1855 | Running Loss 0.0009395172935910523\n",
      "epoch 372 | iter 1860 | Running Loss 0.0009758553467690944\n",
      "epoch 373 | iter 1865 | Running Loss 0.000996259308885783\n",
      "epoch 374 | iter 1870 | Running Loss 0.0008315830491483212\n",
      "epoch 375 | iter 1875 | Running Loss 0.0008502164506353438\n",
      "epoch 376 | iter 1880 | Running Loss 0.000780135439708829\n",
      "epoch 377 | iter 1885 | Running Loss 0.0008776727481745183\n",
      "epoch 378 | iter 1890 | Running Loss 0.000756140728481114\n",
      "epoch 379 | iter 1895 | Running Loss 0.0006877902313135564\n",
      "epoch 380 | iter 1900 | Running Loss 0.0007273420807905496\n",
      "epoch 381 | iter 1905 | Running Loss 0.0007016179384663701\n",
      "epoch 382 | iter 1910 | Running Loss 0.000747501605655998\n",
      "epoch 383 | iter 1915 | Running Loss 0.0007539964281022549\n",
      "epoch 384 | iter 1920 | Running Loss 0.0007745804614387453\n",
      "epoch 385 | iter 1925 | Running Loss 0.0007623495650477708\n",
      "epoch 386 | iter 1930 | Running Loss 0.0009702528594061732\n",
      "epoch 387 | iter 1935 | Running Loss 0.0009150385274551808\n",
      "epoch 388 | iter 1940 | Running Loss 0.0009017789619974792\n",
      "epoch 389 | iter 1945 | Running Loss 0.0009359449031762779\n",
      "epoch 390 | iter 1950 | Running Loss 0.0010711687500588596\n",
      "epoch 391 | iter 1955 | Running Loss 0.0009920286014676095\n",
      "epoch 392 | iter 1960 | Running Loss 0.0010075122583657504\n",
      "epoch 393 | iter 1965 | Running Loss 0.0009832501411437989\n",
      "epoch 394 | iter 1970 | Running Loss 0.001066208048723638\n",
      "epoch 395 | iter 1975 | Running Loss 0.0009527912712655962\n",
      "epoch 396 | iter 1980 | Running Loss 0.0008955411496572197\n",
      "epoch 397 | iter 1985 | Running Loss 0.0008611067198216916\n",
      "epoch 398 | iter 1990 | Running Loss 0.0008190070395357907\n",
      "epoch 399 | iter 1995 | Running Loss 0.0009318693540990352\n",
      "epoch 400 | iter 2000 | Running Loss 0.0009888806496746838\n",
      "epoch 401 | iter 2005 | Running Loss 0.0010198118165135384\n",
      "epoch 402 | iter 2010 | Running Loss 0.00108326212503016\n",
      "epoch 403 | iter 2015 | Running Loss 0.0009605134488083422\n",
      "epoch 404 | iter 2020 | Running Loss 0.001169943029526621\n",
      "epoch 405 | iter 2025 | Running Loss 0.0012420453829690814\n",
      "epoch 406 | iter 2030 | Running Loss 0.0011862811050377786\n",
      "epoch 407 | iter 2035 | Running Loss 0.0012777390773408114\n",
      "epoch 408 | iter 2040 | Running Loss 0.0011729009100235998\n",
      "epoch 409 | iter 2045 | Running Loss 0.0009192214696668088\n",
      "epoch 410 | iter 2050 | Running Loss 0.0008458846714347601\n",
      "epoch 411 | iter 2055 | Running Loss 0.0008704421226866544\n",
      "epoch 412 | iter 2060 | Running Loss 0.0008442968130111695\n",
      "epoch 413 | iter 2065 | Running Loss 0.0008498533396050334\n",
      "epoch 414 | iter 2070 | Running Loss 0.0008615869563072919\n",
      "epoch 415 | iter 2075 | Running Loss 0.0008009209530428052\n",
      "epoch 416 | iter 2080 | Running Loss 0.000767245062161237\n",
      "epoch 417 | iter 2085 | Running Loss 0.000842184410430491\n",
      "epoch 418 | iter 2090 | Running Loss 0.0007795935263857246\n",
      "epoch 419 | iter 2095 | Running Loss 0.0008055970654822886\n",
      "epoch 420 | iter 2100 | Running Loss 0.0007137808483093977\n",
      "epoch 421 | iter 2105 | Running Loss 0.0006877563777379691\n",
      "epoch 422 | iter 2110 | Running Loss 0.0006606176844798029\n",
      "epoch 423 | iter 2115 | Running Loss 0.0007051243097521365\n",
      "epoch 424 | iter 2120 | Running Loss 0.0005646252655424177\n",
      "epoch 425 | iter 2125 | Running Loss 0.0007168355514295399\n",
      "epoch 426 | iter 2130 | Running Loss 0.0006885961862280965\n",
      "epoch 427 | iter 2135 | Running Loss 0.0006521774921566248\n",
      "epoch 428 | iter 2140 | Running Loss 0.0006472036824561655\n",
      "epoch 429 | iter 2145 | Running Loss 0.0007326947641558945\n",
      "epoch 430 | iter 2150 | Running Loss 0.0007441459572874009\n",
      "epoch 431 | iter 2155 | Running Loss 0.0007512770127505064\n",
      "epoch 432 | iter 2160 | Running Loss 0.0009596857707947493\n",
      "epoch 433 | iter 2165 | Running Loss 0.0009846599539741873\n",
      "epoch 434 | iter 2170 | Running Loss 0.0010823259595781564\n",
      "epoch 435 | iter 2175 | Running Loss 0.000798997690435499\n",
      "epoch 436 | iter 2180 | Running Loss 0.0006966706132516265\n",
      "epoch 437 | iter 2185 | Running Loss 0.0006207294994965195\n",
      "epoch 438 | iter 2190 | Running Loss 0.0006596807506866753\n",
      "epoch 439 | iter 2195 | Running Loss 0.0006429116940125823\n",
      "epoch 440 | iter 2200 | Running Loss 0.0006293161422945559\n",
      "epoch 441 | iter 2205 | Running Loss 0.0005465156165882945\n",
      "epoch 442 | iter 2210 | Running Loss 0.0005138087319210172\n",
      "epoch 443 | iter 2215 | Running Loss 0.0005298082367517054\n",
      "epoch 444 | iter 2220 | Running Loss 0.0004923306754790246\n",
      "epoch 445 | iter 2225 | Running Loss 0.00048189749359153213\n",
      "epoch 446 | iter 2230 | Running Loss 0.0005278055905364454\n",
      "epoch 447 | iter 2235 | Running Loss 0.0004815968277398497\n",
      "epoch 448 | iter 2240 | Running Loss 0.0005178726511076093\n",
      "epoch 449 | iter 2245 | Running Loss 0.0004795328713953495\n",
      "epoch 450 | iter 2250 | Running Loss 0.00045353557216003536\n",
      "epoch 451 | iter 2255 | Running Loss 0.0005417595384642482\n",
      "epoch 452 | iter 2260 | Running Loss 0.000534844893263653\n",
      "epoch 453 | iter 2265 | Running Loss 0.0007125187548808753\n",
      "epoch 454 | iter 2270 | Running Loss 0.0005885618447791785\n",
      "epoch 455 | iter 2275 | Running Loss 0.0005798798985779286\n",
      "epoch 456 | iter 2280 | Running Loss 0.0005235599586740136\n",
      "epoch 457 | iter 2285 | Running Loss 0.0005308402120135725\n",
      "epoch 458 | iter 2290 | Running Loss 0.0004968410357832909\n",
      "epoch 459 | iter 2295 | Running Loss 0.0005418489221483469\n",
      "epoch 460 | iter 2300 | Running Loss 0.0005298281321302056\n",
      "epoch 461 | iter 2305 | Running Loss 0.0005078635702375322\n",
      "epoch 462 | iter 2310 | Running Loss 0.0005105250747874379\n",
      "epoch 463 | iter 2315 | Running Loss 0.0004692996444646269\n",
      "epoch 464 | iter 2320 | Running Loss 0.0004942185245454311\n",
      "epoch 465 | iter 2325 | Running Loss 0.00045839868835173547\n",
      "epoch 466 | iter 2330 | Running Loss 0.0005099213100038469\n",
      "epoch 467 | iter 2335 | Running Loss 0.0004617512691766024\n",
      "epoch 468 | iter 2340 | Running Loss 0.00048384516267105935\n",
      "epoch 469 | iter 2345 | Running Loss 0.0004655209952034056\n",
      "epoch 470 | iter 2350 | Running Loss 0.0005674882209859789\n",
      "epoch 471 | iter 2355 | Running Loss 0.000771358300698921\n",
      "epoch 472 | iter 2360 | Running Loss 0.0006684392224997282\n",
      "epoch 473 | iter 2365 | Running Loss 0.0005595706403255463\n",
      "epoch 474 | iter 2370 | Running Loss 0.0006388908601365984\n",
      "epoch 475 | iter 2375 | Running Loss 0.0006147516600321978\n",
      "epoch 476 | iter 2380 | Running Loss 0.0006741231656633318\n",
      "epoch 477 | iter 2385 | Running Loss 0.0006349973962642252\n",
      "epoch 478 | iter 2390 | Running Loss 0.0009283852297812701\n",
      "epoch 479 | iter 2395 | Running Loss 0.000778372585773468\n",
      "epoch 480 | iter 2400 | Running Loss 0.0007715592510066926\n",
      "epoch 481 | iter 2405 | Running Loss 0.0007099880138412118\n",
      "epoch 482 | iter 2410 | Running Loss 0.0007379619521088899\n",
      "epoch 483 | iter 2415 | Running Loss 0.0007671564817428589\n",
      "epoch 484 | iter 2420 | Running Loss 0.0006910793948918581\n",
      "epoch 485 | iter 2425 | Running Loss 0.0007650628453120589\n",
      "epoch 486 | iter 2430 | Running Loss 0.0009014076087623835\n",
      "epoch 487 | iter 2435 | Running Loss 0.0009800690924748779\n",
      "epoch 488 | iter 2440 | Running Loss 0.0010087432456202805\n",
      "epoch 489 | iter 2445 | Running Loss 0.0017532098921947182\n",
      "epoch 490 | iter 2450 | Running Loss 0.001613774523139\n",
      "epoch 491 | iter 2455 | Running Loss 0.0012993234093300998\n",
      "epoch 492 | iter 2460 | Running Loss 0.001443583599757403\n",
      "epoch 493 | iter 2465 | Running Loss 0.0014690160052850843\n",
      "epoch 494 | iter 2470 | Running Loss 0.002582562912721187\n",
      "epoch 495 | iter 2475 | Running Loss 0.005384905496612191\n",
      "epoch 496 | iter 2480 | Running Loss 0.00602137902751565\n",
      "epoch 497 | iter 2485 | Running Loss 0.0040568737778812645\n",
      "epoch 498 | iter 2490 | Running Loss 0.002738950354978442\n",
      "epoch 499 | iter 2495 | Running Loss 0.0021156673086807133\n"
     ]
    }
   ],
   "source": [
    "train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchNN(\n",
       "  (fc1): Linear(in_features=250, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch_model.state_dict(), \"models/saved_models/basic_nn2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fae084943c8>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch_model.eval()\n",
    "i = random.randint(0, len(X_train))\n",
    "example = X_train[i]\n",
    "example = torch.from_numpy(example.reshape(1, 250, 1)).type('torch.FloatTensor')\n",
    "pred = torch_model(example).detach().numpy()\n",
    "combined = np.concatenate([example[0].numpy(), y_train[i].T], axis=0).squeeze()\n",
    "combined_zeros = np.concatenate([np.zeros_like(example.squeeze()),pred]).squeeze()\n",
    "\n",
    "plt.plot(combined[-100:])\n",
    "plt.plot(combined_zeros[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import History, EarlyStopping, Callback\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "300/300 [==============================] - 0s 1ms/step - loss: 0.2000\n",
      "Epoch 2/500\n",
      "300/300 [==============================] - 0s 53us/step - loss: 0.0834\n",
      "Epoch 3/500\n",
      "300/300 [==============================] - 0s 46us/step - loss: 0.0549\n",
      "Epoch 4/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 0.0436\n",
      "Epoch 5/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 0.0372\n",
      "Epoch 6/500\n",
      "300/300 [==============================] - 0s 53us/step - loss: 0.0329\n",
      "Epoch 7/500\n",
      "300/300 [==============================] - 0s 51us/step - loss: 0.0288\n",
      "Epoch 8/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0284\n",
      "Epoch 9/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0277\n",
      "Epoch 10/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0254\n",
      "Epoch 11/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0232\n",
      "Epoch 12/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0220\n",
      "Epoch 13/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0208\n",
      "Epoch 14/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0199\n",
      "Epoch 15/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0188\n",
      "Epoch 16/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0186\n",
      "Epoch 17/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0187\n",
      "Epoch 18/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0180\n",
      "Epoch 19/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0168\n",
      "Epoch 20/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0182\n",
      "Epoch 21/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0180\n",
      "Epoch 22/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0162\n",
      "Epoch 23/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0163\n",
      "Epoch 24/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0144\n",
      "Epoch 25/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0139\n",
      "Epoch 26/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0152\n",
      "Epoch 27/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0144\n",
      "Epoch 28/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0141\n",
      "Epoch 29/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0135\n",
      "Epoch 30/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0130\n",
      "Epoch 31/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0138\n",
      "Epoch 32/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0120\n",
      "Epoch 33/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0114\n",
      "Epoch 34/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0119\n",
      "Epoch 35/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0115\n",
      "Epoch 36/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0114\n",
      "Epoch 37/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0116\n",
      "Epoch 38/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0129\n",
      "Epoch 39/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0113\n",
      "Epoch 40/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0122\n",
      "Epoch 41/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0107\n",
      "Epoch 42/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0097\n",
      "Epoch 43/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0097\n",
      "Epoch 44/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0106\n",
      "Epoch 45/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0092\n",
      "Epoch 46/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0097\n",
      "Epoch 47/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0108\n",
      "Epoch 48/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0104\n",
      "Epoch 49/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0095\n",
      "Epoch 50/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0091\n",
      "Epoch 51/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0087\n",
      "Epoch 52/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0083\n",
      "Epoch 53/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0080\n",
      "Epoch 54/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0077\n",
      "Epoch 55/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0078\n",
      "Epoch 56/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0080\n",
      "Epoch 57/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0079\n",
      "Epoch 58/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0074\n",
      "Epoch 59/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0079\n",
      "Epoch 60/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0081\n",
      "Epoch 61/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0069\n",
      "Epoch 62/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0065\n",
      "Epoch 63/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 0.0067\n",
      "Epoch 64/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0069\n",
      "Epoch 65/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0065\n",
      "Epoch 66/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0066\n",
      "Epoch 67/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0060\n",
      "Epoch 68/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0057\n",
      "Epoch 69/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0056\n",
      "Epoch 70/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0058\n",
      "Epoch 71/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 0.0057\n",
      "Epoch 72/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0055\n",
      "Epoch 73/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0058\n",
      "Epoch 74/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0061\n",
      "Epoch 75/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0063\n",
      "Epoch 76/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0056\n",
      "Epoch 77/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0053\n",
      "Epoch 78/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0051\n",
      "Epoch 79/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0051\n",
      "Epoch 80/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0048\n",
      "Epoch 81/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0047\n",
      "Epoch 82/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0046\n",
      "Epoch 83/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 0.0046\n",
      "Epoch 84/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0047\n",
      "Epoch 85/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0049\n",
      "Epoch 86/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0047\n",
      "Epoch 87/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0043\n",
      "Epoch 88/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0041\n",
      "Epoch 89/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0042\n",
      "Epoch 90/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0044\n",
      "Epoch 91/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0044\n",
      "Epoch 92/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0046\n",
      "Epoch 93/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0041\n",
      "Epoch 94/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0040\n",
      "Epoch 95/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0039\n",
      "Epoch 96/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0038\n",
      "Epoch 97/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0037\n",
      "Epoch 98/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0037\n",
      "Epoch 99/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0038\n",
      "Epoch 100/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0037\n",
      "Epoch 101/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0040\n",
      "Epoch 102/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0041\n",
      "Epoch 103/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0035\n",
      "Epoch 104/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0034\n",
      "Epoch 105/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0035\n",
      "Epoch 106/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0035\n",
      "Epoch 107/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0037\n",
      "Epoch 108/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0041\n",
      "Epoch 109/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0053\n",
      "Epoch 110/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0053\n",
      "Epoch 111/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0047\n",
      "Epoch 112/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0047\n",
      "Epoch 113/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0037\n",
      "Epoch 114/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0035\n",
      "Epoch 115/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0034\n",
      "Epoch 116/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0033\n",
      "Epoch 117/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0031\n",
      "Epoch 118/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0030\n",
      "Epoch 119/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0031\n",
      "Epoch 120/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0029\n",
      "Epoch 121/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0029\n",
      "Epoch 122/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0028\n",
      "Epoch 123/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0027\n",
      "Epoch 124/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0027\n",
      "Epoch 125/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0027\n",
      "Epoch 126/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 0.0027\n",
      "Epoch 127/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0026\n",
      "Epoch 128/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0027\n",
      "Epoch 129/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0026\n",
      "Epoch 130/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0027\n",
      "Epoch 131/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0030\n",
      "Epoch 132/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0030\n",
      "Epoch 133/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0033\n",
      "Epoch 134/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0034\n",
      "Epoch 135/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0036\n",
      "Epoch 136/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0030\n",
      "Epoch 137/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0029\n",
      "Epoch 138/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0030\n",
      "Epoch 139/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0027\n",
      "Epoch 140/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0025\n",
      "Epoch 141/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0023\n",
      "Epoch 142/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0024\n",
      "Epoch 143/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0026\n",
      "Epoch 144/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0026\n",
      "Epoch 145/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0023\n",
      "Epoch 146/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0022\n",
      "Epoch 147/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0021\n",
      "Epoch 148/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0020\n",
      "Epoch 149/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0021\n",
      "Epoch 150/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0022\n",
      "Epoch 151/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0020\n",
      "Epoch 152/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0021\n",
      "Epoch 153/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0020\n",
      "Epoch 154/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0021\n",
      "Epoch 155/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0023\n",
      "Epoch 156/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0021\n",
      "Epoch 157/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 0.0020\n",
      "Epoch 158/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0019\n",
      "Epoch 159/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0019\n",
      "Epoch 160/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0019\n",
      "Epoch 161/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0019\n",
      "Epoch 162/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0018\n",
      "Epoch 163/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0017\n",
      "Epoch 164/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0019\n",
      "Epoch 165/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0019\n",
      "Epoch 166/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 0.0019\n",
      "Epoch 167/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0019\n",
      "Epoch 168/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0018\n",
      "Epoch 169/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0018\n",
      "Epoch 170/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0017\n",
      "Epoch 171/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0017\n",
      "Epoch 172/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0017\n",
      "Epoch 173/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0016\n",
      "Epoch 174/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0016\n",
      "Epoch 175/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0016\n",
      "Epoch 176/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0016\n",
      "Epoch 177/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0016\n",
      "Epoch 178/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0019\n",
      "Epoch 179/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0020\n",
      "Epoch 180/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0018\n",
      "Epoch 181/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 0.0017\n",
      "Epoch 182/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0019\n",
      "Epoch 183/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0020\n",
      "Epoch 184/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0021\n",
      "Epoch 185/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0019\n",
      "Epoch 186/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0017\n",
      "Epoch 187/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0017\n",
      "Epoch 188/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 0.0017\n",
      "Epoch 189/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0021\n",
      "Epoch 190/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0020\n",
      "Epoch 191/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0020\n",
      "Epoch 192/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0017\n",
      "Epoch 193/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0015\n",
      "Epoch 194/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0015\n",
      "Epoch 195/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0015\n",
      "Epoch 196/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0016\n",
      "Epoch 197/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0014\n",
      "Epoch 198/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0014\n",
      "Epoch 199/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0014\n",
      "Epoch 200/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0017\n",
      "Epoch 201/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0015\n",
      "Epoch 202/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0013\n",
      "Epoch 203/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0012\n",
      "Epoch 204/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0012\n",
      "Epoch 205/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0012\n",
      "Epoch 206/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0013\n",
      "Epoch 207/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0012\n",
      "Epoch 208/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0013\n",
      "Epoch 209/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0012\n",
      "Epoch 210/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0012\n",
      "Epoch 211/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0012\n",
      "Epoch 212/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0011\n",
      "Epoch 213/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0011\n",
      "Epoch 214/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0011\n",
      "Epoch 215/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0010\n",
      "Epoch 216/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0011\n",
      "Epoch 217/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0011\n",
      "Epoch 218/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0010\n",
      "Epoch 219/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0011\n",
      "Epoch 220/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0010\n",
      "Epoch 221/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 9.8854e-04\n",
      "Epoch 222/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0010\n",
      "Epoch 223/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 9.6197e-04\n",
      "Epoch 224/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 9.5428e-04\n",
      "Epoch 225/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 9.5601e-04\n",
      "Epoch 226/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 9.3620e-04\n",
      "Epoch 227/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 9.2469e-04\n",
      "Epoch 228/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 9.1807e-04\n",
      "Epoch 229/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 9.1453e-04\n",
      "Epoch 230/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 9.8905e-04\n",
      "Epoch 231/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0012\n",
      "Epoch 232/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0012\n",
      "Epoch 233/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0012\n",
      "Epoch 234/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0011\n",
      "Epoch 235/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0010\n",
      "Epoch 236/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0011\n",
      "Epoch 237/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0011\n",
      "Epoch 238/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0010\n",
      "Epoch 239/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0013\n",
      "Epoch 240/500\n",
      "300/300 [==============================] - 0s 69us/step - loss: 0.0014\n",
      "Epoch 241/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0025\n",
      "Epoch 242/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0018\n",
      "Epoch 243/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0017\n",
      "Epoch 244/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0014\n",
      "Epoch 245/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0013\n",
      "Epoch 246/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0014\n",
      "Epoch 247/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0011\n",
      "Epoch 248/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0010\n",
      "Epoch 249/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0014\n",
      "Epoch 250/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0012\n",
      "Epoch 251/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0015\n",
      "Epoch 252/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0011\n",
      "Epoch 253/500\n",
      "300/300 [==============================] - 0s 69us/step - loss: 0.0011\n",
      "Epoch 254/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0011\n",
      "Epoch 255/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 8.9960e-04\n",
      "Epoch 256/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 8.2757e-04\n",
      "Epoch 257/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 7.7759e-04\n",
      "Epoch 258/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 8.2718e-04\n",
      "Epoch 259/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 8.2149e-04\n",
      "Epoch 260/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 9.5639e-04\n",
      "Epoch 261/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 8.7548e-04\n",
      "Epoch 262/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 8.6739e-04\n",
      "Epoch 263/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 8.1839e-04\n",
      "Epoch 264/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 8.4891e-04\n",
      "Epoch 265/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 8.1245e-04\n",
      "Epoch 266/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 7.7323e-04\n",
      "Epoch 267/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 7.0284e-04\n",
      "Epoch 268/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.8061e-04\n",
      "Epoch 269/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.7166e-04\n",
      "Epoch 270/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.9065e-04\n",
      "Epoch 271/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.8458e-04\n",
      "Epoch 272/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.6996e-04\n",
      "Epoch 273/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 7.0589e-04\n",
      "Epoch 274/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 7.4492e-04\n",
      "Epoch 275/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 7.9312e-04\n",
      "Epoch 276/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 7.5475e-04\n",
      "Epoch 277/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 6.9443e-04\n",
      "Epoch 278/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.5869e-04\n",
      "Epoch 279/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 6.2021e-04\n",
      "Epoch 280/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 6.1994e-04\n",
      "Epoch 281/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.5169e-04\n",
      "Epoch 282/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 6.1774e-04\n",
      "Epoch 283/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 6.2763e-04\n",
      "Epoch 284/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.5361e-04\n",
      "Epoch 285/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 8.2783e-04\n",
      "Epoch 286/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.7199e-04\n",
      "Epoch 287/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 7.0157e-04\n",
      "Epoch 288/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 6.3247e-04\n",
      "Epoch 289/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 6.2552e-04\n",
      "Epoch 290/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 6.5492e-04\n",
      "Epoch 291/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 6.9862e-04\n",
      "Epoch 292/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 7.4952e-04\n",
      "Epoch 293/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0010\n",
      "Epoch 294/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0014\n",
      "Epoch 295/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0013\n",
      "Epoch 296/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 8.7718e-04\n",
      "Epoch 297/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0013\n",
      "Epoch 298/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0013\n",
      "Epoch 299/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0012\n",
      "Epoch 300/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0021\n",
      "Epoch 301/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0012\n",
      "Epoch 302/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0015\n",
      "Epoch 303/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0010\n",
      "Epoch 304/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0013\n",
      "Epoch 305/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0013\n",
      "Epoch 306/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0014\n",
      "Epoch 307/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0013\n",
      "Epoch 308/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 0.0012\n",
      "Epoch 309/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0011\n",
      "Epoch 310/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0011\n",
      "Epoch 311/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 0.0011\n",
      "Epoch 312/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 7.5213e-04\n",
      "Epoch 313/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 6.6295e-04\n",
      "Epoch 314/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 7.2799e-04\n",
      "Epoch 315/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 5.5705e-04\n",
      "Epoch 316/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 5.5436e-04\n",
      "Epoch 317/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.0323e-04\n",
      "Epoch 318/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 5.7206e-04\n",
      "Epoch 319/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.1734e-04\n",
      "Epoch 320/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.1567e-04\n",
      "Epoch 321/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 6.8169e-04\n",
      "Epoch 322/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 7.8077e-04\n",
      "Epoch 323/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0012\n",
      "Epoch 324/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 0.0013\n",
      "Epoch 325/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 0.0012\n",
      "Epoch 326/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 8.9771e-04\n",
      "Epoch 327/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 7.3971e-04\n",
      "Epoch 328/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 7.0295e-04\n",
      "Epoch 329/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 6.0734e-04\n",
      "Epoch 330/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 5.2340e-04\n",
      "Epoch 331/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 5.3707e-04\n",
      "Epoch 332/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 6.0872e-04\n",
      "Epoch 333/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 5.3891e-04\n",
      "Epoch 334/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.4239e-04\n",
      "Epoch 335/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 4.2914e-04\n",
      "Epoch 336/500\n",
      "300/300 [==============================] - 0s 69us/step - loss: 4.3002e-04\n",
      "Epoch 337/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.4017e-04\n",
      "Epoch 338/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 4.3267e-04\n",
      "Epoch 339/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 4.1432e-04\n",
      "Epoch 340/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.9333e-04\n",
      "Epoch 341/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 4.2111e-04\n",
      "Epoch 342/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 4.1195e-04\n",
      "Epoch 343/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.9329e-04\n",
      "Epoch 344/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.7022e-04\n",
      "Epoch 345/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.6543e-04\n",
      "Epoch 346/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.6775e-04\n",
      "Epoch 347/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 3.5737e-04\n",
      "Epoch 348/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.4012e-04\n",
      "Epoch 349/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 3.5195e-04\n",
      "Epoch 350/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.3376e-04\n",
      "Epoch 351/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.4349e-04\n",
      "Epoch 352/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.2700e-04\n",
      "Epoch 353/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.2523e-04\n",
      "Epoch 354/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.2300e-04\n",
      "Epoch 355/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.1531e-04\n",
      "Epoch 356/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.2440e-04\n",
      "Epoch 357/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 3.2232e-04\n",
      "Epoch 358/500\n",
      "300/300 [==============================] - 0s 54us/step - loss: 3.1581e-04\n",
      "Epoch 359/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.1298e-04\n",
      "Epoch 360/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.0690e-04\n",
      "Epoch 361/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.0146e-04\n",
      "Epoch 362/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.1440e-04\n",
      "Epoch 363/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 3.2137e-04\n",
      "Epoch 364/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.2610e-04\n",
      "Epoch 365/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.1957e-04\n",
      "Epoch 366/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.2572e-04\n",
      "Epoch 367/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.1140e-04\n",
      "Epoch 368/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 2.8960e-04\n",
      "Epoch 369/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 2.8044e-04\n",
      "Epoch 370/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 2.9260e-04\n",
      "Epoch 371/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.0242e-04\n",
      "Epoch 372/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.3933e-04\n",
      "Epoch 373/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 4.3485e-04\n",
      "Epoch 374/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 3.3996e-04\n",
      "Epoch 375/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.1782e-04\n",
      "Epoch 376/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.4060e-04\n",
      "Epoch 377/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 4.1922e-04\n",
      "Epoch 378/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 6.2098e-04\n",
      "Epoch 379/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 6.8620e-04\n",
      "Epoch 380/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0010\n",
      "Epoch 381/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 8.7049e-04\n",
      "Epoch 382/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 0.0015\n",
      "Epoch 383/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 0.0013\n",
      "Epoch 384/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 9.9796e-04\n",
      "Epoch 385/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 6.7679e-04\n",
      "Epoch 386/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 5.6052e-04\n",
      "Epoch 387/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 6.6079e-04\n",
      "Epoch 388/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 6.8647e-04\n",
      "Epoch 389/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 7.5981e-04\n",
      "Epoch 390/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 5.3665e-04\n",
      "Epoch 391/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 4.2563e-04\n",
      "Epoch 392/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 4.2684e-04\n",
      "Epoch 393/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 3.7501e-04\n",
      "Epoch 394/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 4.8691e-04\n",
      "Epoch 395/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 4.2098e-04\n",
      "Epoch 396/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 4.1137e-04\n",
      "Epoch 397/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.9412e-04\n",
      "Epoch 398/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 3.1651e-04\n",
      "Epoch 399/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 3.5157e-04\n",
      "Epoch 400/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 4.3357e-04\n",
      "Epoch 401/500\n",
      "300/300 [==============================] - 0s 55us/step - loss: 3.7344e-04\n",
      "Epoch 402/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 2.9026e-04\n",
      "Epoch 403/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 2.7947e-04\n",
      "Epoch 404/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.7274e-04\n",
      "Epoch 405/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.9416e-04\n",
      "Epoch 406/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 2.7101e-04\n",
      "Epoch 407/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.7844e-04\n",
      "Epoch 408/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.9517e-04\n",
      "Epoch 409/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.1686e-04\n",
      "Epoch 410/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 3.5036e-04\n",
      "Epoch 411/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.8329e-04\n",
      "Epoch 412/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 3.5867e-04\n",
      "Epoch 413/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.0295e-04\n",
      "Epoch 414/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 2.7554e-04\n",
      "Epoch 415/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.0827e-04\n",
      "Epoch 416/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.9431e-04\n",
      "Epoch 417/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 3.9472e-04\n",
      "Epoch 418/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.1269e-04\n",
      "Epoch 419/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 2.6630e-04\n",
      "Epoch 420/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.7094e-04\n",
      "Epoch 421/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 5.8358e-04\n",
      "Epoch 422/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0012\n",
      "Epoch 423/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 7.0062e-04\n",
      "Epoch 424/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 5.4865e-04\n",
      "Epoch 425/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 4.6204e-04\n",
      "Epoch 426/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 4.9764e-04\n",
      "Epoch 427/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 4.7248e-04\n",
      "Epoch 428/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.4995e-04\n",
      "Epoch 429/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.2342e-04\n",
      "Epoch 430/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 2.8049e-04\n",
      "Epoch 431/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 2.7487e-04\n",
      "Epoch 432/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.0312e-04\n",
      "Epoch 433/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 2.7196e-04\n",
      "Epoch 434/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 2.8377e-04\n",
      "Epoch 435/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 2.5673e-04\n",
      "Epoch 436/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 2.9751e-04\n",
      "Epoch 437/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.5915e-04\n",
      "Epoch 438/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 3.3632e-04\n",
      "Epoch 439/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.6785e-04\n",
      "Epoch 440/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.8030e-04\n",
      "Epoch 441/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.6743e-04\n",
      "Epoch 442/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.3086e-04\n",
      "Epoch 443/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.0655e-04\n",
      "Epoch 444/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.6371e-04\n",
      "Epoch 445/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 2.8218e-04\n",
      "Epoch 446/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 2.8287e-04\n",
      "Epoch 447/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.0843e-04\n",
      "Epoch 448/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 3.1933e-04\n",
      "Epoch 449/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.5360e-04\n",
      "Epoch 450/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.1709e-04\n",
      "Epoch 451/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 2.1323e-04\n",
      "Epoch 452/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 2.0654e-04\n",
      "Epoch 453/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 2.1172e-04\n",
      "Epoch 454/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.1393e-04\n",
      "Epoch 455/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 2.5815e-04\n",
      "Epoch 456/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 2.1186e-04\n",
      "Epoch 457/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 1.8920e-04\n",
      "Epoch 458/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 1.7625e-04\n",
      "Epoch 459/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 1.8464e-04\n",
      "Epoch 460/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 1.9198e-04\n",
      "Epoch 461/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 1.8019e-04\n",
      "Epoch 462/500\n",
      "300/300 [==============================] - 0s 67us/step - loss: 1.6733e-04\n",
      "Epoch 463/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 1.6206e-04\n",
      "Epoch 464/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 1.5913e-04\n",
      "Epoch 465/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 1.7953e-04\n",
      "Epoch 466/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 1.7805e-04\n",
      "Epoch 467/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 2.1140e-04\n",
      "Epoch 468/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.1753e-04\n",
      "Epoch 469/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 1.8734e-04\n",
      "Epoch 470/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 1.7165e-04\n",
      "Epoch 471/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 1.6651e-04\n",
      "Epoch 472/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 1.7416e-04\n",
      "Epoch 473/500\n",
      "300/300 [==============================] - 0s 56us/step - loss: 1.7792e-04\n",
      "Epoch 474/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 1.5752e-04\n",
      "Epoch 475/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 1.5434e-04\n",
      "Epoch 476/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 1.5675e-04\n",
      "Epoch 477/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 1.9927e-04\n",
      "Epoch 478/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 1.7699e-04\n",
      "Epoch 479/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 1.9923e-04\n",
      "Epoch 480/500\n",
      "300/300 [==============================] - 0s 64us/step - loss: 3.3232e-04\n",
      "Epoch 481/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.4650e-04\n",
      "Epoch 482/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 3.4476e-04\n",
      "Epoch 483/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 3.9772e-04\n",
      "Epoch 484/500\n",
      "300/300 [==============================] - 0s 62us/step - loss: 3.1857e-04\n",
      "Epoch 485/500\n",
      "300/300 [==============================] - 0s 65us/step - loss: 3.0799e-04\n",
      "Epoch 486/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 2.9433e-04\n",
      "Epoch 487/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 5.4742e-04\n",
      "Epoch 488/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 3.9879e-04\n",
      "Epoch 489/500\n",
      "300/300 [==============================] - 0s 63us/step - loss: 4.6134e-04\n",
      "Epoch 490/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 7.8998e-04\n",
      "Epoch 491/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0015\n",
      "Epoch 492/500\n",
      "300/300 [==============================] - 0s 58us/step - loss: 0.0011\n",
      "Epoch 493/500\n",
      "300/300 [==============================] - 0s 60us/step - loss: 9.0776e-04\n",
      "Epoch 494/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0012\n",
      "Epoch 495/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0046\n",
      "Epoch 496/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0065\n",
      "Epoch 497/500\n",
      "300/300 [==============================] - 0s 57us/step - loss: 0.0074\n",
      "Epoch 498/500\n",
      "300/300 [==============================] - 0s 61us/step - loss: 0.0061\n",
      "Epoch 499/500\n",
      "300/300 [==============================] - 0s 59us/step - loss: 0.0054\n",
      "Epoch 500/500\n",
      "300/300 [==============================] - 0s 66us/step - loss: 0.0050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fade1cf9be0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model = Sequential()\n",
    "nn_model.add(Dense(\n",
    "    256,\n",
    "    input_shape=(None, 250)\n",
    "))\n",
    "nn_model.add(Activation('relu'))\n",
    "nn_model.add(Dense(128))\n",
    "nn_model.add(Activation('relu'))\n",
    "nn_model.add(Dense(64))\n",
    "nn_model.add(Activation('relu'))\n",
    "nn_model.add(Dense(10))\n",
    "\n",
    "nn_model.compile(loss='mse',\n",
    "               optimizer='adam')\n",
    "nn_model.fit(X_train, y_train, batch_size=64, epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 240 samples, validate on 60 samples\n",
      "Epoch 1/500\n",
      "240/240 [==============================] - 1s 4ms/step - loss: 0.2812 - val_loss: 0.2214\n",
      "Epoch 2/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 0.2119 - val_loss: 0.1494\n",
      "Epoch 3/500\n",
      "240/240 [==============================] - 0s 87us/step - loss: 0.1452 - val_loss: 0.0956\n",
      "Epoch 4/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 0.1116 - val_loss: 0.0907\n",
      "Epoch 5/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 0.1051 - val_loss: 0.0861\n",
      "Epoch 6/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0994 - val_loss: 0.0788\n",
      "Epoch 7/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0906 - val_loss: 0.0770\n",
      "Epoch 8/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0887 - val_loss: 0.0730\n",
      "Epoch 9/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0862 - val_loss: 0.0667\n",
      "Epoch 10/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 0.0804 - val_loss: 0.0610\n",
      "Epoch 11/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 0.0729 - val_loss: 0.0554\n",
      "Epoch 12/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 0.0689 - val_loss: 0.0499\n",
      "Epoch 13/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 0.0633 - val_loss: 0.0462\n",
      "Epoch 14/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0557 - val_loss: 0.0443\n",
      "Epoch 15/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 0.0537 - val_loss: 0.0447\n",
      "Epoch 16/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 0.0528 - val_loss: 0.0449\n",
      "Epoch 17/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0503 - val_loss: 0.0421\n",
      "Epoch 18/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0493 - val_loss: 0.0395\n",
      "Epoch 19/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0437 - val_loss: 0.0381\n",
      "Epoch 20/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 0.0458 - val_loss: 0.0357\n",
      "Epoch 21/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0424 - val_loss: 0.0343\n",
      "Epoch 22/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0422 - val_loss: 0.0328\n",
      "Epoch 23/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0401 - val_loss: 0.0316\n",
      "Epoch 24/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0409 - val_loss: 0.0305\n",
      "Epoch 25/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0351 - val_loss: 0.0293\n",
      "Epoch 26/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0378 - val_loss: 0.0284\n",
      "Epoch 27/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0375 - val_loss: 0.0275\n",
      "Epoch 28/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0370 - val_loss: 0.0270\n",
      "Epoch 29/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0379 - val_loss: 0.0273\n",
      "Epoch 30/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0345 - val_loss: 0.0267\n",
      "Epoch 31/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0358 - val_loss: 0.0278\n",
      "Epoch 32/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0342 - val_loss: 0.0249\n",
      "Epoch 33/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0336 - val_loss: 0.0249\n",
      "Epoch 34/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0334 - val_loss: 0.0250\n",
      "Epoch 35/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0333 - val_loss: 0.0248\n",
      "Epoch 36/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0310 - val_loss: 0.0260\n",
      "Epoch 37/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0323 - val_loss: 0.0247\n",
      "Epoch 38/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0308 - val_loss: 0.0241\n",
      "Epoch 39/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0304 - val_loss: 0.0235\n",
      "Epoch 40/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0297 - val_loss: 0.0237\n",
      "Epoch 41/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0307 - val_loss: 0.0229\n",
      "Epoch 42/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0308 - val_loss: 0.0227\n",
      "Epoch 43/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0319 - val_loss: 0.0234\n",
      "Epoch 44/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0290 - val_loss: 0.0227\n",
      "Epoch 45/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0299 - val_loss: 0.0225\n",
      "Epoch 46/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0298 - val_loss: 0.0227\n",
      "Epoch 47/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0306 - val_loss: 0.0215\n",
      "Epoch 48/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0311 - val_loss: 0.0247\n",
      "Epoch 49/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0299 - val_loss: 0.0231\n",
      "Epoch 50/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0293 - val_loss: 0.0258\n",
      "Epoch 51/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0291 - val_loss: 0.0215\n",
      "Epoch 52/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0277 - val_loss: 0.0214\n",
      "Epoch 53/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0265 - val_loss: 0.0253\n",
      "Epoch 54/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0254 - val_loss: 0.0213\n",
      "Epoch 55/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0260 - val_loss: 0.0232\n",
      "Epoch 56/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0258 - val_loss: 0.0214\n",
      "Epoch 57/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0259 - val_loss: 0.0221\n",
      "Epoch 58/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0270 - val_loss: 0.0217\n",
      "Epoch 59/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0262 - val_loss: 0.0218\n",
      "Epoch 60/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0251 - val_loss: 0.0225\n",
      "Epoch 61/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0241 - val_loss: 0.0212\n",
      "Epoch 62/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0237 - val_loss: 0.0208\n",
      "Epoch 63/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0245 - val_loss: 0.0228\n",
      "Epoch 64/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0246 - val_loss: 0.0201\n",
      "Epoch 65/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0231 - val_loss: 0.0207\n",
      "Epoch 66/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0250 - val_loss: 0.0202\n",
      "Epoch 67/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0243 - val_loss: 0.0216\n",
      "Epoch 68/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0233 - val_loss: 0.0205\n",
      "Epoch 69/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0222 - val_loss: 0.0216\n",
      "Epoch 70/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0231 - val_loss: 0.0201\n",
      "Epoch 71/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0230 - val_loss: 0.0214\n",
      "Epoch 72/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0226 - val_loss: 0.0200\n",
      "Epoch 73/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0232 - val_loss: 0.0225\n",
      "Epoch 74/500\n",
      "240/240 [==============================] - 0s 124us/step - loss: 0.0250 - val_loss: 0.0202\n",
      "Epoch 75/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0243 - val_loss: 0.0207\n",
      "Epoch 76/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0241 - val_loss: 0.0242\n",
      "Epoch 77/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0248 - val_loss: 0.0203\n",
      "Epoch 78/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0252 - val_loss: 0.0215\n",
      "Epoch 79/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 0.0251 - val_loss: 0.0216\n",
      "Epoch 80/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 0.0234 - val_loss: 0.0199\n",
      "Epoch 81/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0228 - val_loss: 0.0241\n",
      "Epoch 82/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0220 - val_loss: 0.0198\n",
      "Epoch 83/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0212 - val_loss: 0.0241\n",
      "Epoch 84/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0228 - val_loss: 0.0199\n",
      "Epoch 85/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0222 - val_loss: 0.0218\n",
      "Epoch 86/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0217 - val_loss: 0.0204\n",
      "Epoch 87/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0205 - val_loss: 0.0211\n",
      "Epoch 88/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 89/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0210 - val_loss: 0.0201\n",
      "Epoch 90/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0215 - val_loss: 0.0214\n",
      "Epoch 91/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0209 - val_loss: 0.0205\n",
      "Epoch 92/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0211 - val_loss: 0.0200\n",
      "Epoch 93/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0210 - val_loss: 0.0209\n",
      "Epoch 94/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0224 - val_loss: 0.0192\n",
      "Epoch 95/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0217 - val_loss: 0.0208\n",
      "Epoch 96/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0199 - val_loss: 0.0196\n",
      "Epoch 97/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0198 - val_loss: 0.0198\n",
      "Epoch 98/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0204 - val_loss: 0.0212\n",
      "Epoch 99/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0183 - val_loss: 0.0192\n",
      "Epoch 100/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0210 - val_loss: 0.0223\n",
      "Epoch 101/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0196 - val_loss: 0.0196\n",
      "Epoch 102/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0194 - val_loss: 0.0241\n",
      "Epoch 103/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0201 - val_loss: 0.0197\n",
      "Epoch 104/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0203 - val_loss: 0.0208\n",
      "Epoch 105/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0201 - val_loss: 0.0215\n",
      "Epoch 106/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0211 - val_loss: 0.0198\n",
      "Epoch 107/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0222 - val_loss: 0.0233\n",
      "Epoch 108/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 109/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0199 - val_loss: 0.0217\n",
      "Epoch 110/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0191 - val_loss: 0.0199\n",
      "Epoch 111/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0206 - val_loss: 0.0207\n",
      "Epoch 112/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0188 - val_loss: 0.0198\n",
      "Epoch 113/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 114/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0189 - val_loss: 0.0194\n",
      "Epoch 115/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 116/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 117/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0195 - val_loss: 0.0201\n",
      "Epoch 118/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0176 - val_loss: 0.0213\n",
      "Epoch 119/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 0.0181 - val_loss: 0.0198\n",
      "Epoch 120/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0189 - val_loss: 0.0208\n",
      "Epoch 121/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0175 - val_loss: 0.0207\n",
      "Epoch 122/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0183 - val_loss: 0.0191\n",
      "Epoch 123/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0195 - val_loss: 0.0222\n",
      "Epoch 124/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0187 - val_loss: 0.0193\n",
      "Epoch 125/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0197 - val_loss: 0.0220\n",
      "Epoch 126/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0187 - val_loss: 0.0197\n",
      "Epoch 127/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0190 - val_loss: 0.0221\n",
      "Epoch 128/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0179 - val_loss: 0.0194\n",
      "Epoch 129/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0189 - val_loss: 0.0225\n",
      "Epoch 130/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0179 - val_loss: 0.0192\n",
      "Epoch 131/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0181 - val_loss: 0.0213\n",
      "Epoch 132/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0170 - val_loss: 0.0190\n",
      "Epoch 133/500\n",
      "240/240 [==============================] - 0s 118us/step - loss: 0.0171 - val_loss: 0.0208\n",
      "Epoch 134/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0169 - val_loss: 0.0194\n",
      "Epoch 135/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0175 - val_loss: 0.0211\n",
      "Epoch 136/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0168 - val_loss: 0.0214\n",
      "Epoch 137/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0163 - val_loss: 0.0205\n",
      "Epoch 138/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0174 - val_loss: 0.0202\n",
      "Epoch 139/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0165 - val_loss: 0.0223\n",
      "Epoch 140/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0160 - val_loss: 0.0204\n",
      "Epoch 141/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0169 - val_loss: 0.0210\n",
      "Epoch 142/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0166 - val_loss: 0.0204\n",
      "Epoch 143/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0175 - val_loss: 0.0211\n",
      "Epoch 144/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0176 - val_loss: 0.0213\n",
      "Epoch 145/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 0.0167 - val_loss: 0.0190\n",
      "Epoch 146/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0167 - val_loss: 0.0218\n",
      "Epoch 147/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0161 - val_loss: 0.0192\n",
      "Epoch 148/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0175 - val_loss: 0.0252\n",
      "Epoch 149/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0173 - val_loss: 0.0191\n",
      "Epoch 150/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0155 - val_loss: 0.0220\n",
      "Epoch 151/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0164 - val_loss: 0.0192\n",
      "Epoch 152/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0155 - val_loss: 0.0205\n",
      "Epoch 153/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0160 - val_loss: 0.0220\n",
      "Epoch 154/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0172 - val_loss: 0.0195\n",
      "Epoch 155/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0169 - val_loss: 0.0222\n",
      "Epoch 156/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0163 - val_loss: 0.0196\n",
      "Epoch 157/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0150 - val_loss: 0.0229\n",
      "Epoch 158/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 159/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0162 - val_loss: 0.0213\n",
      "Epoch 160/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 161/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0156 - val_loss: 0.0216\n",
      "Epoch 162/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0164 - val_loss: 0.0207\n",
      "Epoch 163/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 0.0158 - val_loss: 0.0205\n",
      "Epoch 164/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0145 - val_loss: 0.0205\n",
      "Epoch 165/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 0.0142 - val_loss: 0.0204\n",
      "Epoch 166/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0158 - val_loss: 0.0215\n",
      "Epoch 167/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0140 - val_loss: 0.0197\n",
      "Epoch 168/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0139 - val_loss: 0.0242\n",
      "Epoch 169/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0149 - val_loss: 0.0202\n",
      "Epoch 170/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 171/500\n",
      "240/240 [==============================] - 0s 92us/step - loss: 0.0158 - val_loss: 0.0214\n",
      "Epoch 172/500\n",
      "240/240 [==============================] - 0s 86us/step - loss: 0.0151 - val_loss: 0.0200\n",
      "Epoch 173/500\n",
      "240/240 [==============================] - 0s 87us/step - loss: 0.0145 - val_loss: 0.0222\n",
      "Epoch 174/500\n",
      "240/240 [==============================] - 0s 88us/step - loss: 0.0155 - val_loss: 0.0215\n",
      "Epoch 175/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 0.0145 - val_loss: 0.0197\n",
      "Epoch 176/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 0.0147 - val_loss: 0.0210\n",
      "Epoch 177/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 0.0157 - val_loss: 0.0209\n",
      "Epoch 178/500\n",
      "240/240 [==============================] - 0s 88us/step - loss: 0.0141 - val_loss: 0.0212\n",
      "Epoch 179/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 0.0135 - val_loss: 0.0201\n",
      "Epoch 180/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 0.0153 - val_loss: 0.0205\n",
      "Epoch 181/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 0.0148 - val_loss: 0.0230\n",
      "Epoch 182/500\n",
      "240/240 [==============================] - 0s 92us/step - loss: 0.0157 - val_loss: 0.0195\n",
      "Epoch 183/500\n",
      "240/240 [==============================] - 0s 90us/step - loss: 0.0159 - val_loss: 0.0241\n",
      "Epoch 184/500\n",
      "240/240 [==============================] - 0s 95us/step - loss: 0.0157 - val_loss: 0.0193\n",
      "Epoch 185/500\n",
      "240/240 [==============================] - 0s 89us/step - loss: 0.0149 - val_loss: 0.0232\n",
      "Epoch 186/500\n",
      "240/240 [==============================] - 0s 90us/step - loss: 0.0143 - val_loss: 0.0191\n",
      "Epoch 187/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 0.0145 - val_loss: 0.0209\n",
      "Epoch 188/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 0.0153 - val_loss: 0.0215\n",
      "Epoch 189/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0144 - val_loss: 0.0194\n",
      "Epoch 190/500\n",
      "240/240 [==============================] - 0s 98us/step - loss: 0.0135 - val_loss: 0.0215\n",
      "Epoch 191/500\n",
      "240/240 [==============================] - 0s 89us/step - loss: 0.0145 - val_loss: 0.0199\n",
      "Epoch 192/500\n",
      "240/240 [==============================] - 0s 92us/step - loss: 0.0145 - val_loss: 0.0216\n",
      "Epoch 193/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 0.0142 - val_loss: 0.0211\n",
      "Epoch 194/500\n",
      "240/240 [==============================] - 0s 94us/step - loss: 0.0132 - val_loss: 0.0197\n",
      "Epoch 195/500\n",
      "240/240 [==============================] - 0s 85us/step - loss: 0.0143 - val_loss: 0.0209\n",
      "Epoch 196/500\n",
      "240/240 [==============================] - 0s 93us/step - loss: 0.0145 - val_loss: 0.0222\n",
      "Epoch 197/500\n",
      "240/240 [==============================] - 0s 97us/step - loss: 0.0135 - val_loss: 0.0194\n",
      "Epoch 198/500\n",
      "240/240 [==============================] - 0s 96us/step - loss: 0.0147 - val_loss: 0.0231\n",
      "Epoch 199/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0140 - val_loss: 0.0207\n",
      "Epoch 200/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0139 - val_loss: 0.0202\n",
      "Epoch 201/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0145 - val_loss: 0.0229\n",
      "Epoch 202/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0140 - val_loss: 0.0195\n",
      "Epoch 203/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 0.0155 - val_loss: 0.0236\n",
      "Epoch 204/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0128 - val_loss: 0.0199\n",
      "Epoch 205/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0137 - val_loss: 0.0226\n",
      "Epoch 206/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0150 - val_loss: 0.0215\n",
      "Epoch 207/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0145 - val_loss: 0.0201\n",
      "Epoch 208/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0143 - val_loss: 0.0238\n",
      "Epoch 209/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0149 - val_loss: 0.0199\n",
      "Epoch 210/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0149 - val_loss: 0.0246\n",
      "Epoch 211/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0133 - val_loss: 0.0207\n",
      "Epoch 212/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0147 - val_loss: 0.0209\n",
      "Epoch 213/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0126 - val_loss: 0.0216\n",
      "Epoch 214/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0130 - val_loss: 0.0209\n",
      "Epoch 215/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0143 - val_loss: 0.0250\n",
      "Epoch 216/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0132 - val_loss: 0.0209\n",
      "Epoch 217/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0128 - val_loss: 0.0231\n",
      "Epoch 218/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0123 - val_loss: 0.0209\n",
      "Epoch 219/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0123 - val_loss: 0.0224\n",
      "Epoch 220/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0136 - val_loss: 0.0214\n",
      "Epoch 221/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0140 - val_loss: 0.0239\n",
      "Epoch 222/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0128 - val_loss: 0.0215\n",
      "Epoch 223/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0133 - val_loss: 0.0204\n",
      "Epoch 224/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0126 - val_loss: 0.0211\n",
      "Epoch 225/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0141 - val_loss: 0.0209\n",
      "Epoch 226/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0122 - val_loss: 0.0225\n",
      "Epoch 227/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0137 - val_loss: 0.0222\n",
      "Epoch 228/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0129 - val_loss: 0.0215\n",
      "Epoch 229/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0134 - val_loss: 0.0221\n",
      "Epoch 230/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 0.0118 - val_loss: 0.0214\n",
      "Epoch 231/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0140 - val_loss: 0.0214\n",
      "Epoch 232/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0126 - val_loss: 0.0217\n",
      "Epoch 233/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 0.0116 - val_loss: 0.0230\n",
      "Epoch 234/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0119 - val_loss: 0.0223\n",
      "Epoch 235/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0140 - val_loss: 0.0236\n",
      "Epoch 236/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0127 - val_loss: 0.0227\n",
      "Epoch 237/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0124 - val_loss: 0.0212\n",
      "Epoch 238/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0130 - val_loss: 0.0243\n",
      "Epoch 239/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0124 - val_loss: 0.0206\n",
      "Epoch 240/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0136 - val_loss: 0.0265\n",
      "Epoch 241/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0131 - val_loss: 0.0206\n",
      "Epoch 242/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0140 - val_loss: 0.0206\n",
      "Epoch 243/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0129 - val_loss: 0.0230\n",
      "Epoch 244/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0138 - val_loss: 0.0205\n",
      "Epoch 245/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0143 - val_loss: 0.0240\n",
      "Epoch 246/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0116 - val_loss: 0.0205\n",
      "Epoch 247/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0128 - val_loss: 0.0210\n",
      "Epoch 248/500\n",
      "240/240 [==============================] - 0s 132us/step - loss: 0.0113 - val_loss: 0.0228\n",
      "Epoch 249/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0124 - val_loss: 0.0219\n",
      "Epoch 250/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0125 - val_loss: 0.0234\n",
      "Epoch 251/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0120 - val_loss: 0.0220\n",
      "Epoch 252/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0118 - val_loss: 0.0218\n",
      "Epoch 253/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0115 - val_loss: 0.0240\n",
      "Epoch 254/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0130 - val_loss: 0.0213\n",
      "Epoch 255/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0135 - val_loss: 0.0248\n",
      "Epoch 256/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0132 - val_loss: 0.0211\n",
      "Epoch 257/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0140 - val_loss: 0.0209\n",
      "Epoch 258/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0123 - val_loss: 0.0221\n",
      "Epoch 259/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0118 - val_loss: 0.0225\n",
      "Epoch 260/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0117 - val_loss: 0.0210\n",
      "Epoch 261/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0134 - val_loss: 0.0253\n",
      "Epoch 262/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0137 - val_loss: 0.0211\n",
      "Epoch 263/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0119 - val_loss: 0.0236\n",
      "Epoch 264/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0124 - val_loss: 0.0231\n",
      "Epoch 265/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0124 - val_loss: 0.0216\n",
      "Epoch 266/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0120 - val_loss: 0.0275\n",
      "Epoch 267/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0124 - val_loss: 0.0223\n",
      "Epoch 268/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0122 - val_loss: 0.0242\n",
      "Epoch 269/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0112 - val_loss: 0.0226\n",
      "Epoch 270/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0116 - val_loss: 0.0245\n",
      "Epoch 271/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0127 - val_loss: 0.0232\n",
      "Epoch 272/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0110 - val_loss: 0.0229\n",
      "Epoch 273/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0118 - val_loss: 0.0247\n",
      "Epoch 274/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0121 - val_loss: 0.0216\n",
      "Epoch 275/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0112 - val_loss: 0.0245\n",
      "Epoch 276/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0124 - val_loss: 0.0237\n",
      "Epoch 277/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0123 - val_loss: 0.0224\n",
      "Epoch 278/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0127 - val_loss: 0.0253\n",
      "Epoch 279/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0113 - val_loss: 0.0222\n",
      "Epoch 280/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0114 - val_loss: 0.0230\n",
      "Epoch 281/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0108 - val_loss: 0.0249\n",
      "Epoch 282/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0105 - val_loss: 0.0234\n",
      "Epoch 283/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0108 - val_loss: 0.0251\n",
      "Epoch 284/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0105 - val_loss: 0.0227\n",
      "Epoch 285/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0129 - val_loss: 0.0245\n",
      "Epoch 286/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0121 - val_loss: 0.0227\n",
      "Epoch 287/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0110 - val_loss: 0.0264\n",
      "Epoch 288/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0118 - val_loss: 0.0239\n",
      "Epoch 289/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0108 - val_loss: 0.0236\n",
      "Epoch 290/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0115 - val_loss: 0.0274\n",
      "Epoch 291/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0119 - val_loss: 0.0227\n",
      "Epoch 292/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0113 - val_loss: 0.0260\n",
      "Epoch 293/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0117 - val_loss: 0.0227\n",
      "Epoch 294/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0114 - val_loss: 0.0252\n",
      "Epoch 295/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0111 - val_loss: 0.0239\n",
      "Epoch 296/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0110 - val_loss: 0.0249\n",
      "Epoch 297/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0112 - val_loss: 0.0222\n",
      "Epoch 298/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0110 - val_loss: 0.0245\n",
      "Epoch 299/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0112 - val_loss: 0.0238\n",
      "Epoch 300/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0111 - val_loss: 0.0251\n",
      "Epoch 301/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0110 - val_loss: 0.0241\n",
      "Epoch 302/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0110 - val_loss: 0.0248\n",
      "Epoch 303/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0107 - val_loss: 0.0229\n",
      "Epoch 304/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 0.0109 - val_loss: 0.0241\n",
      "Epoch 305/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0104 - val_loss: 0.0241\n",
      "Epoch 306/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0108 - val_loss: 0.0239\n",
      "Epoch 307/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0110 - val_loss: 0.0248\n",
      "Epoch 308/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0105 - val_loss: 0.0229\n",
      "Epoch 309/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0107 - val_loss: 0.0244\n",
      "Epoch 310/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0109 - val_loss: 0.0234\n",
      "Epoch 311/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0103 - val_loss: 0.0220\n",
      "Epoch 312/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0110 - val_loss: 0.0280\n",
      "Epoch 313/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0118 - val_loss: 0.0235\n",
      "Epoch 314/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0106 - val_loss: 0.0253\n",
      "Epoch 315/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0100 - val_loss: 0.0234\n",
      "Epoch 316/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0119 - val_loss: 0.0250\n",
      "Epoch 317/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0100 - val_loss: 0.0231\n",
      "Epoch 318/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0114 - val_loss: 0.0238\n",
      "Epoch 319/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0108 - val_loss: 0.0221\n",
      "Epoch 320/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0102 - val_loss: 0.0244\n",
      "Epoch 321/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0111 - val_loss: 0.0238\n",
      "Epoch 322/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 0.0106 - val_loss: 0.0252\n",
      "Epoch 323/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0100 - val_loss: 0.0239\n",
      "Epoch 324/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0101 - val_loss: 0.0237\n",
      "Epoch 325/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0103 - val_loss: 0.0247\n",
      "Epoch 326/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0111 - val_loss: 0.0233\n",
      "Epoch 327/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0107 - val_loss: 0.0237\n",
      "Epoch 328/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0109 - val_loss: 0.0240\n",
      "Epoch 329/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0106 - val_loss: 0.0247\n",
      "Epoch 330/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0121 - val_loss: 0.0271\n",
      "Epoch 331/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0108 - val_loss: 0.0245\n",
      "Epoch 332/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0102 - val_loss: 0.0243\n",
      "Epoch 333/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0106 - val_loss: 0.0264\n",
      "Epoch 334/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0114 - val_loss: 0.0247\n",
      "Epoch 335/500\n",
      "240/240 [==============================] - 0s 119us/step - loss: 0.0102 - val_loss: 0.0235\n",
      "Epoch 336/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0115 - val_loss: 0.0252\n",
      "Epoch 337/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0108 - val_loss: 0.0254\n",
      "Epoch 338/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0106 - val_loss: 0.0243\n",
      "Epoch 339/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0103 - val_loss: 0.0247\n",
      "Epoch 340/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0096 - val_loss: 0.0261\n",
      "Epoch 341/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0103 - val_loss: 0.0276\n",
      "Epoch 342/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0101 - val_loss: 0.0240\n",
      "Epoch 343/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 0.0107 - val_loss: 0.0242\n",
      "Epoch 344/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0100 - val_loss: 0.0241\n",
      "Epoch 345/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0107 - val_loss: 0.0252\n",
      "Epoch 346/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0098 - val_loss: 0.0230\n",
      "Epoch 347/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0097 - val_loss: 0.0239\n",
      "Epoch 348/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0098 - val_loss: 0.0234\n",
      "Epoch 349/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0102 - val_loss: 0.0236\n",
      "Epoch 350/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0103 - val_loss: 0.0253\n",
      "Epoch 351/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0098 - val_loss: 0.0258\n",
      "Epoch 352/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0107 - val_loss: 0.0283\n",
      "Epoch 353/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0096 - val_loss: 0.0243\n",
      "Epoch 354/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 355/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0102 - val_loss: 0.0281\n",
      "Epoch 356/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0110 - val_loss: 0.0250\n",
      "Epoch 357/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0107 - val_loss: 0.0247\n",
      "Epoch 358/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0099 - val_loss: 0.0286\n",
      "Epoch 359/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0105 - val_loss: 0.0237\n",
      "Epoch 360/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0112 - val_loss: 0.0296\n",
      "Epoch 361/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0122 - val_loss: 0.0229\n",
      "Epoch 362/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0106 - val_loss: 0.0248\n",
      "Epoch 363/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0104 - val_loss: 0.0241\n",
      "Epoch 364/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0103 - val_loss: 0.0239\n",
      "Epoch 365/500\n",
      "240/240 [==============================] - 0s 117us/step - loss: 0.0101 - val_loss: 0.0255\n",
      "Epoch 366/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0098 - val_loss: 0.0249\n",
      "Epoch 367/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0107 - val_loss: 0.0246\n",
      "Epoch 368/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0112 - val_loss: 0.0285\n",
      "Epoch 369/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0105 - val_loss: 0.0240\n",
      "Epoch 370/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0102 - val_loss: 0.0249\n",
      "Epoch 371/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0099 - val_loss: 0.0263\n",
      "Epoch 372/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0097 - val_loss: 0.0248\n",
      "Epoch 373/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0108 - val_loss: 0.0297\n",
      "Epoch 374/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0107 - val_loss: 0.0247\n",
      "Epoch 375/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0097 - val_loss: 0.0274\n",
      "Epoch 376/500\n",
      "240/240 [==============================] - 0s 127us/step - loss: 0.0099 - val_loss: 0.0241\n",
      "Epoch 377/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0099 - val_loss: 0.0245\n",
      "Epoch 378/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0098 - val_loss: 0.0271\n",
      "Epoch 379/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0103 - val_loss: 0.0243\n",
      "Epoch 380/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 0.0098 - val_loss: 0.0243\n",
      "Epoch 381/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0097 - val_loss: 0.0282\n",
      "Epoch 382/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0096 - val_loss: 0.0242\n",
      "Epoch 383/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0097 - val_loss: 0.0256\n",
      "Epoch 384/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0092 - val_loss: 0.0257\n",
      "Epoch 385/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0094 - val_loss: 0.0256\n",
      "Epoch 386/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0098 - val_loss: 0.0244\n",
      "Epoch 387/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0097 - val_loss: 0.0263\n",
      "Epoch 388/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0089 - val_loss: 0.0255\n",
      "Epoch 389/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0262\n",
      "Epoch 390/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0257\n",
      "Epoch 391/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0094 - val_loss: 0.0248\n",
      "Epoch 392/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0091 - val_loss: 0.0250\n",
      "Epoch 393/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0242\n",
      "Epoch 394/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0094 - val_loss: 0.0266\n",
      "Epoch 395/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0093 - val_loss: 0.0243\n",
      "Epoch 396/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0099 - val_loss: 0.0238\n",
      "Epoch 397/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0253\n",
      "Epoch 398/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0257\n",
      "Epoch 399/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0087 - val_loss: 0.0270\n",
      "Epoch 400/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0095 - val_loss: 0.0246\n",
      "Epoch 401/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0104 - val_loss: 0.0247\n",
      "Epoch 402/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0099 - val_loss: 0.0299\n",
      "Epoch 403/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0100 - val_loss: 0.0256\n",
      "Epoch 404/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0096 - val_loss: 0.0319\n",
      "Epoch 405/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0098 - val_loss: 0.0253\n",
      "Epoch 406/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0094 - val_loss: 0.0265\n",
      "Epoch 407/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0090 - val_loss: 0.0251\n",
      "Epoch 408/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0104 - val_loss: 0.0248\n",
      "Epoch 409/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0097 - val_loss: 0.0262\n",
      "Epoch 410/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0095 - val_loss: 0.0241\n",
      "Epoch 411/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0093 - val_loss: 0.0263\n",
      "Epoch 412/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0090 - val_loss: 0.0251\n",
      "Epoch 413/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0090 - val_loss: 0.0252\n",
      "Epoch 414/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0090 - val_loss: 0.0271\n",
      "Epoch 415/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0096 - val_loss: 0.0245\n",
      "Epoch 416/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0095 - val_loss: 0.0259\n",
      "Epoch 417/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0096 - val_loss: 0.0265\n",
      "Epoch 418/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0095 - val_loss: 0.0243\n",
      "Epoch 419/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0095 - val_loss: 0.0274\n",
      "Epoch 420/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0094 - val_loss: 0.0243\n",
      "Epoch 421/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0100 - val_loss: 0.0318\n",
      "Epoch 422/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0102 - val_loss: 0.0248\n",
      "Epoch 423/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0105 - val_loss: 0.0257\n",
      "Epoch 424/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0096 - val_loss: 0.0264\n",
      "Epoch 425/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0091 - val_loss: 0.0262\n",
      "Epoch 426/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0087 - val_loss: 0.0254\n",
      "Epoch 427/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0087 - val_loss: 0.0272\n",
      "Epoch 428/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0084 - val_loss: 0.0260\n",
      "Epoch 429/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0085 - val_loss: 0.0275\n",
      "Epoch 430/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0088 - val_loss: 0.0250\n",
      "Epoch 431/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0089 - val_loss: 0.0245\n",
      "Epoch 432/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0084 - val_loss: 0.0265\n",
      "Epoch 433/500\n",
      "240/240 [==============================] - 0s 101us/step - loss: 0.0087 - val_loss: 0.0252\n",
      "Epoch 434/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0089 - val_loss: 0.0268\n",
      "Epoch 435/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0085 - val_loss: 0.0261\n",
      "Epoch 436/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0091 - val_loss: 0.0238\n",
      "Epoch 437/500\n",
      "240/240 [==============================] - 0s 116us/step - loss: 0.0093 - val_loss: 0.0277\n",
      "Epoch 438/500\n",
      "240/240 [==============================] - 0s 111us/step - loss: 0.0091 - val_loss: 0.0244\n",
      "Epoch 439/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0090 - val_loss: 0.0253\n",
      "Epoch 440/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0090 - val_loss: 0.0267\n",
      "Epoch 441/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0090 - val_loss: 0.0253\n",
      "Epoch 442/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0089 - val_loss: 0.0265\n",
      "Epoch 443/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0091 - val_loss: 0.0255\n",
      "Epoch 444/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0088 - val_loss: 0.0274\n",
      "Epoch 445/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0086 - val_loss: 0.0261\n",
      "Epoch 446/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0094 - val_loss: 0.0269\n",
      "Epoch 447/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0083 - val_loss: 0.0284\n",
      "Epoch 448/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0086 - val_loss: 0.0263\n",
      "Epoch 449/500\n",
      "240/240 [==============================] - 0s 109us/step - loss: 0.0089 - val_loss: 0.0246\n",
      "Epoch 450/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0090 - val_loss: 0.0276\n",
      "Epoch 451/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0083 - val_loss: 0.0255\n",
      "Epoch 452/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0096 - val_loss: 0.0277\n",
      "Epoch 453/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0090 - val_loss: 0.0262\n",
      "Epoch 454/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0093 - val_loss: 0.0252\n",
      "Epoch 455/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0087 - val_loss: 0.0274\n",
      "Epoch 456/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0081 - val_loss: 0.0246\n",
      "Epoch 457/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0086 - val_loss: 0.0254\n",
      "Epoch 458/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0089 - val_loss: 0.0268\n",
      "Epoch 459/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0088 - val_loss: 0.0246\n",
      "Epoch 460/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0078 - val_loss: 0.0248\n",
      "Epoch 461/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0087 - val_loss: 0.0257\n",
      "Epoch 462/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0087 - val_loss: 0.0251\n",
      "Epoch 463/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0081 - val_loss: 0.0291\n",
      "Epoch 464/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0085 - val_loss: 0.0263\n",
      "Epoch 465/500\n",
      "240/240 [==============================] - 0s 114us/step - loss: 0.0083 - val_loss: 0.0287\n",
      "Epoch 466/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0095 - val_loss: 0.0266\n",
      "Epoch 467/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0081 - val_loss: 0.0268\n",
      "Epoch 468/500\n",
      "240/240 [==============================] - 0s 120us/step - loss: 0.0083 - val_loss: 0.0277\n",
      "Epoch 469/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0082 - val_loss: 0.0248\n",
      "Epoch 470/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0083 - val_loss: 0.0253\n",
      "Epoch 471/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0090 - val_loss: 0.0287\n",
      "Epoch 472/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0086 - val_loss: 0.0247\n",
      "Epoch 473/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0090 - val_loss: 0.0275\n",
      "Epoch 474/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0092 - val_loss: 0.0236\n",
      "Epoch 475/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0085 - val_loss: 0.0261\n",
      "Epoch 476/500\n",
      "240/240 [==============================] - 0s 99us/step - loss: 0.0081 - val_loss: 0.0239\n",
      "Epoch 477/500\n",
      "240/240 [==============================] - 0s 103us/step - loss: 0.0086 - val_loss: 0.0265\n",
      "Epoch 478/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0079 - val_loss: 0.0259\n",
      "Epoch 479/500\n",
      "240/240 [==============================] - 0s 107us/step - loss: 0.0083 - val_loss: 0.0265\n",
      "Epoch 480/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0083 - val_loss: 0.0258\n",
      "Epoch 481/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0080 - val_loss: 0.0253\n",
      "Epoch 482/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0072 - val_loss: 0.0271\n",
      "Epoch 483/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0082 - val_loss: 0.0257\n",
      "Epoch 484/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0083 - val_loss: 0.0255\n",
      "Epoch 485/500\n",
      "240/240 [==============================] - 0s 105us/step - loss: 0.0078 - val_loss: 0.0276\n",
      "Epoch 486/500\n",
      "240/240 [==============================] - 0s 110us/step - loss: 0.0088 - val_loss: 0.0261\n",
      "Epoch 487/500\n",
      "240/240 [==============================] - 0s 112us/step - loss: 0.0077 - val_loss: 0.0270\n",
      "Epoch 488/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0086 - val_loss: 0.0287\n",
      "Epoch 489/500\n",
      "240/240 [==============================] - 0s 106us/step - loss: 0.0082 - val_loss: 0.0260\n",
      "Epoch 490/500\n",
      "240/240 [==============================] - 0s 104us/step - loss: 0.0088 - val_loss: 0.0265\n",
      "Epoch 491/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0081 - val_loss: 0.0288\n",
      "Epoch 492/500\n",
      "240/240 [==============================] - 0s 122us/step - loss: 0.0082 - val_loss: 0.0263\n",
      "Epoch 493/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0083 - val_loss: 0.0284\n",
      "Epoch 494/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0079 - val_loss: 0.0256\n",
      "Epoch 495/500\n",
      "240/240 [==============================] - 0s 108us/step - loss: 0.0080 - val_loss: 0.0260\n",
      "Epoch 496/500\n",
      "240/240 [==============================] - 0s 115us/step - loss: 0.0080 - val_loss: 0.0274\n",
      "Epoch 497/500\n",
      "240/240 [==============================] - 0s 113us/step - loss: 0.0077 - val_loss: 0.0252\n",
      "Epoch 498/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0087 - val_loss: 0.0292\n",
      "Epoch 499/500\n",
      "240/240 [==============================] - 0s 102us/step - loss: 0.0085 - val_loss: 0.0260\n",
      "Epoch 500/500\n",
      "240/240 [==============================] - 0s 100us/step - loss: 0.0089 - val_loss: 0.0266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fadb72e9668>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    80,\n",
    "    input_shape=(None, X_train.shape[2]),\n",
    "    return_sequences=True)\n",
    ")\n",
    "\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(LSTM(\n",
    "    80,\n",
    "    return_sequences=False)\n",
    ")\n",
    "\n",
    "model.add(Dropout(.3))\n",
    "\n",
    "model.add(Dense(10))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "               optimizer='adam')\n",
    "\n",
    "model.fit(X_train,\n",
    "    y_train.squeeze(),\n",
    "    batch_size=64,\n",
    "    epochs=500,\n",
    "    validation_split=.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_13 (LSTM)               (None, None, 80)          105920    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, None, 80)          0         \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 80)                51520     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                810       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 158,250\n",
      "Trainable params: 158,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fae4c579e48>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIQAAAEyCAYAAACLeQv5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8kwX+B/DPk6TpTLr3hu5CGW1RQIaAgCIqiuI+9dzr1FNP7/SGnnq/0/Oc5zjPPVAcOBBBkD1bKN2L7pXuvbKe3x+lWEYhTZ40Tft5v16+Xpo84yt0JN98hyCKIoiIiIiIiIiIaOKQ2ToAIiIiIiIiIiIaXUwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMEwIERERERERERFNMApb3djHx0eMiIiw1e2JiIiIiIiIiMadQ4cONYmi6Hu242yWEIqIiEB6erqtbk9ERERERERENO4IglBhynFsGSMiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIiIiIimmCYECIiIiIimzja0ImMylZbh0FERDQhKWwdABERERFNLOnlLXhzRwm25DdAKZfhwB8Xw9NVaeuwiIiIJhRWCBERERGR1RmNIrbk1WP1G3ux+s19OFTRihtnh0NrMOLrjBpbh0dERDThsEKIiIiIiKxGqzfiu8xavL2zBEX1XQj2cMZfVybgqtRQuCgVyKxqw+dplbhlbgQEQbB1uERERBMGE0JEREREJLnufj0+O1iJ/+0uQ117H+ICVHhpzXSsSAqEg/zXIvWrZ4Xh8a+zkVHVhplhnjaMmIiIaGJhQoiIiIiIJPVFehWe2ZCP9l4dzon0wrOXT8XCGN/TVgCtnBaEp3/Iw+cHq5gQIiIiGkVMCBERERGRZIxGEc/+mI8wLxf87dLEsyZ53BwVuDgpEN9n1eLJlQlwc+TLUyIiotHAodJEREREJJmSxi609ehww+xwkyt+1qSGoUdrwA+ZtVaOjoiIiAYxIUREREREkjlY3gIASI3wMvmcmWEeiPZzw9q0KmuFRURERCdhQoiIiIiIJJNe3gofN0dEeLuYfI4gCFiTGoojVW0o0HRYMToiIiIaxIQQEREREUnmYFkLUiM8R7xC/vKZIVDKZficVUJERESjggkhIiIiIpJEbVsvatp6kTKCdrFBXq5KLE30xzcZNejTGawQHREREQ3FhBARERERSSK9ohUAMMuMhBAAXJ0ahrYeHTblaqQMi4iIiE6DCSEiIiIikkRaWQtclHLEB6rMOn/OZG+EeDpb1DaWX9eBfj0rjIiIiM6GCSEiIiIikkRaeQtmhnlCITfvJaZMJmBNSij2ljSjorl7xOf/lFOHC1/ehXd2lZl1fyIioomECSEiIiIislh7rw6F9Z0jWjd/OqtTQiATgC/SR1YldLShCw+vywIAbMypsygGIiKiiYAJISIiIiKy2OGKVogikBrhadF1At2dsTDWD+vSq6E3GE06p7tfjzs/PgRHhQw3zYlATk0Hqlt7LIqDiIhovGNCiIiIiIgsllbeAoVMwPQwD4uvdXVqKBo6+7G9sPGsx4qiiEe/ykJpYxdevWYGbpoTAQDYlFtvcRxERETjGRNCRERERGSx9PJWJAa7w0WpsPha58f5wVfliLUmDJf+3+4ybMiqw6PL4zAnygcRPq6IC1BxUxkREdFZMCFERERERBbp1xtwpLoNqeGWtYsNcpDLsDo5BNsKG1Df0TfscftLm/HcxgIsS/THHfMnHX98aWIA0spb0NjZL0k8RERE4xETQkRERERkkezqdmj1RqRGWjZQeqirUkJhMIr48lD1aZ/XtPfh3k8PI9zbBS9cOQ2CIBx/bnliAEQR2JLPtjEiIqLhMCFERERERBZJK28FAKRIVCEEAJE+rjh3khc+T6uC0Sie8JxWb8Q9nx5Gj9aAt65PhsrJ4YTn4wNVCPVyZtsYERHRGTAhREREREQWSStvwSRfV3i7OUp63atTw1DZ0oP9pc0nPP7MhjwcqmjFP1cnIdpfdcp5giBgeWIA9hxtQkefTtKYiIiIxgsmhIiIiIjIbEajiPTyFsyKkK5dbNDyKQFQOylOGC79TUY1PthXgVvPi8TFSUFnPFdnELGtoEHyuIiIiMYDJoSIiIiIyGzFDV3o6NMjxQoJIScHOS6fGYKfcjRo7dYiv64Dj3+djVmRXvjDhXFnPHdGqCd8VY5sGyMiIhoGE0JEREREZLaD5S0AgNQI6eYHDbUmNRRagxEf7qvAnR8fgruzA16/diYc5Gd+GSuTCVia4I9tBY3o0xmsEhsREZE9Y0KIiIiIiMyWXt4CP5UjwrxcrHL9+EA1poW4499bilDT2ov/XDcTvirTZhUtSwxAr86AXcVNVomNiIjInjEhRERERERmSy9vRWqE1wlr36V27TlhAIAnL05AcrjprWnnTvKG2kmBn3LYNkZERHQyha0DICIiIiL7VNPWi5q2Xtw6L9Kq97kqJRTJ4Z6Y7Os2ovOUChmWxPtja0E9dAbjWdvMiIiIJhL+ViQiIiIis6Qfnx8k/UDpoQRBQJSfyqwqpKWJAWjr0eFgWYsVIiMiIrJfTAgRERERkVnSylvg5qhAfKDa1qEMa0GML5wcZGwbIyIiOgkTQkRERERklrSyVswM94RcZr35QZZyVsqxIMYXm/M0MBpFW4dDREQ0ZjAhREREREQj1t6jQ2F9J1LDrbNuXkrLpwSgvqMfR6rbbB0KERHRmMGEEBERERGNWHrFwEyeFCvPD5LCojh/KGQCNuWybYyIiGgQE0JERERENGJp5a1wkAuYHuph61DOyt3ZAbMne2NTjgaiyLYxIiIigAkhIiIiIjJDenkLpgS7w1kpt3UoJlk+JQDlzT0orO+0dShERERjgkkJIUEQlguCUCgIwlFBEB47zfNhgiBsEwQhQxCELEEQLpI+VCIiIiIaC/p0BmRVt1t93byULkjwhyAAm3LqbR0KERHRmHDWhJAgCHIArwO4EEACgGsEQUg46bAnAHwhiuIMAFcD+I/UgRIRERHR2JBV3Q6twWhXCSE/lROSwzzxE+cIERERATCtQmgWgKOiKJaKoqgFsBbApScdIwJQH/t3dwC10oVIREREZJ8KNZ1Y9Z89aO7qt3UokkorHxgonWwHG8aGWpYYgPy6DlQ299g6FCIiIpszJSEUDKBqyH9XH3tsqL8CuF4QhGoAPwK473QXEgThdkEQ0gVBSG9sbDQjXCIiIiL78eaOEmRUtmF/aYutQ5FUWnkLovzc4OWqtHUoI7IsMQAArLJtrKK5G499lYXs6nbJr01ERGQNpiSEhNM8dvJ6hmsAvC+KYgiAiwB8JAjCKdcWRfFtURRTRFFM8fX1HXm0RERERHaiqasfG7LqAAC5teMnSWAwijhU0WpX7WKDwrxdkBColrxtTG8w4v61R7A2rQqXvL4bf/gyC03jrCqMiIjGH1MSQtUAQof8dwhObQn7LYAvAEAUxX0AnAD4SBEgERERkT36PK0KWoMRPm5K5NZ22DocyRTVd6KzT4/UCPtqFxu0LDEAhytb0dDRJ9k139hegsyqNjx3+VT8dm4kvjpcjfOf3453dpVCqzdKdh8iIiIpmZIQSgMQLQhCpCAISgwMjf7upGMqASwGAEEQ4jGQEGJPGBEREU1IeoMRH++vwHlRPlgQ4zeuEkKD84PssUIIGFg/L4rA5jxpto1lV7fj5a3FuGRaEK6ZFYYnLk7ATw/Mx8xwT/x9Qz6Wv7wT2wobJLkXERGRlM6aEBJFUQ/gXgCbAORjYJtYriAITwmCcMmxw34P4DZBEDIBfAbgJlEUT24rIyIiIpoQtuQ3oK69DzfMDkdikBpNXf2SVqTYUlp5KwLUTgjxdLZ1KGaJ8XdDhLeLJHOE+nQGPPjFEXi7KfHUpYnHH4/yc8P7N6fi3ZtSIIrAze+l4Zb301Da2GXxPYmIiKSiMOUgURR/xMCw6KGP/XnIv+cBmCttaERERET26aP95Qhyd8LiOD8cqmgFAOTWdsBP7WTjyCwjiiLSylqQEuEJQTjdmMmxTxAELJsSgP/tKkN7jw7uLg5mX+uFTYU42tCFD26ZBQ+XEwdsC4KARXH+OC/KF+/vLcMrW49i2Us7cfPcSNy3KAoqJ/PvS0REJAVTWsaIiIiIxpyGzj489MURtPfqbB3KCY42dGLP0WZcd244FHIZ4oPUAMbHYOnq1l5oOvowK9I+28UGLU8MgN4oYmuB+W1j+0qa8b89Zbjh3HAsiBl+WYpSIcPt8yfjl4cX4LLpwXh7ZynOf2EHCjWdZt+biIhICkwIERERkV3akteArw/X4Iesk3dd2NZH+yqglMtwderATg61kwPCvFzGxRyh9IqB+UEp4fadEJoW4oFAdye8srXYrDauzj4dHl6XiXAvFzx+UZxJ5/ipnPD8ldPw7T1z0dqjxfeZY+vrdqherQFv7yxBTo39JzGJiGh4TAgRERGRXSrUDCRYfsqRdoW4Jbr69fjqcA0uTgqEt5vj8ccTg9TjIiGUVt4KlaMCsQEqW4diEZlMwMtXz0BHnx6Xvr4H20c49Pmp7/NQ196Lf101HS5KkyYwHDct1APh3i4oqh+bFUJHGzpx6eu78eyPBVj52m48/nUWmrv6bR0WERFZARNCREREZJcKjrXc7CtpRluP1sbRDPjmcDW6+vW4YXb4CY8nBqlR2dKDjr6x1d42EgajiINlLUiO8IRcZp/zg4aaFemFb++ZixBPF9zyfhre2lECU3aibM7VYN2haty1cDKSwz3NuneMnwrFDWNvwPT6jBpc8toeNHdp8eb1ybhlbiTWpVdj4Qvb8c6uUugMRluHSEREEhrZRxpEREREY4Aoiiis78SUYDVyajrwc149rkwJtXlMH+yrQFKIO6aHepzwXGKQOwAgr7YD507ytkV4JhNFEfUd/Sis70ShpgOFmi4U1neguL4L/XojLp8ZbOsQJRPq5YKv7pqNR9Zl4bmNBciv68A/rkiCk4P8tMc3dfXj8a+zkRCoxu8Wx5h935gAFTbnadCnMwx7r9HUpzPgb9/n4bODlZgV4YVXr50Bf7UTlk8JwDWzQvHUD/n4+4Z8fHawEn9emXjGmUlERGQ/mBAiIiIiu9PQ2Y+2Hh1+tzgard1l2JijsXlCaF9pM442dOH51UmnbOBKPD5YeuwlhHq0enx7pBZ5tR0o1HSisL7zhEHdfipHxAaocOPscMQGqHHR1AAbRis9F6UCr107A/HbVHhhcxFKGrvx9o3JCHR3PuE4URTxx6+z0dmnx6e3TYdSYX6hfYy/G4wiUNLYdTxZaCtlTd24+5PDyK/rwN0LJ+OhC2KgkP/6/xblp8IHN6fil4IGPP1DHn7z7kEsiffDn1YkINLH1YaRExGRpZgQIiIiIrsz2C4WF6DG8ikB+GhfBTr7dDZd5f3h3gp4ujhg5bSgU57zUzvBx81xzG0ay6hsxYOfH0F5cw9UjgrEBKiwIikQsf4qxAaoEOuvgqer8uwXsnOCIODeRdGIDVDjwc+PYOWre/DWDTORPGR49leHa7A5rx5/vCjO4hlKMf4D5xfVd9o0IfRDVi0e+yobCrmA925Kxflxfqc9ThAELI73x3nRPnhvTzle3VqMpf/egVvOi8R9i6Lh5si3FERE9og/vYmIiMjuDA6UjgtQwUEu4H+7y/BLQQMunW6bdqa69l78nF+PW+dFDtsClBikRt4YGSytMxjx2i9H8dq2owhQO+HTW8/B7Mnep1Q2TTQXJPjjm7vn4NYP03H12/vx98umYE1qGKpbe/C373IxK8ILvz1vksX3ifB2hUImoKjeNnOE+vUGPLMhHx/uq8DMMA+8du1MBHk4n/U8R4Ucdy6YjMtnBOP/firEWztK8fXhGrxw5TS2kRER2SEOlSYiIiK7U6DphJ/KEZ6uSswM84SfyhEbs223bezTA5UwiiKuPyd82GMSg9QobuhCn84wipGdqrSxC6vf2IuXtxbj0mlB2PjAPMyJ8pnwyaBB0f4qfHvPXJw7yRt/+Cobf/k2B4+sy4JRFPGvq6ZJMlBbqZAh0scVxTbYNFbZ3IPVb+zDh/sqcNu8SHx+x2yTkkFD+amd8K+rpmH9PXOhdlLgkXWZ6NXa9uuaiIhGjgkhIiIisjuFms7jbTsymYBliQHYXtSAHq1+1GPp1xvw2cFKLI7zQ6iXy7DHJQa5w2AUUWyjqhBRFPHR/gpc9MouVLT04PVrZ+LFNdOhtmGb3Vjl4aLEezel4rZ5kfhgXwX2lTbjzysTzvj3O1IxAapRrxDaml+PFa/uQkVzN96+IRl/WpEAB7n5bwemh3rgucuT0NDZjw/3lUsWJ9FYkV/Xgds/TLd5Ip/IWpgQIiIiIrtiMIoobuhC3JA5LhdODUCfzogdhY2jHs9PORo0dWlxw+yIMx7362Dp0Z8j1NDRh5vfT8OT63MwK9Ibmx6YjxVJgaMehz1RyGX404oEvHrNDDywJBpXSTy0PMZPharWnlGprBFFEa9vO4pbP0xHuLcLNtw/D0sTpRkOPivSC/NjfPHGjhJ09unOfgKRHXlnVxk259Uju2ZszX8jkgoTQkRERGRXypu7odUbjw/mBYBZEV7wclViY87ot419sLcckT6umBflc8bjwrxc4OaoQO4ozxH6KacOy17aiX0lzXjq0kR8cHMq/NVOoxqDPVs5LQgPLImRvKUuxt8NoggcbbBulVCPVo/7PsvA85sKccm0IKy7Y46klU4A8MjSWLT16PDOrjJJr0tkS71aA37KqQMAFNSNjflvRFJjQoiIiIjsSuGQDWODFHIZlib4Y2t+/aiW9ufUtONwZRuuPzccsrPMlpHJBCQEqketQqirX4+H12Xizo8PI8RzoCrkxtkRnBU0RkQfS2gWWnGOUHXrwLygDdl1ePzCOLy0Zjqclacfem6JqSHuWJ4YgP/tLkNLt1by6xPZws/59eg+VsGXVzf6876IRgMTQkRERGRXCjSdkAlAtL/bCY8vnxKAbq0Bu4ubRi2WD/eVw9lBjtXJISYdnxCkRn5dJwxG0bqBAfj7D3n4+nA17lsUha/vnoMoP7ezn0SjJsLbBUq5zGqDpQ+UNuPS1/agqrUH796UijsWTLZqMvD3S2PQrdXjzR0lVrsH0Whan1GDQHcnzIrwQoGGFUI0PjEhRERERHalUNOBCG/XU9a7z5nsA5WTYtTaxtp6tPj2SC0umxEMd2fTBjMnBqnRqzOgrKnbqrG19+iw/kgN1qSG4fdLYy0aHEzWoZDLMMnXFUVWSAh9vL8C171zAO4uDlh/z1ycH+sn+T1OFu2vwqoZwfhgbznqO/qsfj8ia2ru6sfOokZcOj0YCUFqFGo6YRyFRD7RaOOrAyIiIrIrQzeMDaVUyHBBvD+25NdDZzBaPY4v0qvQrzfixtnDr5o/WWKQOwDrD5b+8nA1+nRGXH9umFXvQ5aJ8Zd205hWb8Qfv8nGE+tzMC/aB+vvmYvJvqNXGfbA4hgYjCJe/aV41O5JZA0bsuugN4pYNSMY8YEq9GgNqGzpsXVYRJJjQoiIiIjsRo9Wj4qWntMmhICBtrH2Xh32lTRbNQ6jUcTH+ysxK8IL8YHqs59wTLS/G5RyGfKsOFhaFEV8cqACM8I8jiegaGyK8XdDTVsvuvr1Fl+rqasf172zH58eqMTdCyfjnd+kQu1kWuWaVMK8XXD1rFCsPViFyma+eSb79U1GDeICVIgNUB3/Gc+2MRqPmBAiIiIiu1Fc3wVRxAkr54eaH+MLF6Xc6m1jO4oaUdnSgxtGUB0EAA5yGWIC3Ky6aWxfSTNKG7tx/Tkji41G3+BgaUvnCBXXd+KSV3cju6Ydr1wzA48uj4P8LEPOreW+RdGQywS8tLXIJvcnslR5UzcyKtuwakYwACDaTwWZwMHSND4xIURERER2Y3DDWGzA6atynBzkWBTnh825GqsObv7kQAV8VY5Ylhgw4nMTA92RW9sOUbROfB8fqICHiwNWJAVa5foknZjjCSHL2sZe3lqMbq0BX945B5dMC5IiNLP5q53wmzkRWJ9RY7WB2UTWtP5IDQQBuGT6wPeSs1KOCB9Xrp6ncYkJISIiIrIbBZpOODnIEOblMuwxF04JRHO3FgfLWqwSg6a9D78UNODK5BAoFSN/KZUYrEZrjw517dIP3m3o6MPm3HpcmRxyytBtGnvCvFzgqJBZNFhaFEWklbdgYawvpgSPjRbBOxdMhotSgRd/ZpUQ2RdRFPHtkVrMnuSNQHfn44/HB6pRoGGCk8YfJoSIiIjIbhTWdyDGX3XGdpiFsb5wVMjwU06dVWL46nA1jCJwVUqoWecnBg1UN1mjbWxtWhX0RhHXsl3MLshlAqL83FDUYH6FUHVrL+o7+pES4SVhZJbxclXit+dFYmOOBtnV1h2gTiSlzOp2lDV147LpwSc8Hh+gQmVLDzr7dDaKjMg6mBAiIiIiu1Go6USs/+nnBw1ydVRgQYwvfsrVSL4m2GgU8XlaFWZP8kaEj6tZ14gLUEMQpN80pjcY8dnBSsyL9kGkmbHR6IvxV1nUWjVYCTdrDCWEAODWeZHwcHHAC5sLbR0KkcnWZ9RAqZBh+dQT24EHB0tbUs1HNBYxIURERER2oamrH01d2mE3jA114dQA1Hf0I6OqTdIY9pU2o7KlB1fPMq86CBhIWEX6uEpeIbStsBF17X24jtVBdiXa3w117X1o7zWv8iC9ogVqJwWi/UZvvbwpVE4OuGvBZOwoarRa+yaRlHQGI77PrMUF8f6nbOiLO5YQ4mBpGm+YECIiIiK7MDhQOm6YgdJDLYrzh4NckLxtbG1aFdydHcwaJj1UYpC75KvnP95fAX+1I5bE+0l6XbKuwYq3ow3mvdFMK29FSoQXZDbaKnYmN86OgK/KEc9vKrDaEHUiqewubkJztxaXzQg+5bkgdyeonRQcLE3jDhNCREREZBcKjm8YO3uFkLuzA+ZG+WBjjkayN6Kt3VpsytFg1Yxgiwc2JwapUdPWi9ZurSSxVTb3YGdxI65ODYNCzpd39mRw01iRGZvGWrq1ONrQhdQx1i42yFkpx/2LopBW3oodRY22DofojL7JqIGHiwMWxPie8pwgCIjjYGkah/iKgYiIiOxCoaYD3q5K+KocTTr+oimBqG7tRU6NNJ/ofpNRA63BiDWp5reLDRocLJ0n0afNnxysgEwQcM2sMEmuR6Mn2MMZzg5ys2aTpJcPtGKlRnhKHZZk1qSGIcTTGS9sLmSVEI1ZXf16bM7TYMXUwGG3R8YHqFBQ1yH5bDoiW2JCiIiIiOxCoabTpOqgQRck+EMuE7BRgrYxURwYJj0t1OP4cFFLJAQObhqzfLB0v96AdenVWBLvhwB3J4uvR6NLJhMQ7e+GYjMqhNIrWqFUyDA1ZGysmz8dpUKGB5bEIKemAz/laGwdDtFpbc7VoE9nxKrTtIsNigtUo1trQHVr7yhGRmRdTAgRERGR2fp0Blz62m78nFdv1fsYjSKK6rtGlBDydFXi3Ele+EmCtrEjVW0orO/E1RJUBwGAt5sjAtROkgyW3pitQUu3Ftefy2HS9iraT2VWhdDBshZMD/GAo8KyFkZrWzUjGFF+bnh+cyH69QZbhzMm3f9ZBu786BBq25hssIVvMmoQ4umM5PDhq+0GPwzI13COEI0fTAgRERGR2faWNCGzuh0/ZNVa9T6VLT3o1RkQN4KEEAAsnxKI0qZus+azDLX2YBVclHKsnBZk0XWGSgxSS5IQ+nh/BSK8XTB3so8EUZEtxAa4oaGzH209ps+U6tUakFPTjpQx3C42SC4T8MSKeJQ2duPVrUdtHc6Y09jZj+8ya/FTrgYXvLgDH+wth4FtSaOmoaMPe442YdWMYAjC8MPZY/zdIAhAPgdL0zjChBARERGZbVPOQGVQmpXXSv86UHpk7VrLEv0hCLCobayrX4/vs2pxcVIg3BwVZl/nZIlBapQ2dqFXa37FRIGmA+kVrbjunPAxuWWKTBNtxmDpjKpW6I3imB0ofbKFsX5YnRyCN3aUILva8lbJ8WT30YGB229cNxPJEV74y3e5WP3mXrOqxmjkvsushVEELp0+fLsYALgoFYj0dkUBV8/TOMKEEBEREZnFYBSxJb8eSoUMte19qLFiq0OhphOCMPAJ7Uj4qZyQEu5p0eySHzJr0aM1YE2qtAObE4LcYRQtaz/4eH8FlAoZVieHSBgZjbZfN42Z/kYzvbwVggDMPEOLy1jz5IoE+Lgp8ciXmdDqjbYOZ8zYWdQEb1clliUG4IObU/HvNdNQ3tSNFa/swotss7O6b4/UYmqwO6L8zv77JS5QxZYxGleYECIiIiKzHK5sRXO3FrfMjQTw68Yjayis70CYlwtclCOv0Fk+JRAFmk6UNprXNrY2rQox/m6YGeZh1vnDGdw0Zm7bWFe/Ht8crsHFSYHwdFVKGRqNsiB3J7g5KlA8goRQWnkLYv1VcHd2sGJk0nJ3ccCzq6aiQNOJ17axdQwYmI+2q7gR50X7QCYTIAgCVs0IwZaHFuDipCC88stRXPTyLqRZ8efrRHa0oRPZNe247AzDpIeKC1CjorkH3f16K0dGNDqYECIiIiKzbM7VQCmX4a4Fk+HmqMBBK7aNFWo6Ees/svlBg5ZPCYAgAC9vLR7xcOkCTQeOVLVhTWrYGWdLmCPE0xnuzg7IM3PT2PqMGnRrDRwmPQ4IgoAoPzeTW8b0BiMOV7TaTbvYUIvj/XH5jGD8Z9tRSbbs2bu8ug40dWkxP9r3hMe93Rzx7zXT8cEts9CnM+LKN/fhT99ko6NPZ6NIx6f1GbWQCcDKaYEmHT84WLqQ7Xw0TjAhRERERCMmiiI259VjTpQ33F0cMDPcE+nlrVa5V5/OgPLmnhEPlB4U7OGMh5bE4NsjtXh5a/GIzv08rQpKueyMq4jNJQiLgT5KAAAgAElEQVQCEgLNGywtiiI+OVCJhEA1ZoRKW7lEthHrb/qmsQJNJ7q1BqRG2l9CCAD+vDIBnq5KPLIuCzrDxG4d21k8MD9oXszph8IviPHF5gfn47fnReKzg5W44MUd2FHUOJohjltGo4j1R2owN8oHfionk84Z/D3EwdI0XjAhRERERCNWVN+FiuYeLE0IAACkhnuisL4T7T3Sf3p9tKELBqM44oHSQ927KApXzAzBS1uK8U1GtUnn9OkM+CajBksT/eFlpZasxCA1CjSdI35TfLiyDfl1HbjuXOkrl8g2ov3d0NytRXNX/1mPHWwfSrWDDWOn4+GixDOXTUFeXQfe2F5i63BsamdRI+ID1WdMSLg6KvDkxQn45u65cHNU4IG1GSOudqRTHapsRXVr74gS/iGezlA5KjhYmsYNJoSIiIhoxDbnaiAIwJIEPwA4XqmQXiF921jh8Q1j5lUIAQPVOM9dPhXnTvLCo19mYX9p81nP2ZSrQVuPDldLPEx6qMRgNbR6I0pGON/ok/0VcHNU4LKzbMUh+xEzgk1jaeUtCPZwRqC7s7XDspqliQG4ZFoQXv2lGAUTdEhvd78ehypaMX+Y6qCTTQv1wK3zJqG1R4eK5h4rRzf+rc+ogbODHMsSA0w+RxCEgcHSrBCicYIJISIiIhqxzXn1mBHqcfxT7WkhHnCQC0izQttYYX0nlAoZIrxdLLqOUiHDW9enIMzLBXd8dOisSZjP06oQ6uWMOZO9LbrvmSQGuQMA8kbQNtbarcUP2XVYNSMYro4jH7JNY9NgQqi44cyVB6IoIq28FbPstF1sqL9ekgh3Zwc8vC5zQraO7Stphs4gYsFJ84POJClk4GdGVg3nL1lCqzfih6w6LE30H/HP0biAgcpOVmnReMCEEBEREY1IbVsvsmvasXTIp6rOSjmmBLtbZdNYgaYTUb5uUMgtf9ni7uKA926aBYVMwM3vpQ3bnlPR3I29Jc1YkxIKmcx6LVmTfFzhqJCNaI7QukNV0OqNHCY9zvirHaFyUpx1jlBFcw8aO/uRYqftYkN5uSrx9KVTkFPTgbd3lto6nFG3o6gRzg5yJI/g7zLGXwVHhQxZVW1WjGz8217YgPZencnbxYaKD1Sjq1+P6tZeK0RGNLqYECIiIqIR+TmvHgCwNMH/hMdnRXghq7odfTqDpPcr1HSYPVD6dMK8XfDf36SgvqMPt3906LTxfpFeBZkArE4Oley+p6OQyxAXqDZ529K+kma89stRzIrwsqiFjsYeQRAGBktrzly59uv8IPuvEAKAC6cGYkVSIF7eUmzyUO3xYmdxI+ZM9oajQm7yOQ5yGRKC1KwQsoAoinh/bzl83JQ4L8q0dr2h4gI5WHrQz3n1+PRApa3DIAswIUREREQjsilXgyg/N0zydTvh8ZQIL2gNRmRVS/dGpa1Hi/qOfsmTHzPDPPHiVdNxqKIVD6/LhNH4a+m/3mDEuvRqnB/rhwB30zbPWCIxSI282o6zth+sz6jBje8egJ/aCS+umWb1uGj0RfurUNRw5laU9PJWeLg4IOqk7z979tQliXBzUuCRdZnQT5DWsYrmblQ092B+jOntYoOSgt2RU9MOg5EtS+bYkt+AvSXNuPf8KDiYUXka66+CIAxUr05kH+4rx20fpuOP32RjX8nZ5/LR2MSEEBEREZmsrUeLA2Utp1QHAUBK+EDbQ5qEbWMFEgyUHs6KpEA8dmEcfsiqw79+Ljz++PbCRjR09mNNqnWrgwYlBqnR0Td8+4Eoinjtl2I88PkRJId74qs75yDE07J5SjQ2xfi7oa1Hh8YzbBpLK29BSrinVVsZR5u3myOeujQRmdXteGd3ma3DGRU7j62ONyshFOKBHq0BpSMcRk9Av96AZzbkIcrPDdeZ2Xbr6qhAuJfLhK0QEkURr2wtxp+/zcWSeH+Eebngj99kS14dTKODCSEiIiIy2S8FDTAYxRPmBw3ydFUi2s9N0oTQ4IaxOAtWzp/JHfMn4ZpZoXh9Wwm+SKsCAKxNq4KvyhHnx/lZ5Z4nGxwsfbq2MZ3BiMe/zsYLm4tw2fQgfHDLLLi7OIxKXDT6jg+WHmbTWFNXP0qbupEyTtrFhloxNRDLEwPw4s9FONow/hMdO4qaEOrlbNaw/MHB0pkSVmNOFB/sLUd5cw+evDjBrOqgQYODpScao1HE0z/k48Wfi3D5zGC8ef1MPLtqKsqauvHqL8W2Do/MwIQQERERmWxzbj0C1E5ICnY/7fMpEV44VNEqWStDgaYT7s4O8Fc7SnK9kwmCgKcunYJ50T744zfZ+OpQNbYVNmB1cohFbxZGIi5ABblMOGWwdGefDr/9IB1r06pw36Io/HvN9BHNGiH7E+0/0AY23Cyd9GNb/MbL/KChBEHA05dNgYtSjofXZaKlW2vrkKxGqzdiX0kT5kf7QhBGXuk1ydcNrko5sqs5WHokmrr68erWo1gU54cFZlRmDRUfqEZ5czd6tHqJohv79AYjHvkyC+/uKcNNcyLwwuppUMhlOC/aB1fMDMFbO0onbNWUPTPplY4gCMsFQSgUBOGoIAiPDXPMVYIg5AmCkCsIwqfShklERES21qczYEdRIy5I8B+2XWVWpCc6+/THK3ssVajpQGyAyqw3TaZykMvw+nUzMdnXDb9flwmDUcSalNFpFwMAJwc5Jvu6npAQ0rT34aq39mPP0Sb83xVT8fulsVb9M6CxwdfNEZ4uDsMmhNLKW+CokGFKsHUq5mzNV+WIv182BZnVbZjzj634y7c5qGrpsXVYkjtc2YpurcGsdjEAkMsEJAa7s0JohP61uRC9OgP+tCLe4mvFBaogipDsd91Y16cz4K5PDuOrw9V4cEkM/rIy4YTXAU+siIe7swMe+zqbs63szFkTQoIgyAG8DuBCAAkArhEEIeGkY6IBPA5griiKiQAesEKsREREZEO7i5vQqzNgaeKp84MGpYQPVC6kV1jeNiaKIorquyTdMDYctZMD3r05Fb4qR8yP8UWEj6vV7zlUYpD78Zax/LoOrPrPHlS19OC9m1KxJjVsVGMh2xEEYWCw9DAtY+nlLZgW6jGuK8UuTgrC5gfm4+KkIHx6sBILX9iO363NQF7t+Kk82FnUCIVMwJzJ3mZfY1qIO/LqOqCbIEO4LZVb2461aVW4cXYEJkswkD3+WBvzRGgb6+rX4+b30vBzXj3+ujIBv1sSfcoHFJ6uSvx5ZQIyq9rw4b5ym8RJ5jGlQmgWgKOiKJaKoqgFsBbApScdcxuA10VRbAUAURQbpA2TiIiIbG1zngYqJwXOiRz+TUyIpzMC1E5IO9baYonq1l509etHbb16sIcztj28EG9cN3NU7jdUYpAa9R39WJ9Rgyvf3AdRBL64Y7bZFQRkv2L83VBUf+qmse5+PXJqOzBrHLaLnSzaX4UXrpyGnY+ej5vnRGBLXj0uemUXfvPuQewraT7rRr6xbmdxI2aGeULlZP48sKkhHtDqjcNWk9GvRFHEU9/nwcPZAb9bHC3JNUM8neHmqBj3LVIt3Vpc99/9OFjegn+vmYab5kYOe+wl04KwIMYXz28qRHXr+KvsG69MSQgFA6ga8t/Vxx4bKgZAjCAIewRB2C8IwvLTXUgQhNsFQUgXBCG9sbHRvIiJiIho1BmMIrbkN2BRnB+UiuFfPgiCgNRIL6SVtVj8pu3XgdKjkxACADdHBVwdFaN2v0EJQQOfNj/w+RGEeDrjm3vmHH+MJpYYfxU6+/So7zhx09iRqjYYjCJSIjxtFNnoC3R3xhMXJ2DvY4vx8NIY5NS045r/7sdl/9mLn3LqYLTD1pSmrn7k1HRgfoyPRdeZdmywdBbbxs7qpxwNDpS14KGlsZIN5ZfJBMQGqFBQN34TcnXtvbjqrX0o0HTireuTsWpGyBmPFwQBf79sCkQReHJ9jt0nbicKUxJCp2tYP/lvVwEgGsBCANcAeEcQBI9TThLFt0VRTBFFMcXXl594ERER2YtDFa1o6dZiacKp28VOlhrhCU1H37Br1E1VeOyT78HNS+NZYpA73BwVmBftg3V3zkagu7OtQyIbGfx6P7nyI628BTIBSA6fOAmhQe4uDrh3UTT2PLYIT182Ba3dWtz58WEseXEH3tpRgto2y37WDNIbjFZfnb27uAmAeevmhwrzcoHaScGE0Fn06Qx4dmM+Yv1VuCZV2tlw8YEq5Gs6xmXio6ypG6vf2AdNex8+uGUWliQM3yo+VKiXCx5eFotthY34PqvOylGSFEz5CKwawNDvnhAAtac5Zr8oijoAZYIgFGIgQZQmSZRERERkU5tzNVDKZVgQe/Y3MYMbkNIrWhDqNfKVyoMKNJ0I9nC2qK3CXrg7O2D3H86H2slh2IHdNDEMTQgNTRqklbcgLkA9Ib4fhuPkIMcN54bjmtRQbMzR4H+7y/DcxgI8t7EAsyK8sHJ6EFZMDYSXq9LkazZ29mNHUSO2FTRgZ3EjPF2U2PLQgjNWQlpiZ1EjvFyVmBJ0+k2NphIEAUkhHsjiprEzendPGapaevHJredAIfHmyLgANT7uq0RNWy9CPM3/XTfW6A1G3PjuAfTqDPjstnMxNWRkX6s3zYnAd0dq8NT3uZgf7QMPF9O/H2n0mfJdkQYgWhCESEEQlACuBvDdScesB3A+AAiC4IOBFrJSKQMlIiIi2xBFEZvyNJgb5Q03E9qpYvxVUDkpcLDMsjlChZqOUW0XszUPFyWTQQQvVyV83JQnVAjpDEZkVLYhdQK1i52JQi7DymlBWH/PXGx/eCF+f0EMWnq0eHJ9DlKf2YKb3juIrw9Xo6v/1JXgRqOII1Vt+PfPRbjktd1IfWYLHl6XiYPlLTgn0guVLT349kiNVeI2GkXsLG7CeVE+knyvJ4W4o1DTafWqJnvV0NGH1385igsS/DE3yrIWvdOJDxz4/TTe2sY259WjqqUXz10+dcTJIGBgC95zlyehtUeHZzbkWyFCktJZX9WJoqgXBOFeAJsAyAG8K4piriAITwFIF0Xxu2PPLRUEIQ+AAcAjoig2WzNwIiIiGh0Fmk5UtfTi7oVRJh0vlwlIDvdEern5m8a0eiNKG7uxJN60MnWi8STa78RNY/l1HejRGpAaOf4HSo9UhI8r7lscjXsXRSG/rhPfZdbi+8xaPPRFJhwV2Vgc74dLpgVBZxCxrbABOwob0dythSAAM0I98PsLYnB+nB8SAtUQBOCiV3bjrZ2luGJmiOQJ2ry6DjR19Us2LD4pxB16o4j8ug7MCGOy8GTPbyqE1mDEny6yfM386cQe2zSWX9dhckuVPXh/TzlCvZwt+v2bEKTG7fMn4Y3tJVg1IxhzrJCQI2mYNDVRFMUfAfx40mN/HvLvIoCHjv1DRERE48jm3HoIAkb04jA1wgvbCwvR2q2F5wjaNwaVNHZBbxRHbcMY0VgS4++Grw7XQBRFCIKAg2UDydWUcCaEhiMIAhKC1EgIUuPRZbHIqGrFt0dqsSGrDj9mawAAHi4OWBDji/Nj/TA/xve0rWV3LpiE3609gq0FDbhA4jf5O4sHlurMj5bmzXFSyMDI1uyadiaETpJd3Y4vD1fjtnmTEOHjapV7uDkqEOblMq5Wz+fUtONgeQueWBEPuYUJ0d8tjsbG7Do8/k02Nj0wH04OcomiJCmN/hoNIiIisiub8zRIDvOEr8rR5HN+nSPUatabql83jHHTFk08MQEqdPXrUdveh2APZ6SXtyLUyxkB7k62Ds0uyGQCksO9kBzuhT9fnICD5S1wVMgwPdTzrG9yV0wNxPObCvHmjhLpE0JFjYgPVMNPLc3fY6C7E3zclMisagdmS3LJcUEURfzt+1x4uShx7yLTKlvNNThYerz4YG85nB3kuDLF8gHcTg5yPLtqKq595wBe3lqMPyyPkyBCkpp1pqURERHRuFDd2oPc2g4sTRzZG6OkEHco5TKz28YKNJ1wkAuY5GudT3aJxrKhg6VFUURaecvxJCuNjEIuw5zJPkgO9zKp4kEhl+G2eZNwqKIVaRa0vZ6su1+PQxWtFq+bH2pwsHR2DQdLD/VDVh3SK1rx8LJYqK08hD0uQI3ypm70au1/jlNzVz++zazFFcnBcHeW5s9tTpQPrkwOwds7S5Fby414YxETQkRERDSsn/PqAQAXmLBufignBzmSQtxx0Mw3VEX1nZjs6wYHibfCENmDGL9jCSFNJ8qautHcrWVCaBRdlRIKL1cl3txeItk195U0Q2cQsSBamvlBg6YGu+NoQxe6TzNAeyLq0xnwj40FiA9U4yoJqlzOJj5QBaOIE4bA26vPDlZCqzfiN7MjJL3un1bEw9PFAY9/nQ2DUZT02mQ5vsoiIiKiYW3OrUeMvxsizZjBkBLhhZyadrM+OS3UdHJ+EE1Y7i4O8FM5oqi+C+nlA9v6uGFs9Dgr5fjN7AhsLWg43r5qqZ3FjXB2kCNZ4r/HaaHuMIpAbu34aVuyxH93lqKmrRd/WZlg8QwcU8QH/jpY2p7pDEZ8tL8C86J9EO0/gt+9vzwDfHYtYDQOe4iHixKPLo9DVnU7Dldatn2UpMeEEBEREZ1Wa7cWB8tbsHSE1UGDZkV6QmcQkVk9snaGjj4datp6mRCiCS3GX4Xihk4cLG+Bp4sDJvu62TqkCeXG2eFwUcrx1g5pqoR2FjVi9mRvOCqkHaw7NXhgsHTWCH/OjkeHKlrx6i9HcdHUAJw7yXtU7hnq6QIXpdzuB0v/lKNBfUc/bp4bYfpJ1YeAnc8DhRuA7HVnPHT5lAAoZAK25NdbFihJjgkhIiIiOq1fChpgMIojnh80KDlsoMUlrWxkbWNFxwdKMyFEE1eMvwrF9V04WNaClAgvCIL1qx3oV56uSlydGobvMmtR09Zr0bUqm3tQ3twj2XaxoXxVjghyd0JW9cSez1LX3os7PjqEQA8nPLtq6qjdVyYTEBugsvsKoff3liPc2wULY/xMO8FoADY8BLj5AwFTga1PAbrhv0/UTg44Z5IXtuY3SBQxSYUJISIiIjqtTbkaBKidMDXY3azz3V0cEOuvQlrFyErEBz9pjeWGMZrAYvzd0KszoLKlh+1iNnLrvEgAwDu7Si26zo7BdfMx0s4PGjQ1xH1CVwj1ag24/cND6NMZ8M6NKfBwUY7q/eMD1civ64Ao2ud8nKzqNhyqaMVvZkdAZmqb3aH3gLojwLJngOX/ADqqgf3/OeMpi+P8cbShC+VN3RJETVJhQoiIiIhO0as1YGdxI5Ym+ltUmZAa6YnDFa0mD5Js79HhvT1l8Dv2qTfRRDV0jgcHSttGkIczLpkehLUHq9DarTX7OjuLGhHi6WzWLDZTJIV4oLy5B+09OqtcfywTRRGPfpWFnNp2vLRm+sjm30gkPkCFjj496tr7Rv3eUnh/TzlclXKsTgkx7YSuxoGKoIh5wJQrgIjzgNgVwK5/Dzw3jCXxA9XGbBsbW5gQIiIiohOIoojnNxWiT2fE8kTz5gcNSo3wQle/3qRyeq3eiDs+TkdlSw9evWYGW2RoQov2H5gZ5OQgQ2KQeVV6ZLk7F0xGr86AD/dVmHW+zmDEvpJmzI/xtdrPtKSQga+PnAm41vs/20vwfWYtHlkWiyUJ5rU3W2pwsHSBxv7axho6+/B9Vi1WJ4dA7WTiqvktfwG0PcCKfwGDX9MXPAXoe4Htzw17Wpi3C2L83dg2NsYwIURERETHiaKIv32fh3f3lOGmORGYPdmywZwpxyob0s+yfl4URTz2dRb2l7bgn6uTcM4oDQQlGqvUTg4I9nDG9FAPKBV8yW4rMf4qLI7zwwf7ys3amHi4ohVd/XrMl3jd/FBJxwZLj3SAv73bklePFzYX4pJpQbhrwWSbxRFzbN5dfp39DZb+7EAVdAYRv5kTYdoJlfuBI58As+8BfGN/fdwnCki5BTj0PtBYOOzpi+P9cbC8ZUJWs41V/O1CREQ0DrR0ay1+gSWKIv7yXS7e31uO354Xib+sTLD4E+1gD2cEezifdY7Qq78cxdeHa/DgkhismmFi2TrROPfvNdPxt0um2DqMCe/OhZPR0q3FF+lVIz53R1Ej5DIBc6Ksl+R2d3FAuLcLsifQYOmi+k78bm0GpgS545+rk2xaUap2ckCIp7PdDZbW6o34+EAFFsb6YpIpWwwNemDD7wF1CLDg0VOfX/AYoHQDNj857CWWxPvDYBSxvYhVQmMFE0JERGQV9jpc0R5tztVg4fPbsPCFbdiYXWfWNYxGEU+sz8GH+ypwx/xJeGJFvGQvsFMiPJFW1jLs18T6jBq8+HMRLp8RjPsXR0lyT6LxYFakF2K5bc/mUiO8kBzuif/uKoXeYBzRuTuLGzEzzMP0dhwzJYV4TJhNY63dWtz6QTqclQq8fWMynBzktg7p+GBpe7Ixpw6Nnf24ydTqoINvA/U5wPLnAOVp5mG5egPzfw8UbwJKt5/2EtNDPeDtqmTb2BjChBAREUmuT2fAef+3DS9tKbJ1KOOazmDE33/Iw+0fHUKEjytCPF1w1yeH8dAXR9DRZ3q1kNEo4k/rs/HJgUrctXAyHrswTtJPW1MivNDQ2Y+qllNX0h4sa8GjX2bhnEgvPHfFVM4NIqIx6c4Fk1Hd2osNJibd+3QGvLK1GDk1HVZtFxuUFOyOmrZeNHX1W/1etqQzGHHPp4ehae/DWzckI9Dd2dYhARgYLF3W1I0+3cjbCm3lvT3lmOTjatrXZ0cdsO1ZIGoJEL9y+ONm3QG4hwGbnhhYTX8SuUzA+XF+2F7YAN0Ik6tkHUwIERGR5PYcbUJNWy9e2lKMzbkaW4czar7JqMadHx1Cd7/e6veqaevFVW/twzu7B2b9rLtzNr6+ew7uXxSF9Rk1uPClXThQ2nzW6xiNIh7/OhufHazCvedH4dFlsZInZWYdmyN08KQ5QqWNXbj9o3SEeDnjrRuS4aiw/ae8RESnszjOD9F+bnhje8kZK2BFUcSP2XVY/K8dePHnIlw4JQA3mlqBYYGpxwZLj/e2sWc25GNvSTOevXwqksM9bR3OcfGBahhFoLi+a1Tv26PV42hDFwo1I5tflFHZiiNVbfjNHBNXzW9+AjBogQv/+esg6dNxcAKW/AWozwYy1572kCXx/ujo0yPtLLMFaXQobB0AERGNP5tz6+HmqECkjyt+/0UmvrtPZbV1u2PFoYpWPPplFnQGEcI64PVrZ5r2IssMvxTU46EvMqE3iHj92plYkRR4/LmHlsZiQawfHvriCK7+737cPn8SHrog5rTJFoNRxB++ysKXh6rxu8XReGBJtFUqdKL93ODu7ID08hasTh6YD9TSrcUt76dBJgh476ZUeLgoJb8vEZFUZDIBdyyYjIfXZWJ7USPOj/U75Zj8ug787ftc7C9tQVyACp/edg7mTPYZlfimBLtDEICs6nacH3dqbOPBZwcr8f7ectx6XuTx3yVjxeAmwJ/z648n5ywliiLqO/pR09aL2qH/tPcd//fWHh0ul+3EdYqteCD0adx/2TyT5gG9v7ccKkcFrjDlz7F0B5DzJbDgD4C3CcO7p1wB7H8D+OVpIPGyU9rL5kX7QCmXYWt+w6h9f9DwWCFERESSMhhFbMmvx/lxfnjj+plQyAXc+dEh9GitXzVjK42d/bj7k0MIcHfC/YujsTFHg1d+KZb8PjqDEc9tzMct76cjyN0ZP9x33gnJoEHJ4Z748f55uDo1FG/tKMVlr+895dNDg1HEI+sy8eWhajy4JAYPXhBjtXYtmUxASrjn8U8D+3QG3P5hOmrb+/DfG5MR7j2+k4VEND5cMi0Ige5OeHN7yQmPt3Zr8cT6bKx4ZRcKNJ14+rIp+OG+80b1za6bowKTfd2QNU43jaWVt+DP3+ZgXrQPHrswztbhnCLM2wUrkgLx1o4SVLX0SHLNx77KxrnPbcUVb+zFfZ9l4LmNBfg6owaVzT3wUznioqmB+GBKJl5UvolkWTGWV7+MZS/txDMb8s7YNl7f0YcNWXW4MiUUbo5nqQ/Ra4EfHwY8woHzHjQtcEEAlj0DdNYB+14/5WlXRwVmT/bGlvx6zpscA5gQIiIiSR2qaEVztxZLE/wR4umCV66ZgaKGTjz2Vfa4/MWvNxhx32eH0dajw5vXJ+PBJdG4YmYIXtpSbPaA59PRtPfh2v/ux1s7SnHtOWH4+u45iDhD1ZWrowLPXZ6E/96YgoaOPqx8bTfe2VUKo1GE3mDEQ18cwdcZNXh4aQx+tyRasjiHkxLhhZLGbjR19eORL7OQXtGKF6+ahuRwL6vfm4hICkqFDL89LxIHylqQUdkKvcGID/aWY+EL2/HZwSrccG44tj+8EDecGw6FfPTfZiWFuCOrpn3c/a7t6tfjro8PIcTTBa9dM9Mmf7am+NNF8ZAJAp7ZkG/xtbYVNODz9CqsSQnFezelYtMD85H116XI/usybHpwPt67eRae8duGBUf/D4i9CJj/CJYL+/B4VCXe2V2GRS9sxxdpVTAaT/1a+ORAJQyiiBtnh589kP2vA01FwEXPAw4jmNcUdi4Qfwmw+yWg89TRAUsS/FHR3IOSxtFtsaNTjc3vJiIislubczVQymVYGDswpHBetC8eXhqL7zJr8f7ectsGZwX/3FSI/aUteHbVVCQGuUMQBDyzagpmhHngoS8ykVdr+daRHUWNuOiVXcit7cDLV0/Hs6ummrxV5YIEf2x6cD7mR/vi7xvycf3/DuD+tRn49kgtHl0ei3sXWT8ZBACpEQOzHu76+BC+zxy498VJQaNybyIiqVwzKwzuzg54+oc8XPTKLvzlu1xMCVbjx/vn4W+XTrFp+2tSsDsaO/uh6eizWQzWcKC0GU1dWjx96RS4u1h3W5slgjycce+iKPyUq8HOokazr9Pdr8cT63MQ7eeGpy+bgvPj/BAboPp1U50oAtueA35+Eki8HLjqQ2D+o4BPLG5pex3f3T4DYV4uePSrLFz6+prqZgMAACAASURBVB4cqvh1Vk+/3oBPD1RgUazfGT9UAgC0VQE7/gnErgBilo38f2TJXwfmDm175pSnFh9ra9xiwbaxd3aVYtMEmlNpLUwIERGRZERRxOa8esyJ8oZqyIrduxZMxgUJ/nhmQ/64GiL4Y3Yd3t5ZihvODT+hD9/JQY63rk+Gu7MDbvsw3eytLzqDES9sKsRN7x2Er5sjvrv3PFw6PXjE1/Fxc8R/b0zGPy6fiiNVbfgxW4M/XhSHuxeO3or3qSHuUCpkSCtvxZqUUNy1wIQ5BEREY4yrowI3zg7H4co29OoMePP6ZHz823MQG6CydWhICvUAgHG3fn5/aTOUChlSIsbOEOnh3DovEhHeLvjr97nQ6s3bovXC5kLUtvfiH1dMhVJx0tt1URxIBO34BzD9euCKdwC5A6BQAitfAtorMbX4DXx11xy8tGY6Gjr7cMUb+/DA2gxo2gdaxZq6tLhpbsTZA9n0+MD9LvyHWf8f8J4MzLoNyPgYqM894akgD2ckBKqxNb/erEunlbfg7xvyccdHh/DhvnLz4iMATAgREZGECus7UdnSg6UJASc8LpMJ+NdV0xDi6Yy7PzmMhnHw6eXRhk48si4TM8I88OTFCac876d2wts3JqOpqx93f3x4xC8MSxu7sPrNfXht21GsnhmC9ffMRZTf2QdFDkcQBFw9KwybHpiPD2+Zhdvnj25CxlEhxwXx/lgU54e/r5rC9fJEZLfuOT8Kb1w3Ez8/uADLpwSMmZ9nCYFqKGTCuJsjtL+0BTNCPUyujLUlR8X/s3ffYVGeWR/Hv8/QOyq92BXFggWNPWqMJYmamMSUTa+bspte3s2m7mY3m957b5teNIktahJ7jQ0ERURBBaRIG+rM8/6BZk1EGWBgEH6f68o1ytzP/RwM9cx9znHjwen9SD9Yxjsrdjf4+l/3FvLuygwuOaXLsSXVdjt8fwesfAGGXQszXgDLUf8mXUbBkMtg1UsY2Vs5e3A0S+4Yz00TevDDtmwmPPkTj89PpWeYP2N61tPfauePsH0ujLsTgjs3+P34zbi7wCsQFt5/zFOT4sPZsKeQgrKqBm1pmiaPzUshLMCLSX3DeODbJF5YvLPNlUq2FCWERETasBqbnRpb416haoyFSTkYBkyKP3bCSaC3B69dmkhpRQ03fbyR6haMy9lKK2u4/oMN+Hi68fKfhhz7Ct5hA2OCefy8gazNKODBOUkO/bBimiYfrt7Dmc8vJyOvjBcvHswT5yfg4+mcH4RjO/oyrneoU/ZqqJf+NIS3Lk/Eo5X2fxARcYS3hxvTBkS2ugSFt4cbvcMD2tQJoaLyapL2FzGieydXh+KwCX3CmNQ3jOcX7yS7yPEXwKptdv7vq62EB3hz99S43z9pq4Fvb4L1b8HoW2p7+ljq+F466WHw7Qjf3Qp2G35e7tw1pQ8/3nYq43qHkF1cwTVjup04iVm0r/b6Tj1h1F8cjr9Ovh3h1Lth12JI+/H3ofYNw27W9ktqiEXJOWzYU8gdp3Xj1T8NYdaQaJ5atIN/fLe9zp5JcmL6iUxEpA0qLKvi+cU7Gf6vxVz+ztoWe9VkYXI2g2ODCQvwrvP5uIgAHjt3AOsyCvn3DyktEpOzmWbtdK6MfCsvXDSEyKATN1mcOSiaG8b34L9r9/Lh6j0nXJtbUsGV767j799sI7FrBxbcOq7N9dlpLa+ki4i0RQNjgtjahhpLr88owG5yUiWEAO4/K55qu8m/5zneYPr1X9J/m1J3dNk9NVXw5dWw+WOYcF9t0ud430t9O8KUf8O+DbD+7d/e3LmTL69dmsiq/5vIBcNijx9E8QF47yyoKIJZb4C7l8PxH9ewa6BD19pTQrb/TZztHxVEWIAXi1McLxursdl5YkEqA0NMZq8+B/ePZ/HkjB5cMaorb6/Yzd1fbmnRF0LbAiWERETakP2HynlkbjKj/7OEpxftICzAixVp+SxuQtM+R+07VM62fcVM7hdxwnUzB0Vz5ejab9xzNu9v9ric7Y1l6czbls09U+MY2cOxH1DvnBzHaX3CeGhuMivT8upcM39bNlOe+YVVu/J5aHo87105nIiguhNrIiIidRkYE8whazWZBeUOrTdNk82Zh9iTX9Yqk0hH+gcN7hzs6lAapEsnP/48rjvfbtrPmvT8etenHyzlucU7OWNABKfHh//vieoK+OxSSP4GJv+z9rRNfS+sDDgPuk+AHx+G4t//nBUZ5HP8F2ZKc+G96bWPl3wJ0UPqjdsh7l61secmw/Knf3uzxWJwWt9wftmRR2WNzaGtvtq4j525pbzS6XOMoizYvQzLh7N48PQobpvUmy82ZHHjRxupqHZsP1FCSESkTdiRU8Ltn21i3ONLeX9VBlP7RbDg1nHM/csYuof48fiCFGzNfIx20eFJD5OP/kHmOP52Rl8Su3Tgni+2kJpd0qxxOdPKXXk8Ni+Faf0juHZsd4evc7MYPHvhILqF+HHjxxvZm2/97bmSimru+nwzf/5wA9EdfPj+r2O4YnQ3LBadpBERkYYZGBMEwJZ99fcRstlNHpqTxMyXVnDqEz8x7NHF3PDhBt5cls7mzEOtorT7ZOof9Ec3jO9JdLAPD85JOuGpFbvd5P++2oqXu4WHpvf73xNVZfDfC2DHfDjzacfLtwwDznoa7NUw7x7HrinLq00GFe+DP30OscMdu85RfafDgPPhp8dqTy8dNqlvGKWVNaxJr3/gSEW1jWd+3MG1YalE7/kGxt4Os9+DA5sw3pvOLSM78ND0eBYm53DVu+soraypd09RQkhE5KS2LqOAq99dx+RnfmHe1mwuHdmFn++ewNMXDCIuIgAPNwt3ToljR04pX23MatZYFiTl0DPMn+6h9Tc+9nCz8PKfhuDv7c6fP9xAcUV1s8bmDAeKyvnLx7/SLcSPJ85PaHDpU4C3B29elohpwjXv1/6gsi6jgGnPLePLjVncPKEnX90wmp5hrp9UIyIiJ6fe4QF4ulvq7SNkrarthffeqj1cNbobj57Tn7G9Qti2v4h/fr+dmS+tYOBDC7no9dU8tTCVn3ccbPHv1cUVJ1//oKP5eLpx/1l9Scku4aM1e4+77rP1mazZXcB9Z/QlLPCok8FLHoXdv8DZr8Kwqxt2847da08TbZ8DqfNOvNZaAO/PhMI9cPGntc2pm8MZT0BABHx1PVTVvjA2umcI3h4Wh6aNvbcyA2tRHndVvwLh/WHc3bWJpov+C3lp8M40rhjgxTMXJLBmdwF/emM1hQ1sWN0eKSEkInIS+mXHQc59ZSXnv7qKXzMPcduk3qy8dyIPTu9HdPDve9pM6x9BQmwwTy/a0WxHaAvLqlibUcCUfvWfDjoiLNCbl/80hMwCK5e9tZak/a23CWZljY0bPqw9gvzapUPx93Jv1D5dQ/x46eIh7DpYxtkvrWD2a6uwGAafXT+SO6fEHbc5tYiIiCM83S30jQw84aSxgyWVXPj6apak5PDIzH48MD2eP53ShWcuGMSyuyey5m+n8dLFQ7hgWCyllTW8tDSNy99eS8LDC3lh8c4We19O1v5BR5vSL4KxvUJ4amEqeaWVxzyfW1LBv37YzindOh7b2ydvB0QMhEEXNe7mI/8CoX3h+zuhsrTuNeWFtcmgvJ1w0cfQbVzj7uUInw5w9suQvxN+fAiobYQ+pmcIP27PPWHJYpG1mpeWpvFKp0/xrCyo3cfds/bJnpNqS9yKD8DbUzmnaw2vXTKUlOwSZr+2qkGNvdsj/eQpInKSWbkrj8vfWUtOcQUPz+jHinsmcsukXnTw86xzvWEY3Du1DweKKnh/VUazxLQkJReb3Txm3Hx9hnXtyDMXDGJPfhnTX1jO377e2uDxo83NNE0enpvMpsxDPHF+QpNP8IzpFcL9Z/YlLbeU2UNj+eGWsSR27Vj/hSIiIg5IiAli277iOicupeWWcM7LK9iZU8rrlyZy2ciux6wJD/TmzIGRPDSjH3P/MoatD03ho2tO4dTeobywJI19hxzrT9RUq9ML8HQ7+foHHc0wDB6c3g9rlY0n5qce8/zDc5KpqLHz71kDjj15bM0H3yYkw9w9YfpzUJwFP/372OcriuCDWXAwBS78CHpMbPy9HNV9PJxyA6x9DdIWAzCpbzj7DpWTcoIWAq/8vIsR1asZVbYYxt4JkQm/X9B1NFz+be379PY0JoUW8d5VwzlQVMG5r6wkI6+s+d6nk5wSQiIiJ5HCsipu/3Qz3UL8WHjbOC4f1dWhceQje3Ti1N6hvLR0F0Xlzj/yvTA5m4hAbwZEBzX42ukJUfx05wQuG9mVT9dlMv6JpbyzYner6F0A8Nby3Xy8Zi/Xn9qdMwZEOmXPK0Z349f7T+c/5w1s9GkjERGRugyIDqK0sob0P/wSvCY9n1kvr6Si2s6n149gkgM9/wD8vNwZ3TOER88ZAMDzP7bMKaHV6fkM6nxy9g86Ws8wf64e041P12eyKfN/J7cWJefw/dYD/HViz7rL7a154BfStJt3PgWGXgmrX4b9m/739soS+PA8yN4Cs9+HXqc37T4NMelBCImDb28CawET+4QBHLds7EBROV+v2MKT3u9C+AAYe0fd+0YPhSu+r+2d9M40Rvju57/XjqC82sYlb63BWqWeQnVRQkhE5CRhmib3frWF/LJKnr9wML6eDUsk3DO1D8UV1bz68y6nxlVeZePnHQc5PT680Y2Qg3w9eGhGP+bdMpaBMcE8PDeZM55bxrKdB50aa0MtSMrm0R+2M61/BPdM6ePUvY93oktERKQpEmJrT9QcXTb27aZ9XPrWWkIDvPj6xlEMjGn4qZvoYB/+NKIzX2zMIv3gcUqQnKS4oppt+07e/kF/9JfTehEW4MUD327Dbjcpqajm/m+20ScigOvG9aj7orJ88G1iQghqEzC+ITD3FrDbaptVf3R+bXPn896BuGlNv0dDePjArNeh7CB8fwdhgd4kxATx43Em4j67aCf3Wd4lwCz+falYXSL6w5XzayebvXsmA9jJq5cMJauwnOcXpzXTO3RyU0JIROQk8cm6TBYk5XD3lD70b8RJnPioQM4eFM3by3c7tZ56eVoeFdV2Jjegf9Dx9A4P4IOrh/P6pUOprLFz6Vtrufb99ezJb/mjvpszD3HLJ78yMCaYp2cP0tQvERE5KfQI9cfX040tWUWYpslLS9O45ZNNDO4czFc3jCa2o2+j975xfE883Sw808ynhP7XP6htlFT7e7lz35l92ZJVxGfrM3liQSo5JRX8e9aAuvsHVpdDdRn4OuH99+kA0x6DA5tgxXPw8QWQuQbOfRPiZzR9/8aIGgTj/w+SvoKtXzCpbzibsw6RW/L7n0/Tckso+vUrZlhWYIy7GyIH1r93SE+4ch74dIT3ZzKcJM4fGsOby9LZkXPyTLZtKUoIiYicBNJyS3l4bhJje4Vw9Zhujd7n9tN7YzdNnlu8w2mxLUzKJsDbnVO6OedVPMMwmNwvgoW3jeOuKXGsSMvj9Kd/4T/zUyhroRGiWYVWrn5vPSH+Xrx5WaJDZXkiIiKtgZvFoH9UEL/uLeRvX2/jiQWpzBwUxftXDyfI16NJe4cGeHHVmK7M3byf5P3FTor4WEf6Bw3p3KHZ7tHSZiREMbxrRx79fjsfrN7D5SO7Mvh47581v/axqSVjR/SbVdt8efHDkLEcznkN+s9yzt6NNfpWiBkO39/OlFgbpglLU35/Sujl79fyqPvb1IQNqB0z76gOXWqTQkEx8NF5PNB3P/7e7vz9620nbF7dHikhJCLSylXW2Ljlk1/x9XTnqfMTmnRSJbajL5eM6MKn6zJJy236ce8am50ft+cwsU+Y0ydkeXu4cdOEniy9czxnDYzklZ92Mf2F5VTVNG9voeKKaq56dx2VNTbeuWIYoQFezXo/ERERZxsQE8TmrCL+u3YvN0/oybMXDMLL3Tkvblw3tgcB3u48vejYJsnO0lb6Bx3NMAwemtGPsqoaIgO9uXNK3PEXl+XVPjqjZKz25nDmU7Xj2s9+BQbOds6+TeHmDue8CrYaeq26m+hAz9+VjW3YU8D49CcItpThPutVcGtgMjMwEq74AUJ6ETD3eh48LYK1GQV8sSHLye/IyU0JIRGRVu7JBakk7S/mP+cOJCzQu8n73TyhJ76e7jyxIKXJe23YU0ihtZop/Ro2XawhwgO9efqCQTx34SDS88pYmlp3jbkzVNvs3PTRRtIPlvHqJUPpFd60iWIiIiKucGrvUDzdLPx71gDunBJ37ASrJgjy9eDPp/bgx+25bNxb6LR9jyhpY/2DjhYfFciblyfy3lXDTzxUwnokIeTEf4MOXeGGFY0fY98cOvWAqf/C2P0zfwtdzvKdeVRU2zBNk5++fosZbquwjb2rtjdQY/h1qj0NVVnM2aWfMbRLB/49L4XCVjbR1pWUEBIRacV+2XGQN5bt5tIRXTjdwWkg9enk78V147qzICmnyT/ILUjKwdPdwrjeoU6J7UTOHBBJWIAXn6/PbJb9TdPk/m+2sWxnHv+aNYDRPZ30qpyIiEgLG9c7lKRHpnDR8M7Nsv8Vo7oS4u/Jkwucf0pofUZhbf+gbm2jf9AfTewTXv8LTtaC2kdnlYy1ZkMuh95TmZr9CtE1e1i5K49lm1K4vPB58gPj8Tz1OFPFHBXeDxIuwlj7Ov+Z1IGi8mr+M7/pL4q2FUoIiYi0Uvmlldzx+WZ6hflz35l9nbr31WO6EeLvxWM/pDS6lto0TRYmZzOmZ0iLjE53d7Mwa0gMS1MPklvsvKbYR7z6czqfrMvk5gk9mZ0Y6/T9RUREWpKHW/P9qufn5c6N43uyclc+K9LynLr36vR8PN0sx++v0x6UNcMJodbKMGD681i8/HnO8xWWbMvC/OEOAg0rgRe90fBSsbpM+D/ApGfSi1w9phufrMtkw56Cpu/bBighJCLSCpmmyd1fbKGovJrnLxrs9Bp6Py93bpnUi7UZBY0uwdp+oISswnImO+nkkiPOT4zBZjf56td9Tt33+y0H+M/8FKYnRHH76b2dureIiEhbdPEpnYkM8uaJBalObdS7Oj2fQbHB7XuggzUPDDfwDnZ1JC0jIBxj+nP0M3Zz5pabObV6Ben9/oJHZCNLxf4ouDMMuxY2f8ytCTaigry57+ttVNuaty/lyUAJIRGRVujD1XtYnJLLvVP70DcysFnuceGwWLp28uU/81Kx2Rv+g9zC5GwMA07r23IJoR6h/iR26cBn6zOd9sPnhj2F3PbZJhK7dOCJ8wZqvLyIiIgDvD3cuOW0XmzKPPS7ZsBNUVJRzdZ9RW1m3HyjWfNrR85b2tGv632nszv2HEZaktnh3pu4Wfc5d/+xd4CnP76//IsHZ/QjJbuEd1dkOPceJ6F29BEmInJySM0u4Z/fb2d8XChXju7abPfxcLNw55Q4UnNK+KYRJ24WJuUwtHOHFp/CNTsxlvSDZU5pZLk338p1768nMsib1y9LbFPTTERERJrbuUNj6NrJl6cWpmJvxItLf/Rb/6A22FC6QcrynDdh7CTScdbTfOd7NlUzX8dwRqnY0fw6wai/Qur3TA7I4LQ+YTzz4w72Hyp37n1OMkoIiYi0IhXVNv76318J8HbnifMSnDoVpC5n9I9kYEwQTy/aQUW1zeHrMgusJB8oZnK/ljsddMQZAyPx9XTjs3VNGxtaWWPjqvfWYTNN3rliGB39PJ0UoYiISPvg4WbhttN7k5Jdwtwt+5u8n/oHHWbNbx8Npf8gqENHzrr7PfoPGNw8Nxh5I/iFYfz4EA9Nj8dumjwyN7l57nWSUEJIROQopmnywuKdJO0vcsn9H5uXQmpOCU+cn9AiJ28sFoN7pvZh36FyPly9x+HrFiXnADA5vvnGzR+Pv5c7Zw6I5Lst+7FW1TR6n/+u2UtabinPzB5E91B/J0YoIiLSfkwfGEWfiACeWbSjyT1ZVu8uUP8g+F/JmDiXpx+Mvwf2riI2bxl/Pa0X85OyWZKS4+rIXEYJIRGRo3y7aT9PLdrByz/tavF7b9hTyLsrM7hydFcmxIW12H1H9wxhbK8QnlyYyr9+2E52Uf0TvBYmZxMXHkDXEL8WiPBYs4fFUlZl44et2Y263lpVw4tL0xjRvSPj40KdHJ2IiEj7YbEY3DE5jox8K19uaPzp3ZKKarbtK+KU9t4/CNptyViLGHI5dOwOix/mmlFd6BXmzwPfJlFe5fhJ+bZECSERkcNKKqp59IftAPyUkktlTct+Y3hnxW4CvN25a0pci94X4PHzBjI5PoI3l6Uz9vEl3P3FZtJyS+tcW1hWxdrdBS4pFzsisUsHuoX48dn6zEZd/+7KDPJKq7hrSlyzl+WJiIi0dZP6hpEQG8zzi3c2qAT9aOv3FGKzm+ofZLdBeWG7LBlrEW4eMPHvkJuMZ/IX/PPs/mQVlvPCkp2ujswllBASETnshSVp5JVWctuk3pRV2Vi5K7/F7p1bXMH8bdnMTozF19O9xe57RGSQD89fNJif7pzAhcM68+2m/Zz+zM9c9/76Y5o3/7g9B7vpmnKxIwzD4PzEGNbuLmB3XlmDri0qr+bVn3YxsU8YQ7voVUgREZGmMgyDu6fEsb+ogo/X7G3UHqvT8/FwMxjS3vsHlRcCJvi288RYc4o/ByITYOmjnBLrx7lDYnhjWTppuSWujqzFOZQQMgxjqmEYqYZhpBmGce8J1p1nGIZpGEai80IUEWl+abklvL18N7OHxvLn8d3x83RjYVLL1RN/vHYvNXaTS0Z0abF71qVzJ1/+cXZ/Vtw7kZsn9GTN7gJmvbyS2a+tYmlKLqZpsjA5h8ggb/pHB7o01nOHxGAx4IsNDTsl9OaydIorarhjcu9mikxERKT9Gd0zhJHdO/HyT2mUVTa8x9/qdPUPAmrLxUAJoeZkscCkh6AoE9a/xd/O6IOvpzv3fb0N02z6tLyTSb0JIcMw3ICXgGlAPHCRYRjxdawLAP4KrHF2kCIizck0TR6ak4yvpxt3T43Dy92N8X3CWJSc45QRqvWpttn5eM1eTu0dSjcX9eT5oxB/L+6YHMfKeydy/1nxZBVYufLddUx9dhm/7DjI5Phwl5dahQd6Mz4ujC82ZGFz8P9TXmklby3fzZkDI+kXFdTMEYqIiLQvd06JI6+0indXZjTouiP9g9p9uRiA9XBCSCVjzavHROg+Hn55kk7uFdw7rQ/b9hWx62DdLRPaKkdOCA0H0kzTTDdNswr4BJhZx7p/AI8D9XcjFRFpReZvy2Z5Wh53TI6jk3/tZK/J8eHklVbya2ZhPVc33YKkbHJLKrlspGtPB9XFz8udq8d04+e7J/DU+QmYmFTW2DlzYJSrQwNgdmIMOcWV/LLzoEPrX/lpFxXVNm4/XaeDREREnG1olw5M6hvGi0vSSN5f7PB16h90FJ0QajmTHoLyAlj5AhckxrL0zvH0DAtwdVQtypGEUDRw9Hn8rMNv+41hGIOBWNM0v3NibCIiza68ysY/vkumT0QAfzql829vn9AnDA83o0XKxt5ftYfYjj6Mb8HJYg3l4Wbh3KExzL9lHMvvmcDwbq2j987EPuF09PPkcweaSx8oKueD1Xs4d0gMPTRmXkREpFn865wBBPq4c+3768kvrXTomjXpBeofdIT1cA9LTRlrflGDod85sOolLGW5hAV6uzqiFudIQqiumoDfzuYbhmEBngHuqHcjw7jOMIz1hmGsP3jQsVdzRUSa08s/pbG/qIJHZvbH3e1/XxIDvT0Y0b0TC5Kym7WWOCW7mLW7C7jklC64WVr/tCuLxSCmg6+rw/iNp7uFcwZHsyg5h4KyqhOufX5xGqZpcsukXi0UnYiISPsTFujN65cmcrC0khs+2khVjb3ea1an55MQo/5BwFEJIZ0QahET7wdbFfzyuKsjcQlHEkJZQOxRf48B9h/19wCgP/CTYRgZwAhgTl2NpU3TfN00zUTTNBNDQ0MbH7WIiBPsyS/jtV/SOXtQVJ0nXib3iyAj33rc8evO8P6qPXi5W5idGFv/YqnT7MRYqm0m3/y677hrMvLK+Gx9JhcP79yqEloiIiJtUUJsMI+fO5C1uwt4eG7SCdeWVtawVf2D/qcsD7wCwd3T1ZG0D516wJDLYMO7kL/L1dG0OEcSQuuAXoZhdDMMwxO4EJhz5EnTNItM0wwxTbOraZpdgdXADNM01zdLxCIiTvKP75LxsBj83xl963x+cnw4AAuTm6dsrKi8mq837mNGQhQd/PRNv7HiIgIYGBPEZ+szj3ua69kfd+DhZnDTxJ4tHJ2IiEj7dPbgaP58ag8+WrOXD1bvOe669RkF6h90NGu+Tge1tFPvATdPWPJPV0fS4upNCJmmWQPcDCwAtgOfmaaZZBjGI4ZhzGjuAEVEmsOSlBx+3J7LLZN6EX6ceuHwQG8GxQazMCm7WWL4ckMW5dU2Lh/VtVn2b0/OT4wlJbuEbfuObWCZml3Ct5v3c8WoboQFtL/acBEREVe5a0ocE/uE8fCcJFbuyqtzzeoj/YO6BLdwdK2UNU8TxlpaQASMuBGSvoKDqa6OpkU5ckII0zR/ME2zt2maPUzTfPTw2x4wTXNOHWvH63SQiLRmFdU2Hp6bTI9QP64Y1e2Eayf3C2dzVhEHisqdGoPdbvLh6j0M7hxM/2iNP2+qGQlReLlb+KyO5tJPLUzF39OdP5/a3QWRiYiItF9uFoPnLhxE1xA/bvpoI3vzrcesOdI/yNfT3QURtkJlOiHkEqP/Cn/6EkLa1yRahxJCIiJtyVvLd7Mn38pDM/rh6X7iL4OT4yMA+NHJZWPL0/JIzyvj8pFdnbpvexXk48HU/hF8u2kfFdW2396+KfMQC5NzuHZcd4J9VZYnIiLS0gK8PXjzskTsJlz7/npKK2t+e079g+pgzdeEMVfwDoJek8Bo/UNenEkJIRFpV/YdKueFJTuZ1j+Csb3qb27fM8yfTEpk5gAAIABJREFU7qF+Tu8j9P6qPXTy82TagAin7tuezU6Mpbii5nf/r55amEpHP0+uGnPik2AiIiLSfLqG+PHSxUNIO1jK7Z9uwm6v7fm3YU+h+gcdzTQPl4zp30NahhJCItKu/Ov77QDcd2bdjaTrMjk+glW78imyVjslhswCK4tTcrhoeGe83DVe1VlGdu9EdLAPnx8uG1u1K59lO/O4cXwP/L10DF1ERMSVxvQK4b4z+rIwOYdnf9wB1JaLuVvUP+g3lSW1I9B1QkhaiBJCItJurEjL4/utB7hxfM8GjR6f3C+cGrvJ0tRcp8Tx0Zq9GMDFp3R2yn5Sy2IxOD8xhuVpeWQVWnlyYSoRgd5cMqKLq0MTERER4MrRXZmdGMPzS9L4bsv+2v5Bseof9Btrfu2jeghJC1FCSETahWqbnQfnJNG5oy/XjWtYc+FBMcGEBnixMLnp08Yqqm18um4vp8eHExXs0+T95PfOGxoDwO2fbWbDnkL+clpPvD10CktERKQ1MAyDf5zdn6FdOnDn55vZklXEiO4dXR1W63EkIaQpY9JClBASkXbhk3WZpOWWcv9Z8Q1OEFgsBqfHh/NT6sHfNSxujO+2HKDQWq1m0s0kpoMvo3uEsHZ3AZ07+jI7MdbVIYmIiMhRvNzdePWSoXTw9VT/oD8qy6t9VMmYtBAlhESkzSuvsvHC4p0M69qBSX3DGrXHlH4RWKtsrNyV16RYPliVQc8wf0b20A8/zeWCYbVJoNtP742Hm77NiYiItDahAV68fcUwLhwWy/BuOiH0m99KxvRvIi1DxZoi0uZ9sDqD3JJKXrx4CEYjR0mO7N6JAC93FiblMLFPeKP22JR5iM1ZRTwys1+j45D6nTUwkpgOPgyKVYNKERGR1qpvZCCPnTvQ1WG0LtbDLzyqZExaiF46FZE2raSimpd/2sW43qFNegXK093C+D5h/Lg9B9vhUakN9f6qDPw83ThncHSj45D6GYbB4M4dlHQTERGRk0tZHrh5gae/qyORdkIJIRFp095avptD1mrumhzX5L0mx4eTV1rFr3sLG3xtfmkl320+wLlDYwjw9mhyLCIiIiLSxljzayeM6UUtaSFKCIlIm1VYVsWby3YztV8EA2KCmrzf+LhQPNwMFibnNPjaT9dnUmWzc6lGoIuIiIhIXaz54Kc+k9JylBASkVappKKakorqJu3x6s+7KKuq4Y7JvZ0SU4C3B6N6hLAgKRvTdLxszGY3+Wj1Xkb16ESv8ACnxCIiIiIibUxZniaMSYtSQkhEWp2Kahtnv7SCqc8uI6+0slF75BRX8O7KDM4ZFO3UJMzkfuHsybeyI6fU4Wu++XUf+w6Vc9lInQ4SERERkeOw5tWWjIm0ECWERKTVeWlpGrsOlnGwpJIbPtxAVY29wXu8uCQNm93k1knOOR10xOl9ayeMLUzKrnetzW7y1MJU7vxiM/2jA5nUt3HTyURERESkHbAWaMKYtCglhESkVUnNLuGVn3ZxzuBonpqdwLqMQh74dluDSrQyC6z8d+1eLhgWS+dOvk6NLyzQm8Gdg+vtI5RbUsElb67hhSVpnDckhs+vH4W7m77kioiIiEgdaiqhslglY9Ki3F0dgIjIETa7yT1fbiHQx4P7z4qno58nKdnFvLR0F30jA7l8VFeH9nn2x524WQz+MrFXs8Q5pV8Ej81LYf+hcqKCfY55fmVaHn/9ZBOlldU8eX4C5w2NaZY4RERERKSNsObXPvp2dG0c0q7o5WoRaTU+WJXBpsxD3H9WXzr6eQJwx+lxTOobxiPfJbMiLa/ePdJyS/j61ywuG9mFiCDvZolzcnxt6deiP5wSstlNnl+8k0veWkOQjzvf3jRGySARERERqd+RhJBKxqQFKSEkIq3C/kPlPLEglXG9Qzl7UPRvb7dYDJ65YBA9Qv248aON7MkvO+E+Ty/agY+HGzeM79lssXYP9adnmD8Lk//XRyivtJIr3lnL04t2MHNQNHNuHkNchCaKiYiIiIgDyg6/8KmSMWlBSgiJiMuZpsn932zDbsKjZ/fHMIzfPR/g7cEblyViGHDNe+uPO45+274iftiazdVju/92wqi5TI4PZ3V6AUXWatak53Pm88tYs7uAx2YN4OnZCfh5qSJXRERERBz0W8mYpoxJy1FCSERc7vutB1ickssdk3sT27HuJtBdOvnx8sVDSM8r47ZPN2G3H9tk+smFqQT7enDN2G7NHTKT+0Vgs5vc8umvXPzmGnw93fnmxtFcOLzzMQktEREREZETUsmYuIASQiLiUkXWah6ak8yA6CCuqKdp9KieITxwVjw/bs/lqUWpv3tuXUYBP6Ue5M+n9iDQ26MZI641MDqI8EAvfko9yLT+Ecy5eTTxUYHNfl8RERERaYPK8gADfDq4OhJpR1TTICIu9a8ftlNoreK9q4Y5NJb9spFdfps81js8gJmDojFNkyfmpxIa4MXlI7s2f9DU9jZ67NyBFFmrmTkoSqeCRERERKTxrHm1E8Ysbq6ORNoRJYRExGVW7srj0/WZXH9qd/pFBTl0jWEYPDyjP2m5pdz9xRa6h/hTYK1ibUYBj8zsh49ny30TnRAX1mL3EhEREZE2zJqv/kHS4pQQEnGyfYfK2b6/GH9vdwK83Qn09iDA2x1/L3eHTsC0FxXVNv721VY6d/Tl1tN6N+haT3cLr1wylJkvruC6D9YT5ONBTAcfLhzWuZmiFRERERFpRmX5mjAmLU4JIREnu+mjjWzKPFTnc76ebgR4uxNwOEnUOyyAf88agMXS/sqNnl+8k4x8Kx9dc0qjTvWE+Hvx+mVDOe+VVRwoquCJ8wbi6a6Em4iIiIichKx5ENLL1VFIO6OEkIgTZRVa2ZR5iKvHdGNinzBKKqoprqihtKKGkooaSiqqax8rq9l3qIJP12dyfmIMiV07ujr0FrX9QDGv/5LOeUNjGN2z8a+E9IsK4uVLhvBjcg7nDI52YoQiIiIiIi2oLA86j3B1FNLOKCEk4kTzt2UDcOmILnQN8Tvh2tLKGob+YxFzN+9vVwkhm93k3i+3EOTjwX1n9G3yfhPiwtTLR0REREROXnY7lBeoZExanOorpF07UFTOzR9vJLuowin7zd+WTd/IwHqTQQD+Xu6c1jeM77ceoMZmd8r9Twbvrcxgc1YRD0yPp4Ofp6vDERERERFxrYpDYNrBTwkhaVlKCEm7ZbOb3PrJJr7bcoCP1uxp8n65xRVs2FvItP4RDl8zfWAUeaVVrE4vaPL9TwYlFdU8tTCV8XGhzEiIcnU4IiIiIiKuV5ZX+6gpY9LClBCSduvVn3exZncBIf6efLVxH3a72aT9FiRlY5o0KCE0oU8Yfp5uzN28v0n3Pll8t+UAZVU2bjmtF4bR/hppi4iIiIgcw5pf+6iEkLQwJYSkXdqUeYhnFu3grIGR3HdmX/YdKmdtRtNO6czblk2PUD96hQc4fI23hxuT+0Uwb9sBqmraftnYZ+sz6RXmz6DYYFeHIiIiIiLSOlgPnxBSyZi0MCWEpN0prazhlk9+JTzQm0fPGcCUfhH4ebrx9cZ9jd6zoKyKNbsLmNY/ssHXTk+IpLiihmU7Dzb6/ieDtNwSft17iNmJsTodJCIiIiJyhErGxEWUEJJ258Fvk8gssPLshYMI8vHA19OdaQMi+X7rASqqbY3ac1FyNja7ydQGlIsdMaZnKEE+Hm2+bOzz9Vm4WwzO1nh4EREREZH/+a1kTCeEpGUpISTtypzN+/lyYxY3T+zFsKNGvc8aHE1pZQ0Lk3Mate8PW7OJ7ehDv6jABl/r6W5hWv8IFiXnUF7VuIRUa1dts/Plxn1M7BNGaICXq8MREREREWk9rPng6Q8e3q6ORNoZJYSk3cgssHLf11sZ0jmYv07s+bvnRnTvRFSQN19vzGrwvkXl1azclce0/pGNLoWakRBFWZWNpam5jbq+tfsp9SB5pZWcnxjr6lBERERERFqXsjzw7Vj/OhEnU0JI2oUam53bPt0EJjx34WDc3X7/oW85XMr0y848cksqGrT34u05VNsaVy52xCndOxHi79Vmy8Y+W59JiL8X4+NCXR2KiIiIiEjrYs1XuZi4hBJC0i68tHQX6/cU8s9z+hPb0bfONbOGRGOzm8zZ1LCkzLxt2UQGeTMopvGTs9wsBmcNjGRJSi4lFdWN3qc1yi2pYElKLucOicbDTV9yRERERER+x5qnCWPiEvrtTNq89RkFPLd4B+cMjmbmoOM3NO4ZFsDAmCC+asC0sbLKGn7ZcZAp/SKwWJo2OWt6QiSVNXYWNbKPUWv1za/7sNlNzk+McXUoIiIiIiKtT5lOCIlrKCEkbVpxRTW3fLKJ6A4+PDKzX73rZw2OJvlAMSnZxQ7tvzQ1l8oaO9OaUC52xODYDkQH+7SpsjHTNPlsfRZDOgfTMyzA1eGIiIiIiLQupll7Qkg9hMQFlBCSNss0Tf7+9Tayiyt47sLBBHh71HvN9IQo3C0GXzt4Smje1mxC/D1J7Nr0L+CWw2Vjy3bmUVhW1eT9WoNNmYdIyy1ltppJi4iIiIgcq9oKNRUqGROXUEJI2qyvf93HnM37ufW0Xgzp3MGhazr5ezE+LoyvD5c5nUhFde1UsMn9InBrYrnYEdMToqixm8xPynbKfq722fosfDzcOHNgpKtDERERERFpfcryah9VMiYuoISQtElbsg5x/zfbGN61IzdO6Fn/BUeZNSSa3JJKVqTlnXDdzzsOYq2yOaVc7Ih+UYF0D/FrE2Vj5VU25m7ezxkDIh06nSUiIiIi0u5YjySEOrk2DmmXlBCSNsM0TVbtyufyt9cy48UVeHm48cyFgxp8emdinzACvd35+tcTl43N35ZNkI8HI7o774u3YRiclRDFqvR8cosrnLavK8zbdoDSyhpmq5m0iIiIiEjdrAW1jyoZExdQQkhOeja7yfxtBzj75ZVc9MZqkvYXcdeUOJbeMZ7oYJ8G7+ft4cZZCVHM35ZNaWVNnWuqauz8uD2H0+PDnT5KffrASEwTfth6wKn7trTP1mfStZMvw7upQZ6IiIiISJ3KdEJIXMeh32QNw5hqGEaqYRhphmHcW8fztxuGkWwYxhbDMBYbhtHF+aGK/F5ljY1P1u7l9Kd/5s8fbqSwrIp/nt2f5fdM5KYJPQnybXyZ0rlDoimvtjF/W929fFbsyqOkosap5WJH9AoPoE9EAHO3nLwJoT35ZaxOL+D8xFgMwzn9lURERERE2hyVjIkLude3wDAMN+Al4HQgC1hnGMYc0zSTj1r2K5BomqbVMIwbgMeBC5ojYJHiimo+XrOXt5fvJrekkv7Rgbx48WCm9Y90WnPnIZ070KWTL19tzOK8oceWPM3fmo2/lztjejXP0c7pCVE8sSCVrEIrMR18m+UezemLDVlYjNp+TCIiIiIichzWfLB4gHeQqyORdsiRE0LDgTTTNNNN06wCPgFmHr3ANM2lpmlaD/91NaCmIeJ0NTY7Ly7Zyeh/L+GxeSn0Dg/gw6tPYe7NYzhrYJTTkkFQ28vnnMHRrErPZ/+h8mPiWJiczWl9w/Byd3PaPY82fWAUAN+fhKeEbHaTLzZkMbZXKJFBDS/ZExERERFpN8ryak8H6VS9uIAjCaFoIPOov2cdftvxXA3Mq+sJwzCuMwxjvWEY6w8ePOh4lNLupR8s5dxXV/Hkwh2M6tmJuTeP4cNrTmFMr5BmK0maNTgG04RvNv2+ufSa3QUUWqubpVzsiM6dfEmIDWaOi6eNpeWW8PGavVTb7A5fszwtjwNFFcxOjG3GyERERERE2gBrvsrFxGUcSQjV9du2WedCw7gESASeqOt50zRfN00z0TTNxNDQUMejlHbLNE0+XL2HM59fTkZeGS9ePJjXLk1kQEzzH6ns3MmXYV078NXGfZjm/z7k5207gI+HG6f2DmvW+08fGEnS/mJ2HSxt1vsczxcbspj+wgr+9vVWZr28krRcx+L4fH0mwb4eTIpv3n8fEREREZGTnjUf/JQQEtdwJCGUBRz9Un8McMyxBcMwJgH3ATNM06x0TnjSnuWWVHDVu+v4+zfbSOzagQW3juOsw6VULWXWkBjSckvZtq8YALvdZEFSDuPjQvHxbJ5ysSPOGhiFYcB3m1u2bKy8ysbdX2zmzs83kxAbxOPnDSSr0MqZzy/jvZUZv0uO/dEhaxULk3I4e1B0s5XTiYiIiIi0GWV54KuR8+IajiSE1gG9DMPoZhiGJ3AhMOfoBYZhDAZeozYZlOv8MKW9WZCUzdRnl7FyVz4PTY/nvSuHExHk3eJxnDEgEk93C19uzAJgw95CDpZUMrUZy8WOiAjyZnjXjszZvO+ESRhn2nWwlLNfWsHnG7L4y8SefHj1KcxOjGXBreMY2aMTD85J4vJ31pFTXFHn9d9u2k+Vza5yMRERERERR1jzVDImLlNvQsg0zRrgZmABsB34zDTNJMMwHjEMY8bhZU8A/sDnhmFsMgxjznG2Ezmh0soa7vp8M9d/sIGoYG++/+sYrhjdDYsTG0Y3RJCPB6f3DWfO5v1U2+zM25qNp5uFiX1aphxqekIUuw6WkZJd0uz3+nbTPqa/sJyDpZW8e+Vw7pgch7tb7ZeIsEBv3rliGP84uz9rd+cz5dlf+GHrsSeXPlufSf/oQOKjAps9XhERERGRk5qtGiqKwE8nhMQ16h07D2Ca5g/AD3942wNH/XmSk+OSNuCQtYp7vtyCj4cbkcE+RAX7EB3sTdThPwd6e/xu/bqMAm7/bBP7Csu5eUJP/npaLzzdHTnE1rxmDYnm+60H+Cn1IPO3HWBsrxAC/hB7c5nWP4IH5yQxd/N++kY2T5KlotrGI98l8/GavQzr2oHnLxpc53QwwzC4dEQXRvXoxO2fbuLGjzYya3A0D83sR6C3B9v2FZG0v5hHZvZrljhFRERERNoUa0Hto04IiYs4lBASaYx527JZkJRDdLAPOcUHqLH/vuzJ38udqMMJIj9Pd+ZtO0BMB18+u34kiV07uijqY43rHUonP08em7ed/UUV3HZ67xa7dyd/L0b3DGHulv3cNSXO6RPVMvLKuPGjjSQfKOb6U7tz5+Q4PNxOnITrEerPFzeM4sUlaby4NI01uwt4anYC87dl4+luYUZCy/Z5EhERERE5KVnzah+VEBIXUUJIms2SlFyig31Yfs8E7CbklVay71A5+w+Vc+BQxW9/3l9UTlJxMRcMi+W+M+Px92pdH5YebhamJ0Tx7soM3C0Gp8eHt+j9pw+M5K4vtvDRmr1cMqKL0/adt/UAd3+xBYvF4K3LEzmtr+Pvl4ebhdtO7834uFBu+3QTF72xGk83C1P6RRDs6+m0GEVERERE2qyywwkhlYyJi7Su37ylzaiotrF8Zx7nJ8ZgGAZuBoQHehMe6M2Qzh1cHV6DnTskhndXZjCyR6cWT3hMT4ji2037+fs320jLLeW+M/vWe4rnRMqrbPx73nbeX7WHwZ2DefHiIUQHH1si5ojBnTvwwy1jefT77fx37V4uOaVzo+MSEREREWlXrPm1j5oyJi6ihJA0i9Xp+ZRX21qs+XJz6x8dyHXjurvk/fH2cOPdK4fx73kpvLV8NztySnjp4iF08Gt4YmprVhG3fvoruw6Wcc2Ybtw9tU+T+zT5errz6DkD+PuZ8fh4atS8iIiIiIhDjiSEdEJIXEQJIWkWS1Jy8fFwY0T3tlEPaxgGfzujr8vu7+5m4f6z4ukbGcjfvt7KjJeW88ZlifSJcKzRdI3Nzis/7eK5xTsJ8ffio2tOYXRP537jUTJIRERERKQBjpSM+Zx8FRTSNrh+hJO0OaZpsnh7LmN6heDtoSSBM503NIZPrxtBZbWdWS+vZP62Y0e//9Ge/DJmv7aKpxbtYNqASBbcOs7pySAREREREWkgaz54B4Nby0wwFvkjJYTE6XbklLLvUDmntZFysdZmcOcOzP3LGHqHB/DnDzfyzKId2P8wwQ1qE3P/XbuXac8tIy23lOcuHMQLFw0myFffcEREREREXM6ap3IxcSmVjInTLU7JAWCCEkLNJjzQm0+uG8Hfv9nGc4t3sv1AMU9fMOi3CW15pZXc++VWftyew6genXjy/ASiGtk4WkREREREmkFZnkbOi0spISROt2R7LgOigwgP9HZ1KG2at4cbT5w3kPjIQB79YTuzXl7BG5clsiOnlHu/3EJJZQ33nxXPlaO6YrEYrg5XRERERESOZi2ADl1dHYW0Y0oIiVMVlFWxcW8hf5nYy9WhtAuGYXDVmG70Dg/gpo83MvXZZZRX2+gbGcjHFwwiLiLA1SGKiIiIiEhdrHkQM9TVUUg7poSQONXPO3Kxm3BaX5WLtaQxvUKYc/No7v1yK4M7B3PLpF54uauht4iIiIhIq2SatU2lVTImLqSEkDjV4u25hAZ40T8qyNWhtDtdOvnx3+tGuDoMERERERGpT0UR2GvAV02lxXU0ZUycptpm5+cdB5kYF6aeNSIiIiIiIsdjza991JQxcSElhMRp1mcUUlJRw0SVi4mIiIiIiBxfWV7to0rGxIWUEGpllqbm8qc3V5ORV+bqUBpsSUoOnm4WxvRUlltEREREROS4jpwQUkJIXEgJoVakvMrG377ayoq0fGa9spINewpdHVKDLE7JZUSPTvh5qTWViIiIiIjIcVkPnxBSyZi4kBJCrcjrv6RzoKiCx88bSKC3Oxe/sZp5Ww+4OiyH7M4rI/1gGaf1UbmYiIiIiIjICalkTFoBJYRaiQNF5bz68y7OHBDJ7MRYvrxhFP2iArnx4428uSwd0zRdHeIJLUnJBWCiEkIiIiIiIiInZs0Hdx/w9HN1JNKOKSHUSvxnXgo20+TeaX0A6OTvxcfXjmBqvwj++f12HpqThM3eepNCS1Jy6B3uT2xHX1eHIiIiIiIi0rpZ81UuJi6nhFArsHFvId9s2s91Y7v/LqHi7eHGSxcP4dqx3Xhv1R6u/2AD1qoaF0Zat5KKatakFzCxT7irQxEREREREWn9yvLAt6Oro5B2TgkhF7PbTR6em0xYgBc3jO9xzPMWi8F9Z8bzyMx+LEnJ4aLXV3OwpNIFkR7fsp151NhNTtO4eRERERERkfpZ88BXJ4TEtZQQcrFvNu1jc+Yh7pna54TTuS4b2ZXXLk0kNaeEc15eQVpuSQtGeWKLt+cS7OvB4NhgV4ciIiIiIiLS+qlkTFoBJYRcqKyyhv/MTyEhNphzBkfXu/70+HA+vW4kFdU2Zr28ktXp+S0Q5YnZ7CY/peYyvnco7m76cBIREREREalXWb5OCInL6Td4F3rt513kFFfywFnxWCyGQ9ckxAbz9Y2jCQ3w4rK31rIl61AzR3lim7MOkV9WxcS+6h8kIiIiIiJSr+pyqC5TDyFxOSWEXCSr0Mprv6QzIyGKoV06NOja2I6+fHnDKHw83Xh56a5mitAxS7bn4mYxOLVXqEvjEBEREREROSlYD1d6qGRMXEwJIRd5bF4KhsFvY+YbKtjXk0tGdGZBcjYZeWVOjs5xi1NySezSgSBfD5fFICIiIiIictIoy6t9VMmYuJgSQi6wLqOA77Yc4PpxPYgK9mn0PpeP7IqHxcJby3c7MTrH7T9UzvYDxZouJiIiIiIi4ijrkYRQJ9fGIe2eEkItzG43eWRuMpFB3vz51GPHzDdEWKA3Zw+O4vMNmRSUVTkpQsctSckFYGIf9Q8SERERERFxiLWg9lElY+JiSgi1sC82ZrF1XxH3TuuDj6dbk/e7Zmx3KqrtfLh6jxOia5glKbl06eRLj1C/Fr+3iIiIiIjISalMJ4SkdVBCqAWVVtbwxIJUhnQOZkZClFP27B0ewIS4UN5bmUFFtc0pezqivMrGirQ8JvYJwzAcm5AmIiIiIiLS7lnzwHAD72BXRyLtnBJCLeilpWkcLKnkgen9nJpEuXZcd/LLqvj6131O27M+K3flUVlj5zSVi4mIiIiIiDjOml87ct6iX8fFtfQR2EIyC6y8tWw3swZHMyjWuZngkd070T86kDeWpWO3m07d+3gWp+Ti5+nG8G4dW+R+IiIiIiIibUJZniaMSavg7uoATnafrcukqLyakopqiitqKK2soaSimpKKmsP/1f65uKIad4uFu6c2bsz8iRiGwbVju3PLJ5tYkpLLpPjmPbVjmiZLtucyrnconu7KKYqIiIiIiDjMmq/+QdIqKCHURP/4LpmSyhoAArzcCfB2J8DbgwBvdzr5e9I1xO/w29yZGBdGRJB3s8RxxoBIHp+fyuvL0hudELJW1bAjp7TedVmFVrKLK5jYR+PmRUREREREGqQsD8LjXR2FiBJCTbXo9lPx9XLD39Mdi8V1zZU93CxcObor//x+O5szD5HQwLK0wrIqzn1lJel5ZQ6td7cYjI9TQkhERERERKRBrPkqGZNWQQmhJmquEz+NceHwzjy3eCdvLEvnxYuHOHxdZY2N6z/YQFZhOY+fN5BQf696rwkL9CI0oP51IiIiIiIicpjdBuWFKhmTVkEJoTbE38udi0/pzBu/pJNZYCW2o2+915imyT1fbGFtRgHPXTiImYOiWyBSERERERGRdshaAJjgpxNC4nrqCNzGXDmqGxbD4O0Vux1a/+yPO/lm037unNxbySAREREREZHmZM2vfdQJIWkFlBBqYyKCvJmREMWn6zIpslafcO2XG7J4bvFOzhsaw00TerZQhCIiIiIiIu2UNa/2USeEpBVQQqgNumZsd6xVNj5au+e4a1btyufer7Ywqkcn/nXOAAzDdQ2xRURERERE2oWywwkhnRCSVkAJoTYoPiqQsb1CeHdFBpU1tmOeT8st5foP1tOlkx+vXDIUT3d9GIiIiIiIiDS730rGdEJIXE+ZgDbq2rHdyS2pZM6m/b97e35pJVe9uw4PNwvvXDGMIB8PF0UoIiIiIiLSzqiHkLQiSgi1UWN7hdAnIoA3lqVjmibZKcS0AAAHfElEQVQAFdU2rn1/PTnFFbx5eaJDU8hERERERETEScrywCsQ3D1dHYmIYwkhwzCmGoaRahhGmmEY99bxvJdhGJ8efn6NYRhdnR2oNIxhGFw7tjs7ckr5ecdB7HaTOz7fzMa9h3j2gkEM7tzB1SGKiIiIiIi0L9Z8nQ6SVqPehJBhGG7AS8A0IB64yDCM+D8suxooNE2zJ/AM8B9nByoNNz0hivBAL95Yls6TC1P5fssB/m9aH6YNiHR1aCIiIiIiIu2PNU8TxqTVcHdgzXAgzTTNdADDMD4BZgLJR62ZCTx0+M9fAC8ahmGYR2qV2rIdC8B+bOPm1sATeCgumy83ZLEjHR6JC+XScCAl1dWhiYiIiIiItD+FeyA0ztVRiACOJYSigcyj/p4FnHK8NaZp1hiGUQR0AvKOXmQYxnXAdQCdO3duZMitzBdXQVWpq6M4rmnAtCPlqXsO/yciIiIiIiKu0WuyqyMQARxLCBl1vO2PJ38cWYNpmq8DrwMkJia2jdNDV84D0+7qKE6opKIGPy83LEZd/5tERERERESkxYT1dXUEIoBjCaEsIPaov8cA+4+zJsswDHcgCChwSoStXeRAV0dQrwBXByAiIiIiIiIirYojU8bWAb0Mw+hmGIYncCEw5w9r5gCXH/7zecCSdtE/SERERERERETkJFTvCaHDPYFuBhYAbsDbpmkmGYbxCLDeNM05wFvAB4ZhpFF7MujC5gxaREREREREREQaz5GSMUzT/AH44Q9ve+CoP1cA5zs3NBERERERERERaQ6OlIyJiIiIiIiIiEgbooSQiIiIiIiIiEg7o4SQiIiIiIiIiEg7o4SQiIiIiIiIiEg7o4SQiIiIiIiIiEg7o4SQiIiIiIiIiEg7o4SQiIiIiIiIiEg7Y5im6ZobG8ZBYI9Lbu58IUCeq4MQOYnoc0akYfQ5I9Iw+pwRaRh9zog0TGv/nOlimmZofYtclhBqSwzDWG+aZqKr4xA5WehzRqRh9Dkj0jD6nBFpGH3OiDRMW/mcUcmYiIiIiIiIiEg7o4SQyP+3d2+hlo5xHMe/v2ZMGGkcImZoqMkh5ZA0Dkm4MMi4IEQkcqMcIuFGLlwoOUVKzqVBQ0wulMYUNyaHKach09DMZhjlGGXI38X7jNnt1jb2pnnXtr6f2q31PPu9+N88/d7+632eV5IkSZKkEWND6L/xcN8FSDOMa0aaGteMNDWuGWlqXDPS1Pwv1oxnCEmSJEmSJI0YnxCSJEmSJEkaMTaEJEmSJEmSRowNoX8hyRlJPkmyLsnNfdcjDZskByRZlWRtkg+TXNvm90zyapJP2+cefdcqDZMks5KsSfJyGx+UZHVbM88mmdN3jdKwSDIvyfIkH7e8Od6ckSaX5Pp2X/ZBkmVJdjZnpG2SPJZkc5IPxs0NzJV07m89gfeSHNNf5VNnQ2iakswCHgSWAIcDFyU5vN+qpKHzO3BDVR0GLAaubuvkZmBlVS0CVraxpG2uBdaOG98J3NPWzHfAFb1UJQ2n+4BXqupQ4Ei6tWPOSAMkmQ9cAxxbVUcAs4ALMWek8Z4AzpgwN1muLAEWtb+rgId2UI3/CRtC03ccsK6q1lfVFuAZYGnPNUlDpao2VdW77ftPdDfp8+nWypPtsieBc/upUBo+SRYAZwGPtHGAU4Hl7RLXjNQk2R04GXgUoKq2VNX3mDPS35kN7JJkNrArsAlzRvpLVb0OfDtherJcWQo8VZ03gXlJ9tsxlf57NoSmbz6wcdx4rM1JGiDJQuBoYDWwb1Vtgq5pBOzTX2XS0LkXuAn4o433Ar6vqt/b2LyRtjkY+AZ4vG2zfCTJXMwZaaCq+gK4C9hA1wj6AXgHc0banslyZUb3BWwITV8GzNUOr0KaAZLsBjwPXFdVP/ZdjzSskpwNbK6qd8ZPD7jUvJE6s4FjgIeq6mjgZ9weJk2qnXuyFDgI2B+YS7flZSJzRvpnZvR9mg2h6RsDDhg3XgB82VMt0tBKshNdM+jpqnqhTX+99VHK9rm5r/qkIXMicE6Sz+m2Ip9K98TQvPZoP5g30nhjwFhVrW7j5XQNInNGGux04LOq+qaqfgNeAE7AnJG2Z7JcmdF9ARtC0/cWsKidyD+H7jC2FT3XJA2VdvbJo8Daqrp73L9WAJe175cBL+3o2qRhVFW3VNWCqlpIlyuvVdXFwCrgvHaZa0ZqquorYGOSQ9rUacBHmDPSZDYAi5Ps2u7Ttq4Zc0b6e5Plygrg0va2scXAD1u3ls0EqZoxTzMNnSRn0v1yOwt4rKru6LkkaagkOQl4A3ifbeeh3Ep3jtBzwIF0NybnV9XEg9ukkZbkFODGqjo7ycF0TwztCawBLqmqX/usTxoWSY6iO4R9DrAeuJzuR09zRhogye3ABXRvg10DXEl35ok5IwFJlgGnAHsDXwO3AS8yIFdaY/UBureS/QJcXlVv91H3dNgQkiRJkiRJGjFuGZMkSZIkSRoxNoQkSZIkSZJGjA0hSZIkSZKkEWNDSJIkSZIkacTYEJIkSZIkSRoxNoQkSZIkSZJGjA0hSZIkSZKkEfMn19CuYg0AeUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randint(0, X_train.shape[0])\n",
    "example = X_train[i]\n",
    "pred = model.predict(example.reshape(1,1,-1))\n",
    "combined = np.concatenate([example,y_train[i]], axis=1).squeeze()\n",
    "combined_zeros = np.concatenate([np.zeros_like(example),pred], axis=1).squeeze()\n",
    "\n",
    "plt.plot(combined[-100:])\n",
    "plt.plot(combined_zeros[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'lstm_13/kernel:0' shape=(250, 320) dtype=float32>,\n",
       " <tf.Variable 'lstm_13/recurrent_kernel:0' shape=(80, 320) dtype=float32>,\n",
       " <tf.Variable 'lstm_13/bias:0' shape=(320,) dtype=float32>,\n",
       " <tf.Variable 'lstm_14/kernel:0' shape=(80, 320) dtype=float32>,\n",
       " <tf.Variable 'lstm_14/recurrent_kernel:0' shape=(80, 320) dtype=float32>,\n",
       " <tf.Variable 'lstm_14/bias:0' shape=(320,) dtype=float32>,\n",
       " <tf.Variable 'dense_7/kernel:0' shape=(80, 10) dtype=float32>,\n",
       " <tf.Variable 'dense_7/bias:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 250])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.transpose(weights[0])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-4.8413e-02],\n",
       "         [ 2.2317e-02],\n",
       "         [ 3.5249e-02],\n",
       "         [-1.0856e-01],\n",
       "         [-1.5444e-02],\n",
       "         [-2.3786e-02],\n",
       "         [ 2.5587e-02],\n",
       "         [ 6.1045e-02],\n",
       "         [ 3.5671e-02],\n",
       "         [ 1.9390e-01],\n",
       "         [-4.0002e-02],\n",
       "         [ 3.0305e-02],\n",
       "         [-1.5760e-02],\n",
       "         [ 8.6382e-02],\n",
       "         [ 1.5650e-01],\n",
       "         [-8.4576e-03],\n",
       "         [ 1.3139e-01],\n",
       "         [-4.7507e-02],\n",
       "         [ 6.5172e-02],\n",
       "         [-3.6419e-02],\n",
       "         [ 1.5163e-02],\n",
       "         [-4.2161e-02],\n",
       "         [ 1.1821e-01],\n",
       "         [ 1.3961e-01],\n",
       "         [ 1.4361e-01],\n",
       "         [-1.1900e-01],\n",
       "         [ 1.3945e-01],\n",
       "         [-1.2035e-02],\n",
       "         [ 7.7444e-02],\n",
       "         [ 1.4917e-01],\n",
       "         [ 1.7625e-01],\n",
       "         [ 1.4309e-02],\n",
       "         [-1.5466e-02],\n",
       "         [ 1.4270e-02],\n",
       "         [ 4.8904e-02],\n",
       "         [ 4.8180e-02],\n",
       "         [-4.7263e-02],\n",
       "         [ 6.8557e-02],\n",
       "         [ 1.4053e-01],\n",
       "         [ 4.9546e-02],\n",
       "         [-1.9304e-02],\n",
       "         [ 4.9939e-02],\n",
       "         [ 6.4737e-03],\n",
       "         [ 1.2764e-01],\n",
       "         [-3.9641e-02],\n",
       "         [ 1.1728e-01],\n",
       "         [ 6.4581e-02],\n",
       "         [ 7.6148e-02],\n",
       "         [ 5.3903e-03],\n",
       "         [-1.6473e-03],\n",
       "         [ 1.3284e-01],\n",
       "         [ 7.2212e-02],\n",
       "         [ 1.3053e-01],\n",
       "         [ 1.3250e-01],\n",
       "         [ 1.2467e-01],\n",
       "         [ 7.9635e-02],\n",
       "         [-3.2809e-02],\n",
       "         [ 6.1631e-02],\n",
       "         [ 1.4281e-01],\n",
       "         [-4.6180e-02],\n",
       "         [ 1.5600e-01],\n",
       "         [ 1.9645e-01],\n",
       "         [ 7.4478e-02],\n",
       "         [-9.5708e-02],\n",
       "         [ 9.6641e-02],\n",
       "         [ 1.5711e-01],\n",
       "         [-3.9084e-02],\n",
       "         [-4.1569e-02],\n",
       "         [ 1.4642e-02],\n",
       "         [-4.1083e-02],\n",
       "         [ 5.4692e-02],\n",
       "         [-4.6489e-02],\n",
       "         [ 4.3149e-02],\n",
       "         [ 7.8516e-02],\n",
       "         [ 8.5814e-02],\n",
       "         [-3.0508e-02],\n",
       "         [-3.7660e-02],\n",
       "         [-6.8142e-03],\n",
       "         [ 1.0438e-01],\n",
       "         [-3.5569e-02],\n",
       "         [-3.9263e-02],\n",
       "         [ 9.2354e-02],\n",
       "         [-1.2196e-01],\n",
       "         [-1.1050e-01],\n",
       "         [ 6.6369e-02],\n",
       "         [-2.6947e-02],\n",
       "         [-1.8625e-03],\n",
       "         [ 3.7907e-02],\n",
       "         [ 3.3365e-02],\n",
       "         [ 1.0380e-03],\n",
       "         [ 1.4788e-01],\n",
       "         [ 4.5073e-02],\n",
       "         [-8.4897e-02],\n",
       "         [ 1.6151e-01],\n",
       "         [ 1.2920e-01],\n",
       "         [-5.7365e-03],\n",
       "         [ 1.4012e-01],\n",
       "         [ 9.9155e-02],\n",
       "         [ 1.3163e-01],\n",
       "         [ 8.0153e-02],\n",
       "         [ 2.3175e-02],\n",
       "         [ 1.4390e-01],\n",
       "         [ 1.0807e-01],\n",
       "         [ 5.8550e-02],\n",
       "         [ 1.2595e-01],\n",
       "         [-6.6513e-03],\n",
       "         [-5.9958e-02],\n",
       "         [-4.7380e-02],\n",
       "         [-5.0787e-02],\n",
       "         [-5.1373e-02],\n",
       "         [ 9.9182e-03],\n",
       "         [ 1.2494e-02],\n",
       "         [ 1.5079e-01],\n",
       "         [-1.1864e-01],\n",
       "         [ 1.2363e-01],\n",
       "         [-2.6651e-02],\n",
       "         [-6.8567e-03],\n",
       "         [-5.1540e-02],\n",
       "         [-1.5017e-02],\n",
       "         [ 2.4383e-02],\n",
       "         [ 1.4684e-01],\n",
       "         [-1.3856e-01],\n",
       "         [ 6.4975e-02],\n",
       "         [ 7.6044e-02],\n",
       "         [-6.9217e-02],\n",
       "         [ 1.9667e-02],\n",
       "         [ 5.9411e-02],\n",
       "         [-1.0430e-02],\n",
       "         [ 4.9517e-05],\n",
       "         [ 6.8707e-02],\n",
       "         [ 3.2672e-04],\n",
       "         [ 1.2460e-01],\n",
       "         [ 1.6273e-01],\n",
       "         [ 1.4660e-01],\n",
       "         [ 3.6597e-02],\n",
       "         [-2.4868e-02],\n",
       "         [ 1.6517e-02],\n",
       "         [ 9.2878e-02],\n",
       "         [-4.6819e-02],\n",
       "         [-1.6554e-02],\n",
       "         [-3.6452e-02],\n",
       "         [ 1.3513e-01],\n",
       "         [-3.2053e-02],\n",
       "         [-8.6692e-02],\n",
       "         [ 5.5295e-02],\n",
       "         [-5.9000e-02],\n",
       "         [ 2.6867e-02],\n",
       "         [-1.1556e-02],\n",
       "         [ 4.6336e-02],\n",
       "         [ 1.2897e-01],\n",
       "         [ 6.5463e-02],\n",
       "         [ 5.7291e-02],\n",
       "         [ 3.5898e-02],\n",
       "         [-1.2178e-01],\n",
       "         [ 2.8221e-02],\n",
       "         [-6.9817e-02],\n",
       "         [ 7.5776e-02],\n",
       "         [-1.0981e-01],\n",
       "         [ 1.6811e-02],\n",
       "         [-3.4993e-02],\n",
       "         [-1.1524e-01],\n",
       "         [-1.4873e-01],\n",
       "         [-5.9697e-02],\n",
       "         [-3.6114e-04],\n",
       "         [ 9.8724e-02],\n",
       "         [-8.6744e-02],\n",
       "         [ 1.4139e-01],\n",
       "         [-1.1504e-02],\n",
       "         [ 2.5584e-02],\n",
       "         [ 1.1346e-01],\n",
       "         [ 1.5282e-01],\n",
       "         [-1.4425e-01],\n",
       "         [-1.5841e-01],\n",
       "         [-6.9757e-02],\n",
       "         [ 6.7934e-02],\n",
       "         [-2.0028e-01],\n",
       "         [-5.2174e-02],\n",
       "         [-1.6904e-01],\n",
       "         [ 3.7157e-02],\n",
       "         [ 3.7234e-02],\n",
       "         [ 5.9812e-02],\n",
       "         [-6.8513e-03],\n",
       "         [ 9.3065e-02],\n",
       "         [-1.4928e-01],\n",
       "         [-8.8849e-02],\n",
       "         [ 1.4194e-01],\n",
       "         [-1.6950e-01],\n",
       "         [-8.9971e-02],\n",
       "         [ 1.0126e-01],\n",
       "         [ 1.4536e-01],\n",
       "         [ 1.7067e-01],\n",
       "         [ 1.8422e-01],\n",
       "         [ 1.3928e-01],\n",
       "         [-1.2772e-01],\n",
       "         [ 4.2295e-02],\n",
       "         [-1.5504e-01],\n",
       "         [ 1.3217e-01],\n",
       "         [ 1.2258e-01],\n",
       "         [-4.4526e-02],\n",
       "         [ 9.2960e-02],\n",
       "         [ 7.8624e-02],\n",
       "         [-9.7896e-02],\n",
       "         [-1.6753e-01],\n",
       "         [-1.6794e-01],\n",
       "         [ 1.4199e-01],\n",
       "         [-1.0151e-01],\n",
       "         [ 1.2735e-01],\n",
       "         [-1.5680e-01],\n",
       "         [-1.4426e-02],\n",
       "         [-1.0583e-01],\n",
       "         [ 5.7242e-02],\n",
       "         [ 3.2720e-02],\n",
       "         [ 1.6013e-01],\n",
       "         [ 3.9921e-02],\n",
       "         [-1.5172e-01],\n",
       "         [-5.9754e-03],\n",
       "         [ 1.5506e-01],\n",
       "         [ 7.2327e-02],\n",
       "         [-1.2019e-01],\n",
       "         [-5.3833e-02],\n",
       "         [ 2.7511e-02],\n",
       "         [-1.5931e-01],\n",
       "         [-1.3893e-01],\n",
       "         [-1.6773e-01],\n",
       "         [ 7.3165e-02],\n",
       "         [-1.3618e-01],\n",
       "         [-3.8001e-02],\n",
       "         [-7.3794e-02],\n",
       "         [ 1.6987e-01],\n",
       "         [ 1.6242e-01],\n",
       "         [ 9.9920e-02],\n",
       "         [-1.5339e-01],\n",
       "         [ 1.5441e-01],\n",
       "         [ 1.7786e-01],\n",
       "         [-8.2143e-02],\n",
       "         [ 6.7188e-02],\n",
       "         [ 3.3055e-02],\n",
       "         [-1.1788e-01],\n",
       "         [-1.0283e-01],\n",
       "         [-1.0384e-01],\n",
       "         [ 2.2936e-02],\n",
       "         [ 9.5211e-02],\n",
       "         [ 4.9572e-02],\n",
       "         [-1.0283e-02],\n",
       "         [ 2.4233e-02],\n",
       "         [ 1.8649e-01],\n",
       "         [ 1.3658e-01],\n",
       "         [ 1.4223e-01],\n",
       "         [ 7.7468e-02],\n",
       "         [-5.4958e-03],\n",
       "         [ 3.5441e-02],\n",
       "         [ 8.7722e-03],\n",
       "         [ 4.3775e-02],\n",
       "         [ 1.2803e-01],\n",
       "         [ 1.4824e-01],\n",
       "         [ 1.1479e-01],\n",
       "         [ 7.7412e-02],\n",
       "         [ 2.4120e-03],\n",
       "         [ 7.2137e-02],\n",
       "         [-3.1488e-02],\n",
       "         [ 1.0032e-01],\n",
       "         [ 3.8154e-02],\n",
       "         [ 1.1561e-01],\n",
       "         [ 1.6772e-01],\n",
       "         [ 5.8601e-02],\n",
       "         [ 1.1262e-02],\n",
       "         [ 1.0761e-01],\n",
       "         [ 1.7152e-01],\n",
       "         [-4.5446e-04],\n",
       "         [ 1.7382e-01],\n",
       "         [ 4.5847e-02],\n",
       "         [ 1.7998e-01],\n",
       "         [ 1.8836e-01],\n",
       "         [-1.5114e-01],\n",
       "         [ 1.1337e-01],\n",
       "         [ 1.7801e-02],\n",
       "         [-5.1333e-02],\n",
       "         [ 8.1212e-02],\n",
       "         [ 1.2951e-01],\n",
       "         [ 1.4605e-01],\n",
       "         [ 1.4440e-01],\n",
       "         [ 5.2295e-02],\n",
       "         [-1.2396e-02],\n",
       "         [-1.2411e-02],\n",
       "         [ 1.2028e-01],\n",
       "         [-2.4362e-02],\n",
       "         [ 1.0912e-01],\n",
       "         [-3.7557e-02],\n",
       "         [-2.4313e-02],\n",
       "         [ 8.0541e-03],\n",
       "         [-2.1001e-02],\n",
       "         [ 1.2591e-01],\n",
       "         [-3.1980e-02],\n",
       "         [ 1.5448e-01],\n",
       "         [-1.7182e-02],\n",
       "         [-8.3028e-02],\n",
       "         [ 1.1192e-01],\n",
       "         [ 3.4966e-02],\n",
       "         [ 1.4812e-01],\n",
       "         [ 1.0564e-01],\n",
       "         [ 1.1756e-01],\n",
       "         [ 2.4600e-02],\n",
       "         [ 1.4887e-01],\n",
       "         [-4.5036e-02],\n",
       "         [ 2.8219e-02],\n",
       "         [-1.4334e-02],\n",
       "         [ 8.9971e-02],\n",
       "         [ 6.9403e-02],\n",
       "         [ 1.1205e-01],\n",
       "         [ 5.6489e-02],\n",
       "         [ 5.4965e-02],\n",
       "         [ 1.4235e-01],\n",
       "         [ 1.8115e-01],\n",
       "         [-3.4295e-02],\n",
       "         [ 5.3465e-02],\n",
       "         [ 1.2950e-01],\n",
       "         [-1.2420e-01],\n",
       "         [-1.0576e-01],\n",
       "         [ 1.9663e-01],\n",
       "         [-1.0903e-01]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.0780,  0.0304, -0.0750,  ...,  0.0056, -0.1058, -0.0395],\n",
       "         [-0.0584, -0.0698,  0.1245,  ..., -0.0951, -0.1194, -0.0195],\n",
       "         [ 0.0758, -0.0652, -0.1002,  ..., -0.0696,  0.0170,  0.1037],\n",
       "         ...,\n",
       "         [-0.0977, -0.0249, -0.0019,  ...,  0.0222, -0.0369,  0.0206],\n",
       "         [-0.0739,  0.0317, -0.0733,  ..., -0.1774, -0.0290, -0.1086],\n",
       "         [-0.0330, -0.0037, -0.0307,  ...,  0.0209,  0.0670, -0.0273]],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0331,  0.1316, -0.1070, -0.0829,  0.0460, -0.0213, -0.0137,  0.0858,\n",
       "          0.0847,  0.0752,  0.0405, -0.0097, -0.0021,  0.0749,  0.0011, -0.0605,\n",
       "          0.0257,  0.1059,  0.0680,  0.0760,  0.0843, -0.0405,  0.0787,  0.0028,\n",
       "          0.0025,  0.0698,  0.1414,  0.0883, -0.0221, -0.0092, -0.0701,  0.0247,\n",
       "          0.0564, -0.0539,  0.0988,  0.0889, -0.0482, -0.0892, -0.0300,  0.0711,\n",
       "          0.1067,  0.0535,  0.1083,  0.1218, -0.0411,  0.1140, -0.0684,  0.0415,\n",
       "          0.1014,  0.0343,  0.0529, -0.0622, -0.0449, -0.0839,  0.1134, -0.0192,\n",
       "         -0.0150, -0.0434,  0.0011, -0.0480, -0.0352, -0.0643,  0.0827,  0.0847,\n",
       "          0.0214,  0.0422, -0.0747, -0.0388, -0.0293,  0.0503, -0.0814,  0.0663,\n",
       "          0.1540,  0.1736, -0.0123,  0.0254, -0.0939,  0.1723,  0.0458,  0.0670,\n",
       "         -0.0913,  0.1121, -0.1196,  0.0344, -0.1109, -0.0162, -0.0873,  0.0698,\n",
       "          0.1124, -0.0367, -0.0163,  0.0705,  0.1053, -0.0145,  0.0224, -0.0989,\n",
       "          0.0559, -0.0770,  0.0321, -0.0161,  0.0904, -0.0911, -0.0063,  0.0040,\n",
       "         -0.0734,  0.0696,  0.0886, -0.0498, -0.0690,  0.0790,  0.1088, -0.0322,\n",
       "         -0.0699, -0.0164, -0.0029, -0.0479,  0.0746,  0.0670,  0.1026,  0.1186,\n",
       "         -0.0533,  0.0982,  0.1192,  0.1054, -0.0124, -0.1025, -0.1076,  0.0810,\n",
       "          0.0931,  0.0271, -0.0347,  0.0046,  0.1232, -0.0327,  0.0543, -0.0839,\n",
       "         -0.0560,  0.0954,  0.0639, -0.0776, -0.1096,  0.0557,  0.0600, -0.0058,\n",
       "          0.0321,  0.1012, -0.1199,  0.0517, -0.0217, -0.0849,  0.0279, -0.0224,\n",
       "         -0.0153, -0.0355, -0.0925,  0.0638, -0.0069, -0.0358, -0.0437, -0.0549,\n",
       "          0.0476,  0.0557, -0.0637,  0.0427,  0.0630, -0.0516, -0.0270, -0.0956,\n",
       "          0.0457,  0.0477,  0.0977, -0.0142,  0.0683, -0.0343, -0.1203, -0.0161,\n",
       "          0.1112,  0.0972, -0.0745, -0.1066, -0.0470, -0.0679,  0.1033,  0.0453,\n",
       "         -0.0847, -0.0640,  0.0867,  0.0245, -0.0522,  0.0808, -0.0313, -0.0328,\n",
       "          0.0672,  0.0983,  0.0348, -0.0682, -0.0563,  0.0389, -0.0555,  0.1091,\n",
       "          0.0350, -0.0656,  0.0563, -0.0096, -0.0911,  0.0628,  0.0157, -0.0047,\n",
       "          0.0413, -0.0888, -0.0798, -0.0195,  0.0410,  0.0451, -0.0578, -0.0817,\n",
       "         -0.1133, -0.0505,  0.0141,  0.0292,  0.0501, -0.0727,  0.0104,  0.1228,\n",
       "         -0.0503, -0.0865, -0.0014,  0.0682,  0.0467,  0.1028, -0.0515,  0.0069,\n",
       "         -0.0157, -0.0433, -0.0932, -0.0660, -0.0587,  0.0588,  0.0478,  0.0181,\n",
       "          0.0336,  0.1364,  0.0987,  0.0015,  0.0213,  0.0975,  0.1077,  0.0983,\n",
       "         -0.1037, -0.0112, -0.0239,  0.1007,  0.0778,  0.0171, -0.0363,  0.0355,\n",
       "          0.0063,  0.0491,  0.0369, -0.0605, -0.0880, -0.0775,  0.0537,  0.0115,\n",
       "          0.0235, -0.0381, -0.0290,  0.0816,  0.1331, -0.0823,  0.0843,  0.0206,\n",
       "          0.0247,  0.0353, -0.0434,  0.1298,  0.0925, -0.0270, -0.0624, -0.0544,\n",
       "          0.1256,  0.0709,  0.0945, -0.0326, -0.0238,  0.0880, -0.0543,  0.1042,\n",
       "         -0.0161, -0.0802,  0.0641, -0.0223, -0.0747,  0.1071,  0.0903,  0.0764,\n",
       "          0.0866,  0.0305,  0.0018,  0.0827,  0.0215,  0.1490, -0.0149,  0.0253,\n",
       "          0.0939, -0.0342,  0.0543,  0.0296,  0.0942, -0.0149, -0.0833, -0.0628,\n",
       "          0.0373,  0.0627, -0.1130,  0.0770,  0.0731,  0.1111, -0.0601, -0.0317],\n",
       "        requires_grad=True), Parameter containing:\n",
       " tensor([-7.6235e-02,  4.3920e-02, -1.0066e-01, -4.7348e-02, -5.5739e-02,\n",
       "          7.1629e-02,  2.1175e-02, -5.2647e-03,  3.0356e-02,  1.6598e-01,\n",
       "         -1.1656e-02,  9.3405e-02,  2.1239e-01, -5.2017e-02,  9.3021e-02,\n",
       "          4.4146e-02,  4.2210e-02,  1.3072e-02, -7.1907e-02,  2.5195e-02,\n",
       "         -1.0234e-01, -1.0152e-02,  1.7883e-02,  1.3643e-01,  6.5010e-02,\n",
       "          6.7171e-05, -3.7885e-02,  1.1841e-01,  6.4009e-02, -5.9190e-02,\n",
       "         -7.4293e-02, -8.0434e-02, -1.6465e-02,  3.6723e-02,  3.7921e-02,\n",
       "          2.9841e-02, -6.9401e-02,  8.1456e-02, -6.6746e-02,  6.4443e-02,\n",
       "          1.9202e-02,  2.0162e-01,  4.5029e-02,  1.2672e-01,  5.1945e-02,\n",
       "         -3.7547e-02, -1.2451e-02, -8.2861e-02, -6.6766e-02, -4.4249e-03,\n",
       "         -7.0211e-02, -6.5795e-02,  2.3841e-03, -2.3407e-02, -2.7126e-02,\n",
       "         -7.0130e-02,  1.7564e-02, -7.2162e-02,  1.0926e-01, -7.4358e-02,\n",
       "          6.9574e-02,  8.8224e-02,  5.8050e-02,  1.2000e-01,  1.0386e-01,\n",
       "          5.6039e-02, -5.6444e-02, -5.9306e-03, -4.9258e-02,  7.9961e-02,\n",
       "          9.3298e-03, -3.1933e-02,  6.8445e-02,  4.2235e-02, -7.8288e-02,\n",
       "         -7.6583e-02, -6.9087e-02,  1.0777e-01, -5.3260e-02, -1.0031e-01,\n",
       "         -8.5802e-02, -5.9460e-02,  1.5576e-02, -1.9838e-02,  8.4128e-02,\n",
       "         -1.7802e-02,  3.0589e-02, -7.9321e-02, -4.8816e-02,  1.3894e-01,\n",
       "          9.7797e-02, -8.0236e-03, -3.6485e-03, -7.8354e-02, -9.8906e-02,\n",
       "          2.4975e-02,  5.3455e-02, -1.6906e-02, -5.0887e-02,  3.8775e-02,\n",
       "         -7.9357e-02, -8.6776e-02,  2.0772e-02, -2.7668e-02,  2.2910e-02,\n",
       "          1.3838e-02, -5.7494e-03,  1.7074e-02, -1.1827e-02,  4.6462e-02,\n",
       "          7.9515e-02,  5.2557e-02,  3.4371e-02, -3.0393e-02, -3.6681e-02,\n",
       "         -7.5860e-02,  1.4329e-02,  2.1055e-02, -3.1909e-02, -5.7198e-03,\n",
       "         -4.6835e-02,  6.4545e-02, -7.5284e-02, -8.2610e-02, -3.3229e-03,\n",
       "          8.4686e-02, -8.7752e-02, -8.0867e-02,  8.7392e-02, -4.6059e-02,\n",
       "          4.4213e-02,  9.1282e-02,  9.0079e-02, -9.4843e-02,  1.1592e-01,\n",
       "          9.9095e-03, -3.4482e-02, -6.9266e-02,  7.8454e-02,  7.1282e-02,\n",
       "         -6.3483e-02,  1.1195e-01, -1.8881e-02,  3.6247e-03, -4.1319e-02,\n",
       "         -3.9443e-02, -7.9257e-02, -3.1932e-02,  5.2763e-02,  1.6674e-02,\n",
       "         -8.9808e-02,  1.1473e-01,  8.9717e-02, -5.7572e-02, -1.0285e-01,\n",
       "         -6.5393e-03,  3.3861e-03,  1.3727e-01, -1.0058e-01, -6.4266e-02,\n",
       "         -6.9308e-02,  5.0156e-02,  1.1193e-01, -1.0592e-03, -7.6545e-03,\n",
       "          7.6957e-03,  6.7796e-02, -4.9444e-02, -6.7209e-03, -3.9302e-02,\n",
       "         -4.0601e-02, -1.3217e-02, -6.5957e-03, -3.1534e-02, -2.4903e-02,\n",
       "         -3.5018e-02, -6.1668e-03, -2.5397e-02, -1.1295e-01,  2.5325e-02,\n",
       "          9.0417e-02,  9.9577e-03,  9.3952e-02, -2.4910e-02, -4.8391e-02,\n",
       "         -5.7525e-02, -7.5931e-02, -6.8332e-02,  8.5210e-02,  6.4613e-02,\n",
       "          9.7827e-02,  5.2239e-02,  6.1094e-02,  6.0486e-02, -1.0960e-01,\n",
       "          1.5842e-02,  5.8802e-02,  7.7716e-02, -6.9760e-02, -3.0010e-02,\n",
       "         -1.6683e-03,  5.2552e-02,  1.3585e-02,  2.4218e-02,  4.9728e-02,\n",
       "         -5.2762e-02,  6.0360e-02, -5.4730e-02, -9.5030e-02, -3.4234e-02,\n",
       "         -3.2465e-02,  5.3834e-02, -2.4020e-02,  3.1860e-02, -2.2787e-03,\n",
       "         -6.9673e-02,  3.9490e-02, -2.1642e-02, -3.4584e-02, -7.7396e-04,\n",
       "          9.7483e-02,  5.7990e-02,  1.3694e-02, -5.3433e-02, -1.0879e-01,\n",
       "         -5.3000e-02, -9.7385e-02, -6.6756e-02, -7.8407e-02, -2.2450e-04,\n",
       "          8.9627e-02, -8.8201e-02,  4.4180e-02, -5.3166e-02, -6.6013e-02,\n",
       "          5.8320e-02, -8.8145e-02,  1.1464e-02, -3.1986e-02,  7.3750e-02,\n",
       "          7.3141e-03, -6.5218e-02, -8.6474e-02,  6.9416e-02,  1.3379e-02,\n",
       "         -8.2319e-02,  7.3092e-02,  7.5104e-02,  3.8953e-02,  1.8064e-01,\n",
       "         -6.6870e-02,  4.6013e-02,  2.5554e-03, -8.7274e-02, -9.2820e-02,\n",
       "         -2.9620e-02,  1.5120e-02, -1.4189e-03, -1.1254e-01,  5.7913e-02,\n",
       "         -4.8545e-02, -2.5136e-02, -7.0471e-02,  1.7735e-02,  9.4448e-02,\n",
       "         -7.6731e-02,  8.6837e-02, -6.3717e-02,  2.6472e-02, -2.7491e-02,\n",
       "         -7.6355e-02, -6.9126e-02,  8.4636e-02,  3.0807e-02,  6.7207e-02,\n",
       "          8.0243e-02,  1.2405e-02,  8.2725e-02,  6.2131e-02,  1.1090e-01,\n",
       "          1.3926e-02, -1.4981e-02,  3.4685e-02, -1.9381e-02,  7.9428e-02,\n",
       "          6.3564e-02,  1.1079e-01,  2.3311e-02,  1.0683e-01, -6.0900e-02,\n",
       "          8.6977e-02, -5.6738e-02, -8.2343e-02, -1.0200e-01,  2.2616e-02,\n",
       "         -3.3610e-02,  1.1960e-01,  2.3634e-02, -4.8211e-03, -1.2408e-01,\n",
       "          6.6233e-02,  6.8916e-02, -6.9244e-02,  9.6465e-02,  1.1961e-01,\n",
       "         -2.8003e-02,  5.5115e-02,  7.2611e-02, -5.7380e-02,  1.1830e-01,\n",
       "          7.7750e-02,  5.5319e-02, -8.7310e-04,  1.6445e-01, -1.0517e-01,\n",
       "          7.1538e-02, -1.2250e-01,  1.1505e-01, -8.4047e-02,  5.1207e-02],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(torch_model.lstm1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mne-5]",
   "language": "python",
   "name": "conda-env-mne-5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
